{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AssumedGender(input_name='Eirik', gender='mann', mode='list_lookup', assumed_name='Eirik')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "AssumedGender(input_name='Ulerikka', gender='kvinne', mode='predictor', assumed_name='Ulerikka')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "AssumedGender(input_name=\" 'Lan Marie Nguyen Berg'\", gender='kvinne', mode='list_lookup', assumed_name='Lan')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "AssumedGender(input_name=\"Abracus Bakkus Casparus Daniel Berg'\", gender='mann', mode='list_lookup', assumed_name='Abracus')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from ntk import Ntk\n",
    "ntk = Ntk()\n",
    "import pandas as pd\n",
    "\n",
    "ntk.get_gender(\"Eirik\")\n",
    "#AssumedGender(input_name='Eirik', gender='mann', mode='list_lookup', assumed_name='Eirik')\n",
    "\n",
    "input_navn, kjonn, metode, antatt_navn =ntk.get_gender(\"Eirik\")\n",
    "\n",
    "ntk.get_gender(\"Ulerikka\")\n",
    "\n",
    "ntk.get_gender(\" 'Lan Marie Nguyen Berg'\")\n",
    "\n",
    "ntk.get_gender(\"Abracus Bakkus Casparus Daniel Berg'\")\n",
    "\n",
    "# Tving gjennom ML prediksjon: (returnerer 'M'/'F' som str )\n",
    "ntk.predict_gender(\" 'Lan Marie Nguyen Berg'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mann'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntk.get_gender(\"Eirik\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Navn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dato</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2. januar</th>\n",
       "      <td>Dagfinn og Dagfrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. januar</th>\n",
       "      <td>Alfred og Alf og Alva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4. januar</th>\n",
       "      <td>Roar og Roger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5. januar</th>\n",
       "      <td>Hanna og Hanne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6. januar</th>\n",
       "      <td>Aslaug, Åslaug og Aisha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Navn\n",
       "Dato                              \n",
       "2. januar       Dagfinn og Dagfrid\n",
       "3. januar    Alfred og Alf og Alva\n",
       "4. januar            Roar og Roger\n",
       "5. januar           Hanna og Hanne\n",
       "6. januar  Aslaug, Åslaug og Aisha"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jeg burde ha så mange navn: 855\n"
     ]
    }
   ],
   "source": [
    "# Har navnedag\n",
    "url = \"https://no.wikipedia.org/wiki/Liste_over_norske_navnedager\"\n",
    "data = pd.read_html(url, header=0, index_col=0)[0]\n",
    "#data.head()\n",
    "data = data[[\"Navn\"]]\n",
    "data.dropna(subset=['Navn'], how='all', inplace = True) # skip 1.jan, er nan\n",
    "data.head()\n",
    "\n",
    "# | Navn  | dato\n",
    "# | Eirik | 18 mai\n",
    "har_navnedag = []\n",
    "har_navnedag.append([\"Jesus\", \"1. januar\"])\n",
    "\n",
    "rene_navn1 = []\n",
    "\n",
    "for d in data.iterrows():\n",
    "    #print(d[0], type(d[0]))\n",
    "    #print(d[1].Navn)\n",
    "    navn_pr_dag = [n for n in d[1].Navn.replace(\",\",\"\").split() if n.lower() not in [\"og\", \"(navn)\"]]\n",
    "    for n in navn_pr_dag:\n",
    "        har_navnedag.append([n, d[0]])\n",
    "        rene_navn1.append(n)\n",
    "    #print()\n",
    "\n",
    "df = pd.DataFrame.from_records(har_navnedag, columns=[\"Navn\", \"Dato\"])\n",
    "# save only this one scrape\n",
    "#df.to_csv(path_or_buf=\"praenomen2genus/data/har_norsk_navnedag.csv\", sep='\\t', encoding='utf-8', index=False)\n",
    "\n",
    "df.set_index(\"Navn\", inplace=True)\n",
    "#df.head()\n",
    "\n",
    "\n",
    "#    !\n",
    "\n",
    "# pokker finnes enda en liste:\n",
    "url2 = \"https://no.wikipedia.org/wiki/Liste_over_norske_navnedager_sortert_etter_navn\"\n",
    "data2 = pd.read_html(url2, header=0, index_col=0)[0]\n",
    "data2 = data2[[\"Navnedag\"]]\n",
    "data2.columns = [[\"Dato\"]]\n",
    "#data2.head()\n",
    "#data.describe()\n",
    "rene_navn2 = []\n",
    "for nn in data2.iterrows():\n",
    "    rene_navn2.append(nn[0])\n",
    "\n",
    "bare_i_forste = [n for n in rene_navn1 if n not in rene_navn2]\n",
    "bare_i_andre = [n for n in rene_navn2 if n not in rene_navn1]\n",
    "\n",
    "#print(len(bare_i_forste), bare_i_forste)\n",
    "#print(len(bare_i_andre), bare_i_andre)\n",
    "print(\"jeg burde ha så mange navn:\", len(set(rene_navn1+rene_navn2)))\n",
    "\n",
    "\n",
    "# la oss merge disse\n",
    "\n",
    "#result = df.append(data2) #ignore_index=True # blir 1662 rader, virker for mye...\n",
    "#result.describe()\n",
    "#result\n",
    "\n",
    "result2 = pd.merge(df, data2, how=\"outer\", right_index=True, left_index=True) # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_navendager():\n",
    "    nd_df = pd.read_csv(\"data/har_norsk_navnedag.csv\", sep=\"\\t\")\n",
    "    for n in nd_df.itertuples():\n",
    "        print(n.Navn)\n",
    "        # ah føkk. mangler kjønn på disse.\n",
    "\n",
    "#test_navendager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "begge_kjonn = [\"Gunnleiv\", \"Kim\"]\n",
    "kvinne = [\"Hallgjerd\"]\n",
    "menn = [\"Klement\", \"Clement\", \"Clément\", \"Salve\"]\n",
    "\n",
    "har_navnedag_kjonn = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Norrønt navn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Navn</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Allvis</th>\n",
       "      <td>Allvís, «den som vet alt»</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andrimne</th>\n",
       "      <td>Andrimner, «en med sot i ansiktet»</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andvare</th>\n",
       "      <td>Andvari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angerboda</th>\n",
       "      <td>Angrboða, «sorgvarsleren»</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aurboda</th>\n",
       "      <td>Eirboða</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Norrønt navn\n",
       "Navn                                         \n",
       "Allvis              Allvís, «den som vet alt»\n",
       "Andrimne   Andrimner, «en med sot i ansiktet»\n",
       "Andvare                               Andvari\n",
       "Angerboda           Angrboða, «sorgvarsleren»\n",
       "Aurboda                               Eirboða"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# norrøne navn\n",
    "norr_url = \"https://no.wikipedia.org/wiki/Liste_over_personer_i_norr%C3%B8n_mytologi\"\n",
    "\n",
    "norr = pd.read_html(norr_url, header=0, index_col=0)[0]\n",
    "norr2 = norr[[\"Norrønt navn\"]]\n",
    "\n",
    "norr2.head()\n",
    "#norr2.to_csv(path_or_buf=\"praenomen2genus/data/personer_i_norron_mytologi.csv\", sep='\\t', encoding='utf-8')#\n",
    "personer_i_norron_mytologi = norr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bibjent                                       1\n",
      "0                                      \n",
      "NaN  A-Å | Hjelp | Spørsmål | Kontakter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Navn</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>A-Å | Hjelp | Spørsmål | Kontakter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       1\n",
       "Navn                                    \n",
       "NaN   A-Å | Hjelp | Spørsmål | Kontakter"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Kommentar</th>\n",
       "      <th>Kjønn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Navn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [(Kommentar,), (Kjønn,)]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bibelske navn\n",
    "url1 = \"https://www.ssb.no/a/magasinet/blandet/tab-2006-02-09-02.html\" # jenter\n",
    "url2 = \"https://www.ssb.no/a/magasinet/blandet/tab-2006-02-09-01.html\" # gutter\n",
    "\n",
    "bibjent = pd.read_html(url1, index_col=0)[0] #  header=0, føkket det til..\n",
    "print(\"bibjent\", bibjent)\n",
    "#bibjent.columns = [[\"Kommentar\"]]\n",
    "bibjent.index.names = ['Navn']\n",
    "bibjent.head()\n",
    "\n",
    "bibeljenter = ['Abiah', 'Abigail', 'Abijah', 'Abilene', 'Abishag', 'Abital', 'Adah', 'Adina', 'Apphia', 'Ariel', 'Asenath', 'Ashtoreth', 'Atarah', 'Azubah', 'Basemath', 'Bashemath', 'Basmath', 'Bathsheba', 'Bernice', 'Bethany', 'Bethel', 'Beulah', 'Bilhah', 'Bithiah', 'Candace', 'Carmel', 'Chloe', 'Damaris', 'Deborah', 'Delilah', 'Dinah', 'Dorcas', 'Drusilla', 'Eden', 'Edna', 'Elisabeth', 'Elisheba', 'Elizabeth', 'Esther', 'Eunice', 'Eve', 'Gethsemane', 'Hadassah', 'Hagar', 'Hannah', 'Havilah', 'Helah', 'Hephzibah', 'Hepzibah', 'Hulda', 'Huldah', 'Ivah', 'Jael', 'Jedidah', 'Jemima', 'Jerusha', 'Jezebel', 'Joanna', 'Jordan', 'Judith', 'Julia', 'Keren-happuch', 'Keturah', 'Keziah', 'Leah', 'Lois', 'Lydia', 'Magdalene', 'Mahalath', 'Mahlah', 'Mara', 'Martha', 'Mary', 'Mehetabel', 'Mehitabel', 'Micaiah', 'Michal', 'Miriam', 'Moriah', 'Naamah', 'Naomi', 'Neriah', 'Noa', 'Noah', 'Ophrah', 'Orpah', 'Peninnah', 'Persis', 'Philadelphia', 'Phoebe', 'Prisca', 'Priscilla', 'Rachel', 'Rahab', 'Rebecca', 'Rebekah', 'Rhoda', 'Ruth', 'Salome', 'Sapphira', 'Sarah', 'Sarai', 'Sela', 'Sharon', 'Sherah', 'Shiphrah', 'Susanna', 'Susannah', 'Syntyche', 'Tabitha', 'Talitha', 'Tamar', 'Tirzah', 'Tryphena', 'Tryphosa', 'Vashti', 'Zillah', 'Zilpah', 'Zipporah']\n",
    "for j in bibeljenter:\n",
    "    if j not in bibjent.index:\n",
    "        bibjent.loc[j] = pd.Series({'Kommentar': \"fra liste\"})\n",
    "\n",
    "bibjent[\"Kjønn\"] = \"f\"\n",
    "\n",
    "\n",
    "\n",
    "bibgutt = pd.read_html(url2, header=0, index_col=0)[0]\n",
    "bibgutt.columns = [[\"Kommentar\"]]\n",
    "bibgutt.index.names = ['Navn']\n",
    "bibgutt[\"Kjønn\"] = \"m\"\n",
    "bibgutt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Jødiske navn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Populære navn (periodisk oppdatet fra ssb?)\n",
    "# for mange land her: http://www.uib.no/lle/23822/navnestatistikk-fra-mange-land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Som rimer på\n",
    "# som likner på\n",
    "# som inneholder en \"o\"\n",
    "# som besteforeldrenes generasjon brukte\n",
    "# som olderforeldrenes generasjon brukte\n",
    "# som tip-tip-tip...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger __main__ (INFO)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: ../../data/no_names.pickle\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import logging\n",
    "import pickle\n",
    "from nltk import NaiveBayesClassifier, classify\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger\n",
    "\n",
    "\n",
    "# dir = os.path.dirname('../')\n",
    "# print(dir)\n",
    "pickle_file = os.path.join('../../', 'data/no_names.pickle')\n",
    "print(\"file:\", pickle_file)\n",
    "\n",
    "#pickle_file = 'data/no_names.pickle'\n",
    "#%pwd\n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/eirik.stavelin/Projects/ntk/tests/explorations'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Accuracy: 0.8678899082568807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8678899082568807"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# this is just the predictor\n",
    "class genderPredictor():\n",
    "    \"\"\" This is the AI model that kicks in if name is not found in lists.\n",
    "    It is rewritten to just load picke file with names data.\n",
    "    New names data ca be generated with aux_picklemaker_NOLoader.py\n",
    "    \"\"\"\n",
    "\n",
    "    def getFeatures(self):\n",
    "        maleNames, femaleNames = self._loadNames()\n",
    "\n",
    "        featureset = list()\n",
    "        for nameTuple in maleNames:\n",
    "            features = self._nameFeatures(nameTuple[0])\n",
    "            featureset.append((features, 'M'))\n",
    "\n",
    "        for nameTuple in femaleNames:\n",
    "            features = self._nameFeatures(nameTuple[0])\n",
    "            featureset.append((features, 'F'))\n",
    "        #print(featureset)\n",
    "        # [({'last_letter': 'S', 'last_two': 'AS', 'last_three': 'EAS', 'last_is_vowel': False}, 'M'), ({'last_letter': 'Z', 'last_two': 'SZ', 'last_three': 'USZ', 'last_is_vowel': False}, 'M'), ({'last_letter': 'R', 'last_two': 'UR', 'last_three': 'VUR', 'last_is_vowel': False}, 'M'), ({'last_letter': 'S', 'last_two': 'AS', 'last_three': 'BAS', 'last_is_vowel': False}, 'M'), ({'last_letter': 'R', 'last_two': 'UR', 'last_three': 'DUR', 'last_is_vowel': False}, 'M'), \n",
    "        return featureset\n",
    "\n",
    "    def trainAndTest(self, trainingPercent=0.80):\n",
    "        featureset = self.getFeatures()\n",
    "        random.shuffle(featureset)\n",
    "        name_count = len(featureset)\n",
    "        cut_point = int(name_count*trainingPercent)\n",
    "        train_set = featureset[:cut_point]\n",
    "        test_set = featureset[cut_point:]\n",
    "\n",
    "        self.train(train_set)\n",
    "        logger.info(\"Accuracy: %s\" % (self.test(test_set)))\n",
    "        return self.test(test_set)\n",
    "\n",
    "    def classify(self, name):\n",
    "        feats = self._nameFeatures(name)\n",
    "        return self.classifier.classify(feats)\n",
    "\n",
    "    def train(self, train_set):\n",
    "        self.classifier = NaiveBayesClassifier.train(train_set)\n",
    "        return self.classifier\n",
    "\n",
    "    def test(self, test_set):\n",
    "        return classify.accuracy(self.classifier, test_set)\n",
    "\n",
    "    def getMostInformativeFeatures(self, n=15):\n",
    "        logger.info(self.classifier.show_most_informative_features(n))\n",
    "        return self.classifier.most_informative_features(n)\n",
    "\n",
    "    def _loadNames(self):\n",
    "        # print USSSALoader.getNameList()\n",
    "        f = open(pickle_file, 'rb')\n",
    "        names = pickle.load(f)\n",
    "        # return NOLoader.getNameList()\n",
    "        # print names\n",
    "        return names\n",
    "\n",
    "    def _nameFeatures(self, name):\n",
    "        name = name.upper()\n",
    "        return {\n",
    "            'last_letter': name[-1],    # -a er oftere for jenter\n",
    "            'last_two': name[-2:],      # -en er oftere for gutter\n",
    "            'last_three': name[-3:],    # -ine er oftere for jenter..\n",
    "            'last_is_vowel': (name[-1] in u'AEIOUYÆØÅ')  # slutter noen navn på\n",
    "            # ÆØÅ i det heletatt? (øker accuracy til 0.82, men senker\n",
    "            # mini-testen for herrer med 7 prosentpoeng og øker damer med 2\n",
    "            # prosentpoeng)\n",
    "        }\n",
    "\n",
    "%pwd\n",
    "noe = genderPredictor()\n",
    "noe.trainAndTest()\n",
    "\n",
    "#noe.getMostInformativeFeatures()\n",
    "#noe.classify(\"Noe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fra Roberts kode:\n",
    "import numpy as np\n",
    "# def featureEngineer(df):\n",
    "#     output = df\n",
    "    \n",
    "#     # Day of week. Monday = 0, Sunday = 6\n",
    "#     output['DayCreated'] = output['CreatedAt'].dt.dayofweek\n",
    "\n",
    "#     # Weekend or not. Weekend = 1\n",
    "#     output['Weekend'] = np.where(((output['DayCreated']==5) | (output['DayCreated']==5)),1,0)\n",
    "\n",
    "#     global categorical\n",
    "#     categorical = ['Age','Gender','Year','DayCreated','Weekend']\n",
    "\n",
    "#     dummies = output[categorical].astype(str)\n",
    "#     dummies = dummies.fillna('MissingValue')\n",
    "#     dummies = pd.get_dummies(dummies)\n",
    "\n",
    "#     output = pd.concat([output,dummies], axis=1, join='inner')    \n",
    "\n",
    "#     output['Body'] = output['Body'].astype(str)\n",
    "\n",
    "#     return output\n",
    "\n",
    "# data = featureEngineer(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0e2ea01bd33f26cc744c5ad7e2be103241be5e8a6903fb841a3bd29e21386e2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('3.9.0': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
