{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-sklearn is not supported on OSX. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>final_letter_is_vowel</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>last_1_letter</th>\n",
       "      <th>last_2_letter</th>\n",
       "      <th>last_3_letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EIRIK</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>K</td>\n",
       "      <td>IK</td>\n",
       "      <td>RIK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EIRIKA</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>KA</td>\n",
       "      <td>IKA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  final_letter_is_vowel  syllable_count last_1_letter last_2_letter  \\\n",
       "0   EIRIK                      0               1             K            IK   \n",
       "1  EIRIKA                      1               2             A            KA   \n",
       "\n",
       "  last_3_letter  \n",
       "0           RIK  \n",
       "1           IKA  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aux_functions import generate_language_features\n",
    "\n",
    "_ = generate_language_features(pd.DataFrame([\"Eirik\", \"Eirika\"], columns=[\"Name\"]))\n",
    "_.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder(handle_unknown='ignore', sparse=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def get_one_hot_encoder(df, \n",
    "                categorical_columns = ['last_1_letter',\t'last_2_letter', 'last_3_letter']\n",
    "                ):\n",
    "    encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)    \n",
    "    encoder.fit(df[categorical_columns])\n",
    "    print(encoder)\n",
    "    \n",
    "    return encoder\n",
    "\n",
    "encoder = get_one_hot_encoder(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names goes in, this comes out:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>final_letter_is_vowel</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>last_1_letter</th>\n",
       "      <th>last_2_letter</th>\n",
       "      <th>last_3_letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EIRIK</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>K</td>\n",
       "      <td>IK</td>\n",
       "      <td>RIK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EIRIKA</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>KA</td>\n",
       "      <td>IKA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  final_letter_is_vowel  syllable_count last_1_letter last_2_letter  \\\n",
       "0   EIRIK                      0               1             K            IK   \n",
       "1  EIRIKA                      1               2             A            KA   \n",
       "\n",
       "  last_3_letter  \n",
       "0           RIK  \n",
       "1           IKA  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder transformed\n",
      "[[0. 1. 1. 0. 0. 1.]\n",
      " [1. 0. 0. 1. 1. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['last_1_letter_A', 'last_1_letter_K', 'last_2_letter_IK',\n",
       "       'last_2_letter_KA', 'last_3_letter_IKA', 'last_3_letter_RIK'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_1_letter_A</th>\n",
       "      <th>last_1_letter_K</th>\n",
       "      <th>last_2_letter_IK</th>\n",
       "      <th>last_2_letter_KA</th>\n",
       "      <th>last_3_letter_IKA</th>\n",
       "      <th>last_3_letter_RIK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   last_1_letter_A  last_1_letter_K  last_2_letter_IK  last_2_letter_KA  \\\n",
       "0              0.0              1.0               1.0               0.0   \n",
       "1              1.0              0.0               0.0               1.0   \n",
       "\n",
       "   last_3_letter_IKA  last_3_letter_RIK  \n",
       "0                0.0                1.0  \n",
       "1                1.0                0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>final_letter_is_vowel</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>last_1_letter</th>\n",
       "      <th>last_2_letter</th>\n",
       "      <th>last_3_letter</th>\n",
       "      <th>last_1_letter_A</th>\n",
       "      <th>last_1_letter_K</th>\n",
       "      <th>last_2_letter_IK</th>\n",
       "      <th>last_2_letter_KA</th>\n",
       "      <th>last_3_letter_IKA</th>\n",
       "      <th>last_3_letter_RIK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EIRIK</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>K</td>\n",
       "      <td>IK</td>\n",
       "      <td>RIK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EIRIKA</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>KA</td>\n",
       "      <td>IKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  final_letter_is_vowel  syllable_count last_1_letter last_2_letter  \\\n",
       "0   EIRIK                      0               1             K            IK   \n",
       "1  EIRIKA                      1               2             A            KA   \n",
       "\n",
       "  last_3_letter  last_1_letter_A  last_1_letter_K  last_2_letter_IK  \\\n",
       "0           RIK              0.0              1.0               1.0   \n",
       "1           IKA              1.0              0.0               0.0   \n",
       "\n",
       "   last_2_letter_KA  last_3_letter_IKA  last_3_letter_RIK  \n",
       "0               0.0                0.0                1.0  \n",
       "1               1.0                1.0                0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"Names goes in, this comes out:\")\n",
    "nuff = generate_language_features(pd.DataFrame([\"Eirik\", \"Eirika\"], columns=[\"Name\"]))#.drop(['Name'],axis=1)\n",
    "nuff.head()\n",
    "\n",
    "ohe = encoder.transform(nuff[['last_1_letter',\t'last_2_letter', 'last_3_letter']])\n",
    "print(\"encoder transformed\")\n",
    "print(ohe)\n",
    "encoder.get_feature_names_out()\n",
    "\n",
    "ohe_df = pd.DataFrame(ohe, columns=encoder.get_feature_names_out())\n",
    "ohe_df\n",
    "\n",
    "#tt = nuff.append(ohe_df, axis=0)\n",
    "tt = pd.concat([nuff, ohe_df], axis=1)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ösp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Þórður</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  Gender\n",
       "0     Ösp       0\n",
       "1  Þórður       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5492"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets make one for all names i ntk\n",
    "from ntk import Ntk\n",
    "def load_gendered_names(shuffle: bool = True, gender_as_bool:bool=True):\n",
    "    ntk = Ntk()\n",
    "\n",
    "    m = [n for n in ntk.gutter if n not in ntk.jenter]\n",
    "    f = [n for n in ntk.jenter if n not in ntk.gutter]\n",
    "\n",
    "    names = m + f\n",
    "    genders = ['Male' for n in m] + [\"Female\" for n in f]\n",
    "\n",
    "    names_df = pd.DataFrame([(k, v) for k, v in zip(\n",
    "        names, genders)], columns=['Name', 'Gender'])\n",
    "\n",
    "\n",
    "    if shuffle:\n",
    "        names_df = names_df.sample(\n",
    "            frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    #\n",
    "    if gender_as_bool:\n",
    "        # swap \"Mann\", \"Kvinne\" with 1, 0\n",
    "        from sklearn.preprocessing import LabelBinarizer\n",
    "        lb = LabelBinarizer()\n",
    "\n",
    "        binary_gender = lb.fit_transform(names_df['Gender'])\n",
    "        ##print(lb.inverse_transform(binary_gender))\n",
    "        ##target_strings = lb.inverse_transform(np.arange(num_classes))\n",
    "\n",
    "        names_df['Gender'] = binary_gender\n",
    "\n",
    "    return names_df\n",
    "\n",
    "df = load_gendered_names()\n",
    "df.head(2)\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>final_letter_is_vowel</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>last_1_letter</th>\n",
       "      <th>last_2_letter</th>\n",
       "      <th>last_3_letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ÖSP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>SP</td>\n",
       "      <td>ÖSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ÞÓRÐUR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>UR</td>\n",
       "      <td>ÐUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EDDA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>DA</td>\n",
       "      <td>DDA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  Gender  final_letter_is_vowel  syllable_count last_1_letter  \\\n",
       "0     ÖSP       0                      0               1             P   \n",
       "1  ÞÓRÐUR       1                      0               1             R   \n",
       "2    EDDA       0                      1               2             A   \n",
       "\n",
       "  last_2_letter last_3_letter  \n",
       "0            SP           ÖSP  \n",
       "1            UR           ÐUR  \n",
       "2            DA           DDA  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5492"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_features_df = generate_language_features(load_gendered_names())\n",
    "names_features_df.head(3)\n",
    "len(names_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder(handle_unknown='ignore', sparse=False)\n"
     ]
    }
   ],
   "source": [
    "ohe = get_one_hot_encoder(names_features_df, \n",
    "        categorical_columns=[n for n in names_features_df.columns if n.startswith(\"last_\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>final_letter_is_vowel</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>last_1_letter_*</th>\n",
       "      <th>last_1_letter_A</th>\n",
       "      <th>last_1_letter_B</th>\n",
       "      <th>last_1_letter_C</th>\n",
       "      <th>last_1_letter_D</th>\n",
       "      <th>last_1_letter_E</th>\n",
       "      <th>last_1_letter_F</th>\n",
       "      <th>last_1_letter_G</th>\n",
       "      <th>last_1_letter_H</th>\n",
       "      <th>last_1_letter_I</th>\n",
       "      <th>last_1_letter_J</th>\n",
       "      <th>...</th>\n",
       "      <th>last_3_letter_ØGG</th>\n",
       "      <th>last_3_letter_ØRG</th>\n",
       "      <th>last_3_letter_ØRK</th>\n",
       "      <th>last_3_letter_ØRN</th>\n",
       "      <th>last_3_letter_ØRT</th>\n",
       "      <th>last_3_letter_ØVE</th>\n",
       "      <th>last_3_letter_ØYA</th>\n",
       "      <th>last_3_letter_ÚLI</th>\n",
       "      <th>last_3_letter_ÚNA</th>\n",
       "      <th>last_3_letter_ÚNI</th>\n",
       "      <th>last_3_letter_ÚSI</th>\n",
       "      <th>last_3_letter_ÚST</th>\n",
       "      <th>last_3_letter_ÝR</th>\n",
       "      <th>last_3_letter_ÞÓR</th>\n",
       "      <th>last_3_letter_ﾘRN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ÖSP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ÞÓRÐUR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EDDA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1867 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  Gender  final_letter_is_vowel  syllable_count  last_1_letter_*  \\\n",
       "0     ÖSP       0                      0               1              0.0   \n",
       "1  ÞÓRÐUR       1                      0               1              0.0   \n",
       "2    EDDA       0                      1               2              0.0   \n",
       "\n",
       "   last_1_letter_A  last_1_letter_B  last_1_letter_C  last_1_letter_D  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              1.0              0.0              0.0              0.0   \n",
       "\n",
       "   last_1_letter_E  last_1_letter_F  last_1_letter_G  last_1_letter_H  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   last_1_letter_I  last_1_letter_J  ...  last_3_letter_ØGG  \\\n",
       "0              0.0              0.0  ...                0.0   \n",
       "1              0.0              0.0  ...                0.0   \n",
       "2              0.0              0.0  ...                0.0   \n",
       "\n",
       "   last_3_letter_ØRG  last_3_letter_ØRK  last_3_letter_ØRN  last_3_letter_ØRT  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   last_3_letter_ØVE  last_3_letter_ØYA  last_3_letter_ÚLI  last_3_letter_ÚNA  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   last_3_letter_ÚNI  last_3_letter_ÚSI  last_3_letter_ÚST  last_3_letter_ÝR  \\\n",
       "0                0.0                0.0                0.0               0.0   \n",
       "1                0.0                0.0                0.0               0.0   \n",
       "2                0.0                0.0                0.0               0.0   \n",
       "\n",
       "   last_3_letter_ÞÓR  last_3_letter_ﾘRN  \n",
       "0                0.0                0.0  \n",
       "1                0.0                0.0  \n",
       "2                0.0                0.0  \n",
       "\n",
       "[3 rows x 1867 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5492"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = names_features_df[[n for n in names_features_df.columns if n.startswith(\"last_\")]]\n",
    "encoded_features = ohe.transform(cat_features)\n",
    "#encoded_features\n",
    "\n",
    "\n",
    "ohe_df = pd.DataFrame(encoded_features, columns=ohe.get_feature_names_out())\n",
    "\n",
    "#ohe_df\n",
    "\n",
    "non_categorical = names_features_df[[n for n in names_features_df.columns if not n.startswith(\"last_\")]]\n",
    "\n",
    "df_transformed = pd.concat([non_categorical, ohe_df], axis=1)\n",
    "df_transformed.head(3)\n",
    "len(df_transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_transformed['Gender']\n",
    "X = df_transformed.drop(columns=['Gender', 'Name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4119, 1865), pandas.core.frame.DataFrame)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((4119,), pandas.core.series.Series)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_letter_is_vowel</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>last_1_letter_*</th>\n",
       "      <th>last_1_letter_A</th>\n",
       "      <th>last_1_letter_B</th>\n",
       "      <th>last_1_letter_C</th>\n",
       "      <th>last_1_letter_D</th>\n",
       "      <th>last_1_letter_E</th>\n",
       "      <th>last_1_letter_F</th>\n",
       "      <th>last_1_letter_G</th>\n",
       "      <th>last_1_letter_H</th>\n",
       "      <th>last_1_letter_I</th>\n",
       "      <th>last_1_letter_J</th>\n",
       "      <th>last_1_letter_K</th>\n",
       "      <th>last_1_letter_L</th>\n",
       "      <th>...</th>\n",
       "      <th>last_3_letter_ØGG</th>\n",
       "      <th>last_3_letter_ØRG</th>\n",
       "      <th>last_3_letter_ØRK</th>\n",
       "      <th>last_3_letter_ØRN</th>\n",
       "      <th>last_3_letter_ØRT</th>\n",
       "      <th>last_3_letter_ØVE</th>\n",
       "      <th>last_3_letter_ØYA</th>\n",
       "      <th>last_3_letter_ÚLI</th>\n",
       "      <th>last_3_letter_ÚNA</th>\n",
       "      <th>last_3_letter_ÚNI</th>\n",
       "      <th>last_3_letter_ÚSI</th>\n",
       "      <th>last_3_letter_ÚST</th>\n",
       "      <th>last_3_letter_ÝR</th>\n",
       "      <th>last_3_letter_ÞÓR</th>\n",
       "      <th>last_3_letter_ﾘRN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4643</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5283</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5305</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4119 rows × 1865 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      final_letter_is_vowel  syllable_count  last_1_letter_*  last_1_letter_A  \\\n",
       "4643                      0               2              0.0              0.0   \n",
       "1934                      1               4              0.0              0.0   \n",
       "3275                      0               1              0.0              0.0   \n",
       "3300                      1               2              0.0              0.0   \n",
       "5283                      0               2              0.0              0.0   \n",
       "...                     ...             ...              ...              ...   \n",
       "1768                      1               3              0.0              0.0   \n",
       "1737                      0               1              0.0              0.0   \n",
       "3240                      0               2              0.0              0.0   \n",
       "5305                      1               2              0.0              0.0   \n",
       "4737                      1               1              0.0              0.0   \n",
       "\n",
       "      last_1_letter_B  last_1_letter_C  last_1_letter_D  last_1_letter_E  \\\n",
       "4643              0.0              0.0              1.0              0.0   \n",
       "1934              0.0              0.0              0.0              0.0   \n",
       "3275              0.0              0.0              0.0              0.0   \n",
       "3300              0.0              0.0              0.0              0.0   \n",
       "5283              0.0              0.0              1.0              0.0   \n",
       "...               ...              ...              ...              ...   \n",
       "1768              0.0              0.0              0.0              1.0   \n",
       "1737              0.0              0.0              0.0              0.0   \n",
       "3240              0.0              0.0              0.0              0.0   \n",
       "5305              0.0              0.0              0.0              0.0   \n",
       "4737              0.0              0.0              0.0              1.0   \n",
       "\n",
       "      last_1_letter_F  last_1_letter_G  last_1_letter_H  last_1_letter_I  \\\n",
       "4643              0.0              0.0              0.0              0.0   \n",
       "1934              0.0              0.0              0.0              0.0   \n",
       "3275              0.0              0.0              0.0              0.0   \n",
       "3300              0.0              0.0              0.0              1.0   \n",
       "5283              0.0              0.0              0.0              0.0   \n",
       "...               ...              ...              ...              ...   \n",
       "1768              0.0              0.0              0.0              0.0   \n",
       "1737              0.0              0.0              1.0              0.0   \n",
       "3240              0.0              0.0              0.0              0.0   \n",
       "5305              0.0              0.0              0.0              0.0   \n",
       "4737              0.0              0.0              0.0              0.0   \n",
       "\n",
       "      last_1_letter_J  last_1_letter_K  last_1_letter_L  ...  \\\n",
       "4643              0.0              0.0              0.0  ...   \n",
       "1934              0.0              0.0              0.0  ...   \n",
       "3275              0.0              0.0              0.0  ...   \n",
       "3300              0.0              0.0              0.0  ...   \n",
       "5283              0.0              0.0              0.0  ...   \n",
       "...               ...              ...              ...  ...   \n",
       "1768              0.0              0.0              0.0  ...   \n",
       "1737              0.0              0.0              0.0  ...   \n",
       "3240              0.0              0.0              0.0  ...   \n",
       "5305              0.0              0.0              0.0  ...   \n",
       "4737              0.0              0.0              0.0  ...   \n",
       "\n",
       "      last_3_letter_ØGG  last_3_letter_ØRG  last_3_letter_ØRK  \\\n",
       "4643                0.0                0.0                0.0   \n",
       "1934                0.0                0.0                0.0   \n",
       "3275                0.0                0.0                0.0   \n",
       "3300                0.0                0.0                0.0   \n",
       "5283                0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "1768                0.0                0.0                0.0   \n",
       "1737                0.0                0.0                0.0   \n",
       "3240                0.0                0.0                0.0   \n",
       "5305                0.0                0.0                0.0   \n",
       "4737                0.0                0.0                0.0   \n",
       "\n",
       "      last_3_letter_ØRN  last_3_letter_ØRT  last_3_letter_ØVE  \\\n",
       "4643                0.0                0.0                0.0   \n",
       "1934                0.0                0.0                0.0   \n",
       "3275                0.0                0.0                0.0   \n",
       "3300                0.0                0.0                0.0   \n",
       "5283                0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "1768                0.0                0.0                0.0   \n",
       "1737                0.0                0.0                0.0   \n",
       "3240                0.0                0.0                0.0   \n",
       "5305                0.0                0.0                0.0   \n",
       "4737                0.0                0.0                0.0   \n",
       "\n",
       "      last_3_letter_ØYA  last_3_letter_ÚLI  last_3_letter_ÚNA  \\\n",
       "4643                0.0                0.0                0.0   \n",
       "1934                0.0                0.0                0.0   \n",
       "3275                0.0                0.0                0.0   \n",
       "3300                0.0                0.0                0.0   \n",
       "5283                0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "1768                0.0                0.0                0.0   \n",
       "1737                0.0                0.0                0.0   \n",
       "3240                0.0                0.0                0.0   \n",
       "5305                0.0                0.0                0.0   \n",
       "4737                0.0                0.0                0.0   \n",
       "\n",
       "      last_3_letter_ÚNI  last_3_letter_ÚSI  last_3_letter_ÚST  \\\n",
       "4643                0.0                0.0                0.0   \n",
       "1934                0.0                0.0                0.0   \n",
       "3275                0.0                0.0                0.0   \n",
       "3300                0.0                0.0                0.0   \n",
       "5283                0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "1768                0.0                0.0                0.0   \n",
       "1737                0.0                0.0                0.0   \n",
       "3240                0.0                0.0                0.0   \n",
       "5305                0.0                0.0                0.0   \n",
       "4737                0.0                0.0                0.0   \n",
       "\n",
       "      last_3_letter_ÝR  last_3_letter_ÞÓR  last_3_letter_ﾘRN  \n",
       "4643               0.0                0.0                0.0  \n",
       "1934               0.0                0.0                0.0  \n",
       "3275               0.0                0.0                0.0  \n",
       "3300               0.0                0.0                0.0  \n",
       "5283               0.0                0.0                0.0  \n",
       "...                ...                ...                ...  \n",
       "1768               0.0                0.0                0.0  \n",
       "1737               0.0                0.0                0.0  \n",
       "3240               0.0                0.0                0.0  \n",
       "5305               0.0                0.0                0.0  \n",
       "4737               0.0                0.0                0.0  \n",
       "\n",
       "[4119 rows x 1865 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, type(X_train)\n",
    "y_train.shape, type(y_train)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting auto-sklearn\n",
      "  Downloading auto-sklearn-0.14.2.tar.gz (6.3 MB)\n",
      "     |████████████████████████████████| 6.3 MB 4.3 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/eirik.stavelin/.pyenv/versions/3.9.0/lib/python3.9/site-packages (from auto-sklearn) (53.0.0)\n",
      "Requirement already satisfied: typing_extensions in /Users/eirik.stavelin/.pyenv/versions/3.9.0/lib/python3.9/site-packages (from auto-sklearn) (3.7.4.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /Users/eirik.stavelin/.pyenv/versions/3.9.0/lib/python3.9/site-packages (from auto-sklearn) (1.19.5)\n",
      "Collecting scipy>=1.7.0\n",
      "  Downloading scipy-1.7.3-cp39-cp39-macosx_10_9_x86_64.whl (33.2 MB)\n",
      "     |████████████████████████████████| 33.2 MB 5.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: joblib in /Users/eirik.stavelin/.pyenv/versions/3.9.0/lib/python3.9/site-packages (from auto-sklearn) (0.17.0)\n",
      "Collecting scikit-learn<0.25.0,>=0.24.0\n",
      "  Downloading scikit_learn-0.24.2-cp39-cp39-macosx_10_13_x86_64.whl (7.3 MB)\n",
      "     |████████████████████████████████| 7.3 MB 49.7 MB/s            \n",
      "\u001b[?25hCollecting dask<2021.07\n",
      "  Downloading dask-2021.6.2-py3-none-any.whl (973 kB)\n",
      "     |████████████████████████████████| 973 kB 7.1 MB/s            \n",
      "\u001b[?25hCollecting distributed<2021.07,>=2.2.0\n",
      "  Downloading distributed-2021.6.2-py3-none-any.whl (722 kB)\n",
      "     |████████████████████████████████| 722 kB 9.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /Users/eirik.stavelin/.pyenv/versions/3.9.0/lib/python3.9/site-packages (from auto-sklearn) (5.3.1)\n",
      "Requirement already satisfied: pandas>=1.0 in /Users/eirik.stavelin/.pyenv/versions/3.9.0/lib/python3.9/site-packages (from auto-sklearn) (1.3.2)\n",
      "Collecting liac-arff\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl in /Users/eirik.stavelin/.pyenv/versions/3.9.0/lib/python3.9/site-packages (from auto-sklearn) (2.1.0)\n",
      "Collecting ConfigSpace<0.5,>=0.4.14\n",
      "  Downloading ConfigSpace-0.4.20.tar.gz (103 kB)\n",
      "     |████████████████████████████████| 103 kB 12.1 MB/s            \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pynisher>=0.6.3\n",
      "  Downloading pynisher-0.6.4.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyrfr<0.9,>=0.8.1\n",
      "  Downloading pyrfr-0.8.2.tar.gz (296 kB)\n",
      "     |████████████████████████████████| 296 kB 6.5 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting smac>=0.14\n",
      "  Downloading smac-1.1.1-py3-none-any.whl (208 kB)\n",
      "     |████████████████████████████████| 208 kB 6.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pyparsing in /Users/eirik.stavelin/.pyenv/versions/3.9.0/lib/python3.9/site-packages (from ConfigSpace<0.5,>=0.4.14->auto-sklearn) (2.4.7)\n",
      "Requirement already satisfied: cython in /Users/eirik.stavelin/.pyenv/versions/3.9.0/lib/python3.9/site-packages (from ConfigSpace<0.5,>=0.4.14->auto-sklearn) (0.29.24)\n",
      "Collecting fsspec>=0.6.0\n",
      "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
      "     |████████████████████████████████| 132 kB 9.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: toolz>=0.8.2 in /Users/eirik.stavelin/.pyenv/versions/3.9.0/lib/python3.9/site-packages (from dask<2021.07->auto-sklearn) (0.11.1)\n",
      "Collecting partd>=0.3.10\n",
      "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
      "Collecting cloudpickle>=1.1.1\n",
      "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /Users/eirik.stavelin/.pyenv/versions/3.9.0/lib/python3.9/site-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (6.1)\n",
      "Collecting tblib>=1.6.0\n",
      "  Downloading tblib-1.7.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /Users/eirik.stavelin/.pyenv/versions/3.9.0/lib/python3.9/site-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (2.3.0)\n",
      "Collecting zict>=0.1.3\n",
      "  Downloading zict-2.0.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /Users/eirik.stavelin/.pyenv/versions/3.9.0/lib/python3.9/site-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (1.0.2)\n",
      "Requirement already satisfied: click>=6.6 in /Users/eirik.stavelin/.pyenv/versions/3.9.0/lib/python3.9/site-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (7.1.2)\n",
      "Collecting psutil>=5.0\n",
      "  Downloading psutil-5.8.0-cp39-cp39-macosx_10_9_x86_64.whl (236 kB)\n",
      "     |████████████████████████████████| 236 kB 7.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /Users/eirik.stavelin/.pyenv/versions/3.9.0/lib/python3.9/site-packages (from pandas>=1.0->auto-sklearn) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/eirik.stavelin/.pyenv/versions/3.9.0/lib/python3.9/site-packages (from pandas>=1.0->auto-sklearn) (2020.4)\n",
      "Collecting emcee>=3.0.0\n",
      "  Downloading emcee-3.1.1-py2.py3-none-any.whl (45 kB)\n",
      "     |████████████████████████████████| 45 kB 591 kB/s            \n",
      "\u001b[?25hCollecting locket\n",
      "  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/eirik.stavelin/.pyenv/versions/3.9.0/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas>=1.0->auto-sklearn) (1.15.0)\n",
      "Collecting heapdict\n",
      "  Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
      "Building wheels for collected packages: auto-sklearn, ConfigSpace, pynisher, pyrfr, liac-arff\n",
      "  Building wheel for auto-sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for auto-sklearn: filename=auto_sklearn-0.14.2-py3-none-any.whl size=6586720 sha256=af8a2eb241a117b8d5c2d638f9bb5849d419ca0c8b465cdb6575e072d42ce2f0\n",
      "  Stored in directory: /Users/eirik.stavelin/Library/Caches/pip/wheels/2d/b9/02/17cd0c9b059819624bbb8c8cdf323c20b308f8ba1315ec577e\n",
      "  Building wheel for ConfigSpace (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ConfigSpace: filename=ConfigSpace-0.4.20-cp39-cp39-macosx_11_0_x86_64.whl size=872212 sha256=8c30ebcb1650f578248d7c887dc61eb96690301761397b621e6a8ba8de93aaf5\n",
      "  Stored in directory: /Users/eirik.stavelin/Library/Caches/pip/wheels/15/d5/43/fc6fe722533cd0ee074333e72d0e0444926cc092098d0ac791\n",
      "  Building wheel for pynisher (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pynisher: filename=pynisher-0.6.4-py3-none-any.whl size=7043 sha256=0a39aa8888ef282416cd9bcffda8fb185af00dde6d2ebdafd8829e868bbb2b73\n",
      "  Stored in directory: /Users/eirik.stavelin/Library/Caches/pip/wheels/1d/de/5e/d4947b76b76ba27581d1e09f395eca1583a802203a41c04873\n",
      "  Building wheel for pyrfr (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /Users/eirik.stavelin/.pyenv/versions/3.9.0/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/2j/_qstblw53_nfl5m_2_74hk580000gn/T/pip-install-cdc65nb4/pyrfr_fbccd66ff1b94ea39bb10e2df971f46b/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/2j/_qstblw53_nfl5m_2_74hk580000gn/T/pip-install-cdc65nb4/pyrfr_fbccd66ff1b94ea39bb10e2df971f46b/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /private/var/folders/2j/_qstblw53_nfl5m_2_74hk580000gn/T/pip-wheel-zsg76dnr\n",
      "       cwd: /private/var/folders/2j/_qstblw53_nfl5m_2_74hk580000gn/T/pip-install-cdc65nb4/pyrfr_fbccd66ff1b94ea39bb10e2df971f46b/\n",
      "  Complete output (7 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  building 'pyrfr._regression' extension\n",
      "  swigging pyrfr/regression.i to pyrfr/regression_wrap.cpp\n",
      "  swig -python -c++ -modern -py3 -features nondynamic -I./include -o pyrfr/regression_wrap.cpp pyrfr/regression.i\n",
      "  error: command 'swig' failed: No such file or directory\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for pyrfr\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for pyrfr\n",
      "  Building wheel for liac-arff (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11731 sha256=5b29e2ceaadd30a63f99cfd8339657e8b54f8eb0dfb6564b5af69dad3cf8e844\n",
      "  Stored in directory: /Users/eirik.stavelin/Library/Caches/pip/wheels/08/82/8b/5c514221984e88c059b94e36a71d4722e590acaae04deab22e\n",
      "Successfully built auto-sklearn ConfigSpace pynisher liac-arff\n",
      "Failed to build pyrfr\n",
      "Installing collected packages: locket, partd, heapdict, fsspec, cloudpickle, zict, tblib, scipy, psutil, dask, scikit-learn, pyrfr, pynisher, emcee, distributed, ConfigSpace, smac, liac-arff, auto-sklearn\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.4\n",
      "    Uninstalling scipy-1.5.4:\n",
      "      Successfully uninstalled scipy-1.5.4\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0.1\n",
      "    Uninstalling scikit-learn-1.0.1:\n",
      "      Successfully uninstalled scikit-learn-1.0.1\n",
      "    Running setup.py install for pyrfr ... \u001b[?25lerror\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Users/eirik.stavelin/.pyenv/versions/3.9.0/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/2j/_qstblw53_nfl5m_2_74hk580000gn/T/pip-install-cdc65nb4/pyrfr_fbccd66ff1b94ea39bb10e2df971f46b/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/2j/_qstblw53_nfl5m_2_74hk580000gn/T/pip-install-cdc65nb4/pyrfr_fbccd66ff1b94ea39bb10e2df971f46b/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/2j/_qstblw53_nfl5m_2_74hk580000gn/T/pip-record-brokrz4u/install-record.txt --single-version-externally-managed --compile --install-headers /Users/eirik.stavelin/.pyenv/versions/3.9.0/include/python3.9/pyrfr\n",
      "         cwd: /private/var/folders/2j/_qstblw53_nfl5m_2_74hk580000gn/T/pip-install-cdc65nb4/pyrfr_fbccd66ff1b94ea39bb10e2df971f46b/\n",
      "    Complete output (6 lines):\n",
      "    running install\n",
      "    running build_ext\n",
      "    building 'pyrfr._regression' extension\n",
      "    swigging pyrfr/regression.i to pyrfr/regression_wrap.cpp\n",
      "    swig -python -c++ -modern -py3 -features nondynamic -I./include -o pyrfr/regression_wrap.cpp pyrfr/regression.i\n",
      "    error: command 'swig' failed: No such file or directory\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Command errored out with exit status 1: /Users/eirik.stavelin/.pyenv/versions/3.9.0/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/2j/_qstblw53_nfl5m_2_74hk580000gn/T/pip-install-cdc65nb4/pyrfr_fbccd66ff1b94ea39bb10e2df971f46b/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/2j/_qstblw53_nfl5m_2_74hk580000gn/T/pip-install-cdc65nb4/pyrfr_fbccd66ff1b94ea39bb10e2df971f46b/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/2j/_qstblw53_nfl5m_2_74hk580000gn/T/pip-record-brokrz4u/install-record.txt --single-version-externally-managed --compile --install-headers /Users/eirik.stavelin/.pyenv/versions/3.9.0/include/python3.9/pyrfr Check the logs for full command output.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install auto-sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looks like autosklearn i linux only..\n",
    "https://automl.github.io/auto-sklearn/master/installation.html#windows-osx-compatibility\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autosklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0268b5f5050c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mautosklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autosklearn'"
     ]
    }
   ],
   "source": [
    "\n",
    "import autosklearn.classification\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "\n",
    "options = {\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(**options)\n",
    "automl.fit(X_train, y_train)\n",
    "predictions = automl.predict(X_val)\n",
    "print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_val, predictions))\n",
    "\n",
    "\n",
    "# from tpot import TPOTClassifier\n",
    "# config = {\n",
    "#     'generations': 5,\n",
    "#     'population_size': 20, \n",
    "#     'cv': 5,\n",
    "#     'random_state': 42, \n",
    "#     'verbosity': 2, \n",
    "#     'n_jobs': -1,\n",
    "#     'log_file': 'nlp_tpot.log',\n",
    "#     'early_stop': 5,\n",
    "#     'warm_start': True\n",
    "# }\n",
    "\n",
    "# pipeline_optimizer = TPOTClassifier(**config)\n",
    "\n",
    "\n",
    "# pipeline_optimizer.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Female'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-cf53a803880d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# look at results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpipeline_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tpot_exported_pipeline.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/tpot/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, testing_features, testing_target)\u001b[0m\n\u001b[1;32m   1105\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitted_pipeline_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0mtesting_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             \u001b[0mtesting_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m         )\n\u001b[1;32m   1109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5813\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5814\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5815\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5816\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     def convert(\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_coerce_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m   1255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[0;31m# in pandas we don't store numpy str dtypes, so convert to object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;31m# Explicit copy, or required since NumPy can't view from / to object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Female'"
     ]
    }
   ],
   "source": [
    "# look at results\n",
    "print(pipeline_optimizer.score(X_val, y_val))\n",
    "\n",
    "pipeline_optimizer.export('tpot_exported_pipeline.py')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5505.706330776215"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<flaml.model.LRL1Classifier at 0x173401310>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.188212062465053, n_jobs=-1, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[567, 116],\n",
       "       [ 80, 614]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'85_77'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85       683\n",
      "           1       0.84      0.88      0.86       694\n",
      "\n",
      "    accuracy                           0.86      1377\n",
      "   macro avg       0.86      0.86      0.86      1377\n",
      "weighted avg       0.86      0.86      0.86      1377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Time to find best model (in seconds)\n",
    "automl.time_to_find_best_model\n",
    "\n",
    "# Inspect the best model\n",
    "automl.model\n",
    "\n",
    "# look at estimator\n",
    "automl.model.estimator\n",
    "\n",
    "\n",
    "flaml_pred = automl.predict(X_val)\n",
    "# Inspect the confusion matrix\n",
    "#automl.model.score(X_val, y_val)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_val, flaml_pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = str(round(accuracy_score(y_val, flaml_pred)*100, 2)).replace(\".\", \"_\")\n",
    "acc\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_val, flaml_pred, target_names=['0','1']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lightgbm.sklearn.LGBMClassifier"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(automl.model.estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pickle and save the automl object'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'load pickled automl object'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.88968269, 0.01040234, 0.93063584, ..., 0.93415222, 0.48430457,\n",
       "       0.11718994])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "time_used = automl_settings.get('time_budget', 'unknown_time')\n",
    "model_name = automl.model.estimator.__class__.__name__\n",
    "\n",
    "file_name = f'data/automl_{model_name}_{time_used}_s_acs_{acc}.pkl'\n",
    "'''pickle and save the automl object'''\n",
    "import pickle\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(automl, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "'''load pickled automl object'''\n",
    "with open(file_name, 'rb') as f:\n",
    "    automl = pickle.load(f)\n",
    "\n",
    "automl.predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature1 = generate_language_features(pd.DataFrame([\"Eirik\"], columns=[\"Name\"]))\n",
    "\n",
    "# her trenger jeg features slik mine egne funksjoner har definert det:\n",
    "# 1 gen features\n",
    "# 2 ohe på kategorisk varabler\n",
    "# drop navn\n",
    "\n",
    "#automl.predict_proba(feature1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "class Debug(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def transform(self, X):\n",
    "        print(\"Debug transform\")\n",
    "        print(X)\n",
    "        print(pd.DataFrame(X).head())\n",
    "        print(X.shape)\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Index dimension must be <= 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-300-9370aa7a89e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# apply the pipeline to the input dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \"\"\"\n\u001b[1;32m    425\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mlast_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    349\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-300-9370aa7a89e0>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input_df, **transform_params)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtransform_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-205-93239e58f23a>\u001b[0m in \u001b[0;36mgenerate_language_features\u001b[0;34m(df, col, verbose)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'final_letter_is_vowel'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AEIOUYÆØÅ'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Dispatch to specialized methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINT_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m_validate_indices\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mrow\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_asindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misintlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m_asindices\u001b[0;34m(self, idx, length)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Index dimension must be <= 2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Index dimension must be <= 2"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class DataframeFunctionTransformer():\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        return self.func(input_df)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "def drop_cols(input_df, cols=['Name', 'Gender']):\n",
    "    # for col in cols:\n",
    "    #     if col in input_df:\n",
    "    #         input_df.drop()\n",
    "    input_df.drop(labels = cols, axis=1, errors='ignore', inplace=True)\n",
    "    # input_df[\"text\"] = input_df[\"text\"].map(lambda t: t.upper())\n",
    "    return input_df\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"one_hot\", OneHotEncoder(handle_unknown=\"ignore\"), [\"last_1_letter\", \"last_2_letter\", \"last_3_letter\"]),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "# this pipeline has a single step\n",
    "pipeline = Pipeline(\n",
    "    verbose=True,\n",
    "    steps=[\n",
    "    (\"generate_features\", DataframeFunctionTransformer(generate_language_features)),\n",
    "   (\"drop_cols\", DataframeFunctionTransformer(drop_cols)),\n",
    "   # ('dbg', Debug()),\n",
    "    (\"ohe_cat_variables\", preprocessor)\n",
    "    # ,\n",
    "    # (\"model\", lgb.LGBMClassifier(colsample_bytree=0.5205191706285026, learning_rate=1.0,\n",
    "    #            max_bin=511, min_child_samples=2, n_estimators=42, num_leaves=10,\n",
    "    #            reg_alpha=0.0922808777931273, reg_lambda=0.0009765625,\n",
    "    #            verbose=-1))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# # sample dataframe\n",
    "# df = pd.DataFrame({\n",
    "#    # \"id\":[1,2,3,4],\n",
    "#     \"Name\":[\"Eirik\",\"Bar\",\"BAz\",\"quux\"]\n",
    "# })\n",
    "\n",
    "# apply the pipeline to the input dataframe\n",
    "_ = pipeline.fit_transform(X_train.copy())\n",
    "print(\"What?\")\n",
    "_.shape\n",
    "\n",
    "\n",
    "\n",
    "print(\"Transform someting:\")\n",
    "pipeline[-1].get_feature_names_out()\n",
    "print(pipeline.transform(pd.DataFrame({'Name': ['Eirik', 'Ingeridene']})))\n",
    "\n",
    "pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pickle and save the automl object'"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'load pickled automl object'"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one_hot__last_1_letter_A</th>\n",
       "      <th>one_hot__last_1_letter_B</th>\n",
       "      <th>one_hot__last_1_letter_C</th>\n",
       "      <th>one_hot__last_1_letter_D</th>\n",
       "      <th>one_hot__last_1_letter_E</th>\n",
       "      <th>one_hot__last_1_letter_F</th>\n",
       "      <th>one_hot__last_1_letter_G</th>\n",
       "      <th>one_hot__last_1_letter_H</th>\n",
       "      <th>one_hot__last_1_letter_I</th>\n",
       "      <th>one_hot__last_1_letter_J</th>\n",
       "      <th>one_hot__last_1_letter_K</th>\n",
       "      <th>one_hot__last_1_letter_L</th>\n",
       "      <th>one_hot__last_1_letter_M</th>\n",
       "      <th>one_hot__last_1_letter_N</th>\n",
       "      <th>one_hot__last_1_letter_O</th>\n",
       "      <th>...</th>\n",
       "      <th>one_hot__last_3_letter_ØRG</th>\n",
       "      <th>one_hot__last_3_letter_ØRK</th>\n",
       "      <th>one_hot__last_3_letter_ØRN</th>\n",
       "      <th>one_hot__last_3_letter_ØRT</th>\n",
       "      <th>one_hot__last_3_letter_ØVE</th>\n",
       "      <th>one_hot__last_3_letter_ØYA</th>\n",
       "      <th>one_hot__last_3_letter_ÚLI</th>\n",
       "      <th>one_hot__last_3_letter_ÚNA</th>\n",
       "      <th>one_hot__last_3_letter_ÚNI</th>\n",
       "      <th>one_hot__last_3_letter_ÚSI</th>\n",
       "      <th>one_hot__last_3_letter_ÚST</th>\n",
       "      <th>one_hot__last_3_letter_ÝR</th>\n",
       "      <th>one_hot__last_3_letter_ÞÓR</th>\n",
       "      <th>remainder__final_letter_is_vowel</th>\n",
       "      <th>remainder__syllable_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1652 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   one_hot__last_1_letter_A  one_hot__last_1_letter_B  \\\n",
       "0                       0.0                       0.0   \n",
       "\n",
       "   one_hot__last_1_letter_C  one_hot__last_1_letter_D  \\\n",
       "0                       0.0                       0.0   \n",
       "\n",
       "   one_hot__last_1_letter_E  one_hot__last_1_letter_F  \\\n",
       "0                       0.0                       0.0   \n",
       "\n",
       "   one_hot__last_1_letter_G  one_hot__last_1_letter_H  \\\n",
       "0                       0.0                       0.0   \n",
       "\n",
       "   one_hot__last_1_letter_I  one_hot__last_1_letter_J  \\\n",
       "0                       0.0                       0.0   \n",
       "\n",
       "   one_hot__last_1_letter_K  one_hot__last_1_letter_L  \\\n",
       "0                       1.0                       0.0   \n",
       "\n",
       "   one_hot__last_1_letter_M  one_hot__last_1_letter_N  \\\n",
       "0                       0.0                       0.0   \n",
       "\n",
       "   one_hot__last_1_letter_O  ...  one_hot__last_3_letter_ØRG  \\\n",
       "0                       0.0  ...                         0.0   \n",
       "\n",
       "   one_hot__last_3_letter_ØRK  one_hot__last_3_letter_ØRN  \\\n",
       "0                         0.0                         0.0   \n",
       "\n",
       "   one_hot__last_3_letter_ØRT  one_hot__last_3_letter_ØVE  \\\n",
       "0                         0.0                         0.0   \n",
       "\n",
       "   one_hot__last_3_letter_ØYA  one_hot__last_3_letter_ÚLI  \\\n",
       "0                         0.0                         0.0   \n",
       "\n",
       "   one_hot__last_3_letter_ÚNA  one_hot__last_3_letter_ÚNI  \\\n",
       "0                         0.0                         0.0   \n",
       "\n",
       "   one_hot__last_3_letter_ÚSI  one_hot__last_3_letter_ÚST  \\\n",
       "0                         0.0                         0.0   \n",
       "\n",
       "   one_hot__last_3_letter_ÝR  one_hot__last_3_letter_ÞÓR  \\\n",
       "0                        0.0                         0.0   \n",
       "\n",
       "   remainder__final_letter_is_vowel  remainder__syllable_count  \n",
       "0                               0.0                        1.0  \n",
       "\n",
       "[1 rows x 1652 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = f'data/_pickled2_pipe.pkl'\n",
    "'''pickle and save the automl object'''\n",
    "import pickle\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(pipeline, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "'''load pickled automl object'''\n",
    "with open(file_name, 'rb') as f:\n",
    "    pipeline = pickle.load(f)\n",
    "\n",
    "\n",
    "# test\n",
    "pd.DataFrame.sparse.from_spmatrix(\n",
    "    pipeline.transform(pd.DataFrame({\"Name\": [\"Eirik\"]})), \n",
    "    columns=pipeline[2].get_feature_names_out()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Gender]\n",
       "Index: []"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(5505, 1)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(5505, 1652)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['one_hot__last_1_letter_A', 'one_hot__last_1_letter_B',\n",
       "       'one_hot__last_1_letter_C', ..., 'one_hot__last_3_letter_ÞÓR',\n",
       "       'remainder__final_letter_is_vowel', 'remainder__syllable_count'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = load_gendered_names()\n",
    "y = df['Gender']\n",
    "X = df.drop(columns=['Gender'])\n",
    "\n",
    "df[X.duplicated()] # I get duplicates when the names and gender gets dropped. That is prob a problem.\n",
    "\n",
    "# tmp enrich data using pipeline\n",
    "X.shape\n",
    "X_train_transformed = pipeline.transform(X)\n",
    "X_train_transformed.shape\n",
    "\n",
    "# Test\n",
    "#test = pd.DataFrame.sparse.from_spmatrix(\n",
    "#    X_train_transformed, \n",
    "#    columns=pipeline[2].get_feature_names_out()\n",
    "#    )\n",
    "#test['Gender'] = df['Gender']\n",
    "#test['Name'] = df['Name']\n",
    "#test\n",
    "pipeline[2].get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4128, 1652)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# split data\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=99)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_transformed, y, random_state=99)\n",
    "X_train.shape\n",
    "type(X_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "4123    False\n",
       "4124     True\n",
       "4125     True\n",
       "4126     True\n",
       "4127     True\n",
       "Length: 4128, dtype: bool"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4128, 1652)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4128,)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df = pd.DataFrame.sparse.from_spmatrix(\n",
    "   X_train, \n",
    "   columns=pipeline[2].get_feature_names_out()\n",
    "   ).reindex()\n",
    "#X_train_df\n",
    "type(X_train_df)\n",
    "X_train_df.shape\n",
    "type(y_train)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-292-330f05a622da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Fit the models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mautoml_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/flaml/automl.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, dataframe, label, metric, task, n_jobs, log_file_name, estimator_list, time_budget, max_iter, sample, ensemble, eval_method, log_type, model_history, split_ratio, n_splits, log_training_metric, mem_thres, pred_time_limit, train_time_limit, X_val, y_val, sample_weight_val, groups_val, groups, verbose, retrain_full, split_type, learner_selector, hpo_method, starting_points, seed, n_concurrent_trials, keep_search_state, early_stop, append_log, auto_augment, min_sample_size, use_ray, **fit_kwargs)\u001b[0m\n\u001b[1;32m   1464\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m         self._validate_data(\n\u001b[0m\u001b[1;32m   1467\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m         )\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/flaml/automl.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X_train_all, y_train_all, dataframe, label, X_val, y_val, groups_val, groups)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m             self._X_train_all, self._y_train_all = self._transformer.fit_transform(\n\u001b[0m\u001b[1;32m    559\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             )\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/flaml/data.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, task)\u001b[0m\n\u001b[1;32m    315\u001b[0m                     ]\n\u001b[1;32m    316\u001b[0m                 )\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_columns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m             self._cat_columns, self._num_columns, self._datetime_columns = (\n\u001b[1;32m    319\u001b[0m                 \u001b[0mcat_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3595\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3596\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3597\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3598\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3599\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3646\u001b[0m                 \u001b[0;31m# list of lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3647\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3650\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3642\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3643\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iset_not_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3645\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_iset_not_inplace\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3668\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3669\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3670\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Columns must be same length as key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3672\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# what model should I choose?\n",
    "\n",
    "# Initialize an AutoML instance\n",
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "\n",
    "automl_settings = {\n",
    "    \"time_budget\": 2000,  # in seconds (This will train for 10 minutes) 3600=1h\n",
    "    \"metric\": 'macro_f1',\n",
    "    \"task\": 'classification',\n",
    "    \"log_file_name\": \"nlp.log\",\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Fit the models\n",
    "automl.fit(X_train=X_train_df, y_train=y_train, verbose=1, **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still hard. let's see if https://github.com/scikit-learn-contrib/sklearn-pandas \n",
    "# can make this easier..\n",
    "\n",
    "#df = pd.DataFrame({\n",
    "#    \"id\":[1,2,3,4],\n",
    "#    \"Name\":[\"Eirik\",\"Bar\",\"BAz\",\"quux\"]\n",
    "#})\n",
    "#from sklearn_pandas import DataFrameMapper, gen_features\n",
    "#\n",
    "#\n",
    "#class GetColumnsStartingWith:\n",
    "#>    def __init__(self, start_str):\n",
    " #       self.pattern = start_str\n",
    "#\n",
    "#    def __call__(self, X:pd.DataFrame=None):\n",
    "#        return [c for c in X.columns if c.startswith(self.pattern)]\n",
    "#\n",
    "#mapper = DataFrameMapper([\n",
    "#     #gen_features(columns=[\"Name\"], classes=[generate_language_features], )\n",
    "#     ('Name', DataframeFunctionTransformer(generate_language_features), {''}) #,\n",
    "#     #(GetColumnsStartingWith(\"last_\"),  OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "# ])\n",
    "\n",
    "\n",
    "# df\n",
    "# mapper.fit_transform(df)\n",
    "\n",
    "\n",
    "# not easier, because the DataFrameMapper seems to always expect us to work col-by-col\n",
    "# so the feature generation does not fit into this, and I end up with yet-another thing thats\n",
    "# need to be pickled with the model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0e2ea01bd33f26cc744c5ad7e2be103241be5e8a6903fb841a3bd29e21386e2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('3.9.0': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
