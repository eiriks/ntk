{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>final_letter_is_vowel</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>last_1_letter</th>\n",
       "      <th>last_2_letter</th>\n",
       "      <th>last_3_letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EIRIK</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>K</td>\n",
       "      <td>IK</td>\n",
       "      <td>RIK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EIRIKA</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>KA</td>\n",
       "      <td>IKA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  final_letter_is_vowel  syllable_count last_1_letter last_2_letter  \\\n",
       "0   EIRIK                      0               1             K            IK   \n",
       "1  EIRIKA                      1               2             A            KA   \n",
       "\n",
       "  last_3_letter  \n",
       "0           RIK  \n",
       "1           IKA  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aux_functions import generate_language_features\n",
    "\n",
    "_ = generate_language_features(pd.DataFrame([\"Eirik\", \"Eirika\"], columns=[\"Name\"]))\n",
    "_.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder(handle_unknown='ignore', sparse=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def get_one_hot_encoder(df, \n",
    "                categorical_columns = ['last_1_letter',\t'last_2_letter', 'last_3_letter']\n",
    "                ):\n",
    "    encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)    \n",
    "    encoder.fit(df[categorical_columns])\n",
    "    print(encoder)\n",
    "    \n",
    "    return encoder\n",
    "\n",
    "encoder = get_one_hot_encoder(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names goes in, this comes out:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>final_letter_is_vowel</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>last_1_letter</th>\n",
       "      <th>last_2_letter</th>\n",
       "      <th>last_3_letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EIRIK</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>K</td>\n",
       "      <td>IK</td>\n",
       "      <td>RIK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EIRIKA</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>KA</td>\n",
       "      <td>IKA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  final_letter_is_vowel  syllable_count last_1_letter last_2_letter  \\\n",
       "0   EIRIK                      0               1             K            IK   \n",
       "1  EIRIKA                      1               2             A            KA   \n",
       "\n",
       "  last_3_letter  \n",
       "0           RIK  \n",
       "1           IKA  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder transformed\n",
      "[[0. 1. 1. 0. 0. 1.]\n",
      " [1. 0. 0. 1. 1. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['last_1_letter_A', 'last_1_letter_K', 'last_2_letter_IK',\n",
       "       'last_2_letter_KA', 'last_3_letter_IKA', 'last_3_letter_RIK'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_1_letter_A</th>\n",
       "      <th>last_1_letter_K</th>\n",
       "      <th>last_2_letter_IK</th>\n",
       "      <th>last_2_letter_KA</th>\n",
       "      <th>last_3_letter_IKA</th>\n",
       "      <th>last_3_letter_RIK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   last_1_letter_A  last_1_letter_K  last_2_letter_IK  last_2_letter_KA  \\\n",
       "0              0.0              1.0               1.0               0.0   \n",
       "1              1.0              0.0               0.0               1.0   \n",
       "\n",
       "   last_3_letter_IKA  last_3_letter_RIK  \n",
       "0                0.0                1.0  \n",
       "1                1.0                0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>final_letter_is_vowel</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>last_1_letter</th>\n",
       "      <th>last_2_letter</th>\n",
       "      <th>last_3_letter</th>\n",
       "      <th>last_1_letter_A</th>\n",
       "      <th>last_1_letter_K</th>\n",
       "      <th>last_2_letter_IK</th>\n",
       "      <th>last_2_letter_KA</th>\n",
       "      <th>last_3_letter_IKA</th>\n",
       "      <th>last_3_letter_RIK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EIRIK</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>K</td>\n",
       "      <td>IK</td>\n",
       "      <td>RIK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EIRIKA</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>KA</td>\n",
       "      <td>IKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  final_letter_is_vowel  syllable_count last_1_letter last_2_letter  \\\n",
       "0   EIRIK                      0               1             K            IK   \n",
       "1  EIRIKA                      1               2             A            KA   \n",
       "\n",
       "  last_3_letter  last_1_letter_A  last_1_letter_K  last_2_letter_IK  \\\n",
       "0           RIK              0.0              1.0               1.0   \n",
       "1           IKA              1.0              0.0               0.0   \n",
       "\n",
       "   last_2_letter_KA  last_3_letter_IKA  last_3_letter_RIK  \n",
       "0               0.0                0.0                1.0  \n",
       "1               1.0                1.0                0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"Names goes in, this comes out:\")\n",
    "nuff = generate_language_features(pd.DataFrame([\"Eirik\", \"Eirika\"], columns=[\"Name\"]))#.drop(['Name'],axis=1)\n",
    "nuff.head()\n",
    "\n",
    "ohe = encoder.transform(nuff[['last_1_letter',\t'last_2_letter', 'last_3_letter']])\n",
    "print(\"encoder transformed\")\n",
    "print(ohe)\n",
    "encoder.get_feature_names_out()\n",
    "\n",
    "ohe_df = pd.DataFrame(ohe, columns=encoder.get_feature_names_out())\n",
    "ohe_df\n",
    "\n",
    "#tt = nuff.append(ohe_df, axis=0)\n",
    "tt = pd.concat([nuff, ohe_df], axis=1)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sakir</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jef</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name Gender\n",
       "0  Sakir   Male\n",
       "1    Jef   Male"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5492"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets make one for all names i ntk\n",
    "from ntk import Ntk\n",
    "\n",
    "def load_gendered_names():\n",
    "    ntk = Ntk()\n",
    "\n",
    "    m = [n for n in ntk.gutter if n not in ntk.jenter]\n",
    "    f = [n for n in ntk.jenter if n not in ntk.gutter]\n",
    "\n",
    "    names = m + f\n",
    "    genders = ['Male' for n in m] + [\"Female\" for n in f]\n",
    "\n",
    "    names_df = pd.DataFrame([(k, v) for k,v in zip(names, genders)], columns=['Name', 'Gender'])\n",
    "    return names_df\n",
    "\n",
    "\n",
    "df = load_gendered_names()\n",
    "df.head(2)\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>final_letter_is_vowel</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>last_1_letter</th>\n",
       "      <th>last_2_letter</th>\n",
       "      <th>last_3_letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAKIR</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>IR</td>\n",
       "      <td>KIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JEF</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>EF</td>\n",
       "      <td>JEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOLGER</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>R</td>\n",
       "      <td>ER</td>\n",
       "      <td>GER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name Gender  final_letter_is_vowel  syllable_count last_1_letter  \\\n",
       "0   SAKIR   Male                      0               1             R   \n",
       "1     JEF   Male                      0               1             F   \n",
       "2  HOLGER   Male                      0               2             R   \n",
       "\n",
       "  last_2_letter last_3_letter  \n",
       "0            IR           KIR  \n",
       "1            EF           JEF  \n",
       "2            ER           GER  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5492"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_features_df = generate_language_features(load_gendered_names())\n",
    "names_features_df.head(3)\n",
    "len(names_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder(handle_unknown='ignore', sparse=False)\n"
     ]
    }
   ],
   "source": [
    "ohe = get_one_hot_encoder(names_features_df, \n",
    "        categorical_columns=[n for n in names_features_df.columns if n.startswith(\"last_\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>final_letter_is_vowel</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>last_1_letter_*</th>\n",
       "      <th>last_1_letter_A</th>\n",
       "      <th>last_1_letter_B</th>\n",
       "      <th>last_1_letter_C</th>\n",
       "      <th>last_1_letter_D</th>\n",
       "      <th>last_1_letter_E</th>\n",
       "      <th>last_1_letter_F</th>\n",
       "      <th>last_1_letter_G</th>\n",
       "      <th>last_1_letter_H</th>\n",
       "      <th>last_1_letter_I</th>\n",
       "      <th>last_1_letter_J</th>\n",
       "      <th>...</th>\n",
       "      <th>last_3_letter_ØGG</th>\n",
       "      <th>last_3_letter_ØRG</th>\n",
       "      <th>last_3_letter_ØRK</th>\n",
       "      <th>last_3_letter_ØRN</th>\n",
       "      <th>last_3_letter_ØRT</th>\n",
       "      <th>last_3_letter_ØVE</th>\n",
       "      <th>last_3_letter_ØYA</th>\n",
       "      <th>last_3_letter_ÚLI</th>\n",
       "      <th>last_3_letter_ÚNA</th>\n",
       "      <th>last_3_letter_ÚNI</th>\n",
       "      <th>last_3_letter_ÚSI</th>\n",
       "      <th>last_3_letter_ÚST</th>\n",
       "      <th>last_3_letter_ÝR</th>\n",
       "      <th>last_3_letter_ÞÓR</th>\n",
       "      <th>last_3_letter_ﾘRN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAKIR</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JEF</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOLGER</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1867 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name Gender  final_letter_is_vowel  syllable_count  last_1_letter_*  \\\n",
       "0   SAKIR   Male                      0               1              0.0   \n",
       "1     JEF   Male                      0               1              0.0   \n",
       "2  HOLGER   Male                      0               2              0.0   \n",
       "\n",
       "   last_1_letter_A  last_1_letter_B  last_1_letter_C  last_1_letter_D  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   last_1_letter_E  last_1_letter_F  last_1_letter_G  last_1_letter_H  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              1.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   last_1_letter_I  last_1_letter_J  ...  last_3_letter_ØGG  \\\n",
       "0              0.0              0.0  ...                0.0   \n",
       "1              0.0              0.0  ...                0.0   \n",
       "2              0.0              0.0  ...                0.0   \n",
       "\n",
       "   last_3_letter_ØRG  last_3_letter_ØRK  last_3_letter_ØRN  last_3_letter_ØRT  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   last_3_letter_ØVE  last_3_letter_ØYA  last_3_letter_ÚLI  last_3_letter_ÚNA  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   last_3_letter_ÚNI  last_3_letter_ÚSI  last_3_letter_ÚST  last_3_letter_ÝR  \\\n",
       "0                0.0                0.0                0.0               0.0   \n",
       "1                0.0                0.0                0.0               0.0   \n",
       "2                0.0                0.0                0.0               0.0   \n",
       "\n",
       "   last_3_letter_ÞÓR  last_3_letter_ﾘRN  \n",
       "0                0.0                0.0  \n",
       "1                0.0                0.0  \n",
       "2                0.0                0.0  \n",
       "\n",
       "[3 rows x 1867 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5492"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = names_features_df[[n for n in names_features_df.columns if n.startswith(\"last_\")]]\n",
    "encoded_features = ohe.transform(cat_features)\n",
    "#encoded_features\n",
    "\n",
    "\n",
    "ohe_df = pd.DataFrame(encoded_features, columns=ohe.get_feature_names_out())\n",
    "\n",
    "#ohe_df\n",
    "\n",
    "non_categorical = names_features_df[[n for n in names_features_df.columns if not n.startswith(\"last_\")]]\n",
    "\n",
    "df_transformed = pd.concat([non_categorical, ohe_df], axis=1)\n",
    "df_transformed.head(3)\n",
    "len(df_transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_transformed['Gender']\n",
    "X = df_transformed.drop(columns=['Gender', 'Name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4119, 1865), pandas.core.frame.DataFrame)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((4119,), pandas.core.series.Series)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_letter_is_vowel</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>last_1_letter_*</th>\n",
       "      <th>last_1_letter_A</th>\n",
       "      <th>last_1_letter_B</th>\n",
       "      <th>last_1_letter_C</th>\n",
       "      <th>last_1_letter_D</th>\n",
       "      <th>last_1_letter_E</th>\n",
       "      <th>last_1_letter_F</th>\n",
       "      <th>last_1_letter_G</th>\n",
       "      <th>last_1_letter_H</th>\n",
       "      <th>last_1_letter_I</th>\n",
       "      <th>last_1_letter_J</th>\n",
       "      <th>last_1_letter_K</th>\n",
       "      <th>last_1_letter_L</th>\n",
       "      <th>...</th>\n",
       "      <th>last_3_letter_ØGG</th>\n",
       "      <th>last_3_letter_ØRG</th>\n",
       "      <th>last_3_letter_ØRK</th>\n",
       "      <th>last_3_letter_ØRN</th>\n",
       "      <th>last_3_letter_ØRT</th>\n",
       "      <th>last_3_letter_ØVE</th>\n",
       "      <th>last_3_letter_ØYA</th>\n",
       "      <th>last_3_letter_ÚLI</th>\n",
       "      <th>last_3_letter_ÚNA</th>\n",
       "      <th>last_3_letter_ÚNI</th>\n",
       "      <th>last_3_letter_ÚSI</th>\n",
       "      <th>last_3_letter_ÚST</th>\n",
       "      <th>last_3_letter_ÝR</th>\n",
       "      <th>last_3_letter_ÞÓR</th>\n",
       "      <th>last_3_letter_ﾘRN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4643</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5283</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5305</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4119 rows × 1865 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      final_letter_is_vowel  syllable_count  last_1_letter_*  last_1_letter_A  \\\n",
       "4643                      1               1              0.0              0.0   \n",
       "1934                      0               2              0.0              0.0   \n",
       "3275                      1               2              0.0              0.0   \n",
       "3300                      0               1              0.0              0.0   \n",
       "5283                      1               2              0.0              1.0   \n",
       "...                     ...             ...              ...              ...   \n",
       "1768                      0               2              0.0              0.0   \n",
       "1737                      0               1              0.0              0.0   \n",
       "3240                      0               2              0.0              0.0   \n",
       "5305                      1               3              0.0              1.0   \n",
       "4737                      0               2              0.0              0.0   \n",
       "\n",
       "      last_1_letter_B  last_1_letter_C  last_1_letter_D  last_1_letter_E  \\\n",
       "4643              0.0              0.0              0.0              1.0   \n",
       "1934              0.0              0.0              0.0              0.0   \n",
       "3275              0.0              0.0              0.0              1.0   \n",
       "3300              0.0              0.0              0.0              0.0   \n",
       "5283              0.0              0.0              0.0              0.0   \n",
       "...               ...              ...              ...              ...   \n",
       "1768              0.0              0.0              0.0              0.0   \n",
       "1737              0.0              0.0              0.0              0.0   \n",
       "3240              0.0              0.0              0.0              0.0   \n",
       "5305              0.0              0.0              0.0              0.0   \n",
       "4737              0.0              0.0              1.0              0.0   \n",
       "\n",
       "      last_1_letter_F  last_1_letter_G  last_1_letter_H  last_1_letter_I  \\\n",
       "4643              0.0              0.0              0.0              0.0   \n",
       "1934              0.0              0.0              0.0              0.0   \n",
       "3275              0.0              0.0              0.0              0.0   \n",
       "3300              0.0              0.0              0.0              0.0   \n",
       "5283              0.0              0.0              0.0              0.0   \n",
       "...               ...              ...              ...              ...   \n",
       "1768              0.0              0.0              0.0              0.0   \n",
       "1737              0.0              0.0              0.0              0.0   \n",
       "3240              0.0              0.0              0.0              0.0   \n",
       "5305              0.0              0.0              0.0              0.0   \n",
       "4737              0.0              0.0              0.0              0.0   \n",
       "\n",
       "      last_1_letter_J  last_1_letter_K  last_1_letter_L  ...  \\\n",
       "4643              0.0              0.0              0.0  ...   \n",
       "1934              0.0              0.0              0.0  ...   \n",
       "3275              0.0              0.0              0.0  ...   \n",
       "3300              0.0              0.0              0.0  ...   \n",
       "5283              0.0              0.0              0.0  ...   \n",
       "...               ...              ...              ...  ...   \n",
       "1768              0.0              0.0              1.0  ...   \n",
       "1737              0.0              0.0              1.0  ...   \n",
       "3240              0.0              0.0              1.0  ...   \n",
       "5305              0.0              0.0              0.0  ...   \n",
       "4737              0.0              0.0              0.0  ...   \n",
       "\n",
       "      last_3_letter_ØGG  last_3_letter_ØRG  last_3_letter_ØRK  \\\n",
       "4643                0.0                0.0                0.0   \n",
       "1934                0.0                0.0                0.0   \n",
       "3275                0.0                0.0                0.0   \n",
       "3300                0.0                0.0                0.0   \n",
       "5283                0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "1768                0.0                0.0                0.0   \n",
       "1737                0.0                0.0                0.0   \n",
       "3240                0.0                0.0                0.0   \n",
       "5305                0.0                0.0                0.0   \n",
       "4737                0.0                0.0                0.0   \n",
       "\n",
       "      last_3_letter_ØRN  last_3_letter_ØRT  last_3_letter_ØVE  \\\n",
       "4643                0.0                0.0                0.0   \n",
       "1934                0.0                0.0                0.0   \n",
       "3275                0.0                0.0                0.0   \n",
       "3300                0.0                0.0                0.0   \n",
       "5283                0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "1768                0.0                0.0                0.0   \n",
       "1737                0.0                0.0                0.0   \n",
       "3240                0.0                0.0                0.0   \n",
       "5305                0.0                0.0                0.0   \n",
       "4737                0.0                0.0                0.0   \n",
       "\n",
       "      last_3_letter_ØYA  last_3_letter_ÚLI  last_3_letter_ÚNA  \\\n",
       "4643                0.0                0.0                0.0   \n",
       "1934                0.0                0.0                0.0   \n",
       "3275                0.0                0.0                0.0   \n",
       "3300                0.0                0.0                0.0   \n",
       "5283                0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "1768                0.0                0.0                0.0   \n",
       "1737                0.0                0.0                0.0   \n",
       "3240                0.0                0.0                0.0   \n",
       "5305                0.0                0.0                0.0   \n",
       "4737                0.0                0.0                0.0   \n",
       "\n",
       "      last_3_letter_ÚNI  last_3_letter_ÚSI  last_3_letter_ÚST  \\\n",
       "4643                0.0                0.0                0.0   \n",
       "1934                0.0                0.0                0.0   \n",
       "3275                0.0                0.0                0.0   \n",
       "3300                0.0                0.0                0.0   \n",
       "5283                0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "1768                0.0                0.0                0.0   \n",
       "1737                0.0                0.0                0.0   \n",
       "3240                0.0                0.0                0.0   \n",
       "5305                0.0                0.0                0.0   \n",
       "4737                0.0                0.0                0.0   \n",
       "\n",
       "      last_3_letter_ÝR  last_3_letter_ÞÓR  last_3_letter_ﾘRN  \n",
       "4643               0.0                0.0                0.0  \n",
       "1934               0.0                0.0                0.0  \n",
       "3275               0.0                0.0                0.0  \n",
       "3300               0.0                0.0                0.0  \n",
       "5283               0.0                0.0                0.0  \n",
       "...                ...                ...                ...  \n",
       "1768               0.0                0.0                0.0  \n",
       "1737               0.0                0.0                0.0  \n",
       "3240               0.0                0.0                0.0  \n",
       "5305               0.0                0.0                0.0  \n",
       "4737               0.0                0.0                0.0  \n",
       "\n",
       "[4119 rows x 1865 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, type(X_train)\n",
    "y_train.shape, type(y_train)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install flaml\n",
    "\n",
    "#sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 12-02 12:59:03] {1485} INFO - Data split method: stratified\n",
      "INFO:flaml.automl:Data split method: stratified\n",
      "[flaml.automl: 12-02 12:59:03] {1489} INFO - Evaluation method: holdout\n",
      "INFO:flaml.automl:Evaluation method: holdout\n",
      "[flaml.automl: 12-02 12:59:03] {1540} INFO - Minimizing error metric: 1-macro_f1\n",
      "INFO:flaml.automl:Minimizing error metric: 1-macro_f1\n",
      "[flaml.automl: 12-02 12:59:03] {1577} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'lrl1']\n",
      "INFO:flaml.automl:List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'lrl1']\n",
      "[flaml.automl: 12-02 12:59:03] {1826} INFO - iteration 0, current learner lgbm\n",
      "INFO:flaml.automl:iteration 0, current learner lgbm\n",
      "[flaml.tune.tune: 12-02 12:59:03] {403} INFO - trial 1 config: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}\n",
      "[flaml.automl: 12-02 12:59:03] {143} DEBUG - flaml.model - LGBMClassifier(learning_rate=0.09999999999999995, max_bin=255, n_estimators=4,\n",
      "               num_leaves=4, reg_alpha=0.0009765625, reg_lambda=1.0,\n",
      "               verbose=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - LGBMClassifier(learning_rate=0.09999999999999995, max_bin=255, n_estimators=4,\n",
      "               num_leaves=4, reg_alpha=0.0009765625, reg_lambda=1.0,\n",
      "               verbose=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:03] {146} DEBUG - flaml.model - LGBMClassifier(learning_rate=0.09999999999999995, max_bin=255, n_estimators=4,\n",
      "               num_leaves=4, reg_alpha=0.0009765625, reg_lambda=1.0,\n",
      "               verbose=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - LGBMClassifier(learning_rate=0.09999999999999995, max_bin=255, n_estimators=4,\n",
      "               num_leaves=4, reg_alpha=0.0009765625, reg_lambda=1.0,\n",
      "               verbose=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:03] {1943} INFO - Estimated sufficient time budget=1081s. Estimated necessary time budget=18s.\n",
      "INFO:flaml.automl:Estimated sufficient time budget=1081s. Estimated necessary time budget=18s.\n",
      "[flaml.automl: 12-02 12:59:03] {2023} INFO -  at 5.3s,\testimator lgbm's best error=0.2777,\tbest estimator lgbm's best error=0.2777\n",
      "INFO:flaml.automl: at 5.3s,\testimator lgbm's best error=0.2777,\tbest estimator lgbm's best error=0.2777\n",
      "[flaml.automl: 12-02 12:59:03] {1826} INFO - iteration 1, current learner lgbm\n",
      "INFO:flaml.automl:iteration 1, current learner lgbm\n",
      "[flaml.tune.tune: 12-02 12:59:03] {403} INFO - trial 1 config: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 33, 'learning_rate': 0.03735454900037746, 'log_max_bin': 9, 'colsample_bytree': 0.8085131463835397, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.692397057684401}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 33, 'learning_rate': 0.03735454900037746, 'log_max_bin': 9, 'colsample_bytree': 0.8085131463835397, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.692397057684401}\n",
      "[flaml.automl: 12-02 12:59:03] {143} DEBUG - flaml.model - LGBMClassifier(colsample_bytree=0.8085131463835397,\n",
      "               learning_rate=0.03735454900037746, max_bin=511,\n",
      "               min_child_samples=33, n_estimators=4, num_leaves=4,\n",
      "               reg_alpha=0.0009765625, reg_lambda=0.692397057684401,\n",
      "               verbose=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - LGBMClassifier(colsample_bytree=0.8085131463835397,\n",
      "               learning_rate=0.03735454900037746, max_bin=511,\n",
      "               min_child_samples=33, n_estimators=4, num_leaves=4,\n",
      "               reg_alpha=0.0009765625, reg_lambda=0.692397057684401,\n",
      "               verbose=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:03] {146} DEBUG - flaml.model - LGBMClassifier(colsample_bytree=0.8085131463835397,\n",
      "               learning_rate=0.03735454900037746, max_bin=511,\n",
      "               min_child_samples=33, n_estimators=4, num_leaves=4,\n",
      "               reg_alpha=0.0009765625, reg_lambda=0.692397057684401,\n",
      "               verbose=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - LGBMClassifier(colsample_bytree=0.8085131463835397,\n",
      "               learning_rate=0.03735454900037746, max_bin=511,\n",
      "               min_child_samples=33, n_estimators=4, num_leaves=4,\n",
      "               reg_alpha=0.0009765625, reg_lambda=0.692397057684401,\n",
      "               verbose=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:03] {2023} INFO -  at 5.4s,\testimator lgbm's best error=0.2631,\tbest estimator lgbm's best error=0.2631\n",
      "INFO:flaml.automl: at 5.4s,\testimator lgbm's best error=0.2631,\tbest estimator lgbm's best error=0.2631\n",
      "[flaml.automl: 12-02 12:59:03] {1826} INFO - iteration 2, current learner lgbm\n",
      "INFO:flaml.automl:iteration 2, current learner lgbm\n",
      "[flaml.tune.tune: 12-02 12:59:03] {403} INFO - trial 1 config: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.001348364934537134, 'reg_lambda': 1.0}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.001348364934537134, 'reg_lambda': 1.0}\n",
      "[flaml.automl: 12-02 12:59:03] {143} DEBUG - flaml.model - LGBMClassifier(learning_rate=0.09999999999999995, max_bin=255, n_estimators=4,\n",
      "               num_leaves=4, reg_alpha=0.001348364934537134, reg_lambda=1.0,\n",
      "               verbose=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - LGBMClassifier(learning_rate=0.09999999999999995, max_bin=255, n_estimators=4,\n",
      "               num_leaves=4, reg_alpha=0.001348364934537134, reg_lambda=1.0,\n",
      "               verbose=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:03] {146} DEBUG - flaml.model - LGBMClassifier(learning_rate=0.09999999999999995, max_bin=255, n_estimators=4,\n",
      "               num_leaves=4, reg_alpha=0.001348364934537134, reg_lambda=1.0,\n",
      "               verbose=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - LGBMClassifier(learning_rate=0.09999999999999995, max_bin=255, n_estimators=4,\n",
      "               num_leaves=4, reg_alpha=0.001348364934537134, reg_lambda=1.0,\n",
      "               verbose=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:03] {2023} INFO -  at 5.5s,\testimator lgbm's best error=0.2631,\tbest estimator lgbm's best error=0.2631\n",
      "INFO:flaml.automl: at 5.5s,\testimator lgbm's best error=0.2631,\tbest estimator lgbm's best error=0.2631\n",
      "[flaml.automl: 12-02 12:59:03] {1826} INFO - iteration 3, current learner lgbm\n",
      "INFO:flaml.automl:iteration 3, current learner lgbm\n",
      "[flaml.tune.tune: 12-02 12:59:03] {403} INFO - trial 1 config: {'n_estimators': 9, 'num_leaves': 4, 'min_child_samples': 25, 'learning_rate': 0.10131160192564638, 'log_max_bin': 10, 'colsample_bytree': 0.7370133750309855, 'reg_alpha': 0.002668211515123386, 'reg_lambda': 0.36111742401339153}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 9, 'num_leaves': 4, 'min_child_samples': 25, 'learning_rate': 0.10131160192564638, 'log_max_bin': 10, 'colsample_bytree': 0.7370133750309855, 'reg_alpha': 0.002668211515123386, 'reg_lambda': 0.36111742401339153}\n",
      "[flaml.automl: 12-02 12:59:03] {143} DEBUG - flaml.model - LGBMClassifier(colsample_bytree=0.7370133750309855,\n",
      "               learning_rate=0.10131160192564638, max_bin=1023,\n",
      "               min_child_samples=25, n_estimators=9, num_leaves=4,\n",
      "               reg_alpha=0.002668211515123386, reg_lambda=0.36111742401339153,\n",
      "               verbose=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - LGBMClassifier(colsample_bytree=0.7370133750309855,\n",
      "               learning_rate=0.10131160192564638, max_bin=1023,\n",
      "               min_child_samples=25, n_estimators=9, num_leaves=4,\n",
      "               reg_alpha=0.002668211515123386, reg_lambda=0.36111742401339153,\n",
      "               verbose=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:03] {146} DEBUG - flaml.model - LGBMClassifier(colsample_bytree=0.7370133750309855,\n",
      "               learning_rate=0.10131160192564638, max_bin=1023,\n",
      "               min_child_samples=25, n_estimators=9, num_leaves=4,\n",
      "               reg_alpha=0.002668211515123386, reg_lambda=0.36111742401339153,\n",
      "               verbose=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - LGBMClassifier(colsample_bytree=0.7370133750309855,\n",
      "               learning_rate=0.10131160192564638, max_bin=1023,\n",
      "               min_child_samples=25, n_estimators=9, num_leaves=4,\n",
      "               reg_alpha=0.002668211515123386, reg_lambda=0.36111742401339153,\n",
      "               verbose=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:03] {2023} INFO -  at 5.6s,\testimator lgbm's best error=0.2444,\tbest estimator lgbm's best error=0.2444\n",
      "INFO:flaml.automl: at 5.6s,\testimator lgbm's best error=0.2444,\tbest estimator lgbm's best error=0.2444\n",
      "[flaml.automl: 12-02 12:59:03] {1826} INFO - iteration 4, current learner xgboost\n",
      "INFO:flaml.automl:iteration 4, current learner xgboost\n",
      "[flaml.tune.tune: 12-02 12:59:03] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}\n",
      "[flaml.automl: 12-02 12:59:03] {143} DEBUG - flaml.model - XGBClassifier(base_score=None, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=None, colsample_bytree=1.0, gamma=None,\n",
      "              gpu_id=None, grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.09999999999999995,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=0.9999999999999993, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=0.0009765625,\n",
      "              reg_lambda=1.0, scale_pos_weight=None, subsample=1.0,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=0) fit started\n",
      "DEBUG:flaml.automl:flaml.model - XGBClassifier(base_score=None, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=None, colsample_bytree=1.0, gamma=None,\n",
      "              gpu_id=None, grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.09999999999999995,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=0.9999999999999993, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=0.0009765625,\n",
      "              reg_lambda=1.0, scale_pos_weight=None, subsample=1.0,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=0) fit started\n",
      "[flaml.automl: 12-02 12:59:03] {146} DEBUG - flaml.model - XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=1, colsample_bytree=1.0, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.09999999999999995,\n",
      "              max_delta_step=0, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=0.9999999999999993, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,\n",
      "              reg_lambda=1.0, scale_pos_weight=1, subsample=1.0,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=1, colsample_bytree=1.0, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.09999999999999995,\n",
      "              max_delta_step=0, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=0.9999999999999993, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,\n",
      "              reg_lambda=1.0, scale_pos_weight=1, subsample=1.0,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0) fit finished\n",
      "[flaml.automl: 12-02 12:59:03] {2023} INFO -  at 5.9s,\testimator xgboost's best error=0.2586,\tbest estimator lgbm's best error=0.2444\n",
      "INFO:flaml.automl: at 5.9s,\testimator xgboost's best error=0.2586,\tbest estimator lgbm's best error=0.2444\n",
      "[flaml.automl: 12-02 12:59:03] {1826} INFO - iteration 5, current learner lgbm\n",
      "INFO:flaml.automl:iteration 5, current learner lgbm\n",
      "[flaml.tune.tune: 12-02 12:59:03] {403} INFO - trial 1 config: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 33, 'learning_rate': 0.03735454900037746, 'log_max_bin': 8, 'colsample_bytree': 0.8085131463835397, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.6923970576844015}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 33, 'learning_rate': 0.03735454900037746, 'log_max_bin': 8, 'colsample_bytree': 0.8085131463835397, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.6923970576844015}\n",
      "[flaml.automl: 12-02 12:59:03] {143} DEBUG - flaml.model - LGBMClassifier(colsample_bytree=0.8085131463835397,\n",
      "               learning_rate=0.03735454900037746, max_bin=255,\n",
      "               min_child_samples=33, n_estimators=4, num_leaves=4,\n",
      "               reg_alpha=0.0009765625, reg_lambda=0.6923970576844015,\n",
      "               verbose=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - LGBMClassifier(colsample_bytree=0.8085131463835397,\n",
      "               learning_rate=0.03735454900037746, max_bin=255,\n",
      "               min_child_samples=33, n_estimators=4, num_leaves=4,\n",
      "               reg_alpha=0.0009765625, reg_lambda=0.6923970576844015,\n",
      "               verbose=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:04] {146} DEBUG - flaml.model - LGBMClassifier(colsample_bytree=0.8085131463835397,\n",
      "               learning_rate=0.03735454900037746, max_bin=255,\n",
      "               min_child_samples=33, n_estimators=4, num_leaves=4,\n",
      "               reg_alpha=0.0009765625, reg_lambda=0.6923970576844015,\n",
      "               verbose=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - LGBMClassifier(colsample_bytree=0.8085131463835397,\n",
      "               learning_rate=0.03735454900037746, max_bin=255,\n",
      "               min_child_samples=33, n_estimators=4, num_leaves=4,\n",
      "               reg_alpha=0.0009765625, reg_lambda=0.6923970576844015,\n",
      "               verbose=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:04] {2023} INFO -  at 6.0s,\testimator lgbm's best error=0.2444,\tbest estimator lgbm's best error=0.2444\n",
      "INFO:flaml.automl: at 6.0s,\testimator lgbm's best error=0.2444,\tbest estimator lgbm's best error=0.2444\n",
      "[flaml.automl: 12-02 12:59:04] {1826} INFO - iteration 6, current learner lgbm\n",
      "INFO:flaml.automl:iteration 6, current learner lgbm\n",
      "[flaml.tune.tune: 12-02 12:59:04] {403} INFO - trial 1 config: {'n_estimators': 10, 'num_leaves': 5, 'min_child_samples': 15, 'learning_rate': 0.10591441245329958, 'log_max_bin': 9, 'colsample_bytree': 0.6389203895134972, 'reg_alpha': 0.0014132988481787994, 'reg_lambda': 0.022976154325858374}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 10, 'num_leaves': 5, 'min_child_samples': 15, 'learning_rate': 0.10591441245329958, 'log_max_bin': 9, 'colsample_bytree': 0.6389203895134972, 'reg_alpha': 0.0014132988481787994, 'reg_lambda': 0.022976154325858374}\n",
      "[flaml.automl: 12-02 12:59:04] {143} DEBUG - flaml.model - LGBMClassifier(colsample_bytree=0.6389203895134972,\n",
      "               learning_rate=0.10591441245329958, max_bin=511,\n",
      "               min_child_samples=15, n_estimators=10, num_leaves=5,\n",
      "               reg_alpha=0.0014132988481787994, reg_lambda=0.022976154325858374,\n",
      "               verbose=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - LGBMClassifier(colsample_bytree=0.6389203895134972,\n",
      "               learning_rate=0.10591441245329958, max_bin=511,\n",
      "               min_child_samples=15, n_estimators=10, num_leaves=5,\n",
      "               reg_alpha=0.0014132988481787994, reg_lambda=0.022976154325858374,\n",
      "               verbose=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:04] {146} DEBUG - flaml.model - LGBMClassifier(colsample_bytree=0.6389203895134972,\n",
      "               learning_rate=0.10591441245329958, max_bin=511,\n",
      "               min_child_samples=15, n_estimators=10, num_leaves=5,\n",
      "               reg_alpha=0.0014132988481787994, reg_lambda=0.022976154325858374,\n",
      "               verbose=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - LGBMClassifier(colsample_bytree=0.6389203895134972,\n",
      "               learning_rate=0.10591441245329958, max_bin=511,\n",
      "               min_child_samples=15, n_estimators=10, num_leaves=5,\n",
      "               reg_alpha=0.0014132988481787994, reg_lambda=0.022976154325858374,\n",
      "               verbose=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:04] {2023} INFO -  at 6.1s,\testimator lgbm's best error=0.2441,\tbest estimator lgbm's best error=0.2441\n",
      "INFO:flaml.automl: at 6.1s,\testimator lgbm's best error=0.2441,\tbest estimator lgbm's best error=0.2441\n",
      "[flaml.automl: 12-02 12:59:04] {1826} INFO - iteration 7, current learner lgbm\n",
      "INFO:flaml.automl:iteration 7, current learner lgbm\n",
      "[flaml.tune.tune: 12-02 12:59:04] {403} INFO - trial 1 config: {'n_estimators': 9, 'num_leaves': 4, 'min_child_samples': 26, 'learning_rate': 0.10131160192564638, 'log_max_bin': 10, 'colsample_bytree': 0.7370133750309855, 'reg_alpha': 0.002668211515123386, 'reg_lambda': 0.36111742401339153}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 9, 'num_leaves': 4, 'min_child_samples': 26, 'learning_rate': 0.10131160192564638, 'log_max_bin': 10, 'colsample_bytree': 0.7370133750309855, 'reg_alpha': 0.002668211515123386, 'reg_lambda': 0.36111742401339153}\n",
      "[flaml.automl: 12-02 12:59:04] {143} DEBUG - flaml.model - LGBMClassifier(colsample_bytree=0.7370133750309855,\n",
      "               learning_rate=0.10131160192564638, max_bin=1023,\n",
      "               min_child_samples=26, n_estimators=9, num_leaves=4,\n",
      "               reg_alpha=0.002668211515123386, reg_lambda=0.36111742401339153,\n",
      "               verbose=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - LGBMClassifier(colsample_bytree=0.7370133750309855,\n",
      "               learning_rate=0.10131160192564638, max_bin=1023,\n",
      "               min_child_samples=26, n_estimators=9, num_leaves=4,\n",
      "               reg_alpha=0.002668211515123386, reg_lambda=0.36111742401339153,\n",
      "               verbose=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:04] {146} DEBUG - flaml.model - LGBMClassifier(colsample_bytree=0.7370133750309855,\n",
      "               learning_rate=0.10131160192564638, max_bin=1023,\n",
      "               min_child_samples=26, n_estimators=9, num_leaves=4,\n",
      "               reg_alpha=0.002668211515123386, reg_lambda=0.36111742401339153,\n",
      "               verbose=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - LGBMClassifier(colsample_bytree=0.7370133750309855,\n",
      "               learning_rate=0.10131160192564638, max_bin=1023,\n",
      "               min_child_samples=26, n_estimators=9, num_leaves=4,\n",
      "               reg_alpha=0.002668211515123386, reg_lambda=0.36111742401339153,\n",
      "               verbose=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:04] {2023} INFO -  at 6.2s,\testimator lgbm's best error=0.2441,\tbest estimator lgbm's best error=0.2441\n",
      "INFO:flaml.automl: at 6.2s,\testimator lgbm's best error=0.2441,\tbest estimator lgbm's best error=0.2441\n",
      "[flaml.automl: 12-02 12:59:04] {1826} INFO - iteration 8, current learner lgbm\n",
      "INFO:flaml.automl:iteration 8, current learner lgbm\n",
      "[flaml.tune.tune: 12-02 12:59:04] {403} INFO - trial 1 config: {'n_estimators': 4, 'num_leaves': 6, 'min_child_samples': 20, 'learning_rate': 0.19173807345245308, 'log_max_bin': 9, 'colsample_bytree': 0.7082741990160921, 'reg_alpha': 0.012553125619676954, 'reg_lambda': 0.1186494209766889}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'num_leaves': 6, 'min_child_samples': 20, 'learning_rate': 0.19173807345245308, 'log_max_bin': 9, 'colsample_bytree': 0.7082741990160921, 'reg_alpha': 0.012553125619676954, 'reg_lambda': 0.1186494209766889}\n",
      "[flaml.automl: 12-02 12:59:04] {143} DEBUG - flaml.model - LGBMClassifier(colsample_bytree=0.7082741990160921,\n",
      "               learning_rate=0.19173807345245308, max_bin=511, n_estimators=4,\n",
      "               num_leaves=6, reg_alpha=0.012553125619676954,\n",
      "               reg_lambda=0.1186494209766889, verbose=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - LGBMClassifier(colsample_bytree=0.7082741990160921,\n",
      "               learning_rate=0.19173807345245308, max_bin=511, n_estimators=4,\n",
      "               num_leaves=6, reg_alpha=0.012553125619676954,\n",
      "               reg_lambda=0.1186494209766889, verbose=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:04] {146} DEBUG - flaml.model - LGBMClassifier(colsample_bytree=0.7082741990160921,\n",
      "               learning_rate=0.19173807345245308, max_bin=511, n_estimators=4,\n",
      "               num_leaves=6, reg_alpha=0.012553125619676954,\n",
      "               reg_lambda=0.1186494209766889, verbose=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - LGBMClassifier(colsample_bytree=0.7082741990160921,\n",
      "               learning_rate=0.19173807345245308, max_bin=511, n_estimators=4,\n",
      "               num_leaves=6, reg_alpha=0.012553125619676954,\n",
      "               reg_lambda=0.1186494209766889, verbose=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:04] {2023} INFO -  at 6.3s,\testimator lgbm's best error=0.2441,\tbest estimator lgbm's best error=0.2441\n",
      "INFO:flaml.automl: at 6.3s,\testimator lgbm's best error=0.2441,\tbest estimator lgbm's best error=0.2441\n",
      "[flaml.automl: 12-02 12:59:04] {1826} INFO - iteration 9, current learner lgbm\n",
      "INFO:flaml.automl:iteration 9, current learner lgbm\n",
      "[flaml.tune.tune: 12-02 12:59:04] {403} INFO - trial 1 config: {'n_estimators': 28, 'num_leaves': 4, 'min_child_samples': 11, 'learning_rate': 0.05850618274888138, 'log_max_bin': 10, 'colsample_bytree': 0.5695665800109022, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.004449273020130269}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 28, 'num_leaves': 4, 'min_child_samples': 11, 'learning_rate': 0.05850618274888138, 'log_max_bin': 10, 'colsample_bytree': 0.5695665800109022, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.004449273020130269}\n",
      "[flaml.automl: 12-02 12:59:04] {143} DEBUG - flaml.model - LGBMClassifier(colsample_bytree=0.5695665800109022,\n",
      "               learning_rate=0.05850618274888138, max_bin=1023,\n",
      "               min_child_samples=11, n_estimators=28, num_leaves=4,\n",
      "               reg_alpha=0.0009765625, reg_lambda=0.004449273020130269,\n",
      "               verbose=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - LGBMClassifier(colsample_bytree=0.5695665800109022,\n",
      "               learning_rate=0.05850618274888138, max_bin=1023,\n",
      "               min_child_samples=11, n_estimators=28, num_leaves=4,\n",
      "               reg_alpha=0.0009765625, reg_lambda=0.004449273020130269,\n",
      "               verbose=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:04] {146} DEBUG - flaml.model - LGBMClassifier(colsample_bytree=0.5695665800109022,\n",
      "               learning_rate=0.05850618274888138, max_bin=1023,\n",
      "               min_child_samples=11, n_estimators=28, num_leaves=4,\n",
      "               reg_alpha=0.0009765625, reg_lambda=0.004449273020130269,\n",
      "               verbose=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - LGBMClassifier(colsample_bytree=0.5695665800109022,\n",
      "               learning_rate=0.05850618274888138, max_bin=1023,\n",
      "               min_child_samples=11, n_estimators=28, num_leaves=4,\n",
      "               reg_alpha=0.0009765625, reg_lambda=0.004449273020130269,\n",
      "               verbose=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:04] {2023} INFO -  at 6.4s,\testimator lgbm's best error=0.2436,\tbest estimator lgbm's best error=0.2436\n",
      "INFO:flaml.automl: at 6.4s,\testimator lgbm's best error=0.2436,\tbest estimator lgbm's best error=0.2436\n",
      "[flaml.automl: 12-02 12:59:04] {1826} INFO - iteration 10, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 10, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:04] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 1.0, 'max_leaves': 4, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 1.0, 'max_leaves': 4, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:04] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=4,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=4,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:04] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=4,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=4,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:04] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=4,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=4,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:04] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=4,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=4,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:04] {2023} INFO -  at 6.6s,\testimator extra_tree's best error=0.2777,\tbest estimator lgbm's best error=0.2436\n",
      "INFO:flaml.automl: at 6.6s,\testimator extra_tree's best error=0.2777,\tbest estimator lgbm's best error=0.2436\n",
      "[flaml.automl: 12-02 12:59:04] {1826} INFO - iteration 11, current learner xgboost\n",
      "INFO:flaml.automl:iteration 11, current learner xgboost\n",
      "[flaml.tune.tune: 12-02 12:59:04] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 3.815612027960909, 'learning_rate': 0.03859136192132085, 'subsample': 1.0, 'colsample_bylevel': 0.8148474110627004, 'colsample_bytree': 0.9777234800442423, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.525802807180917}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 3.815612027960909, 'learning_rate': 0.03859136192132085, 'subsample': 1.0, 'colsample_bylevel': 0.8148474110627004, 'colsample_bytree': 0.9777234800442423, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.525802807180917}\n",
      "[flaml.automl: 12-02 12:59:04] {143} DEBUG - flaml.model - XGBClassifier(base_score=None, booster='gbtree',\n",
      "              colsample_bylevel=0.8148474110627004, colsample_bynode=None,\n",
      "              colsample_bytree=0.9777234800442423, gamma=None, gpu_id=None,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.03859136192132085,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=3.815612027960909, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=0.0009765625,\n",
      "              reg_lambda=5.525802807180917, scale_pos_weight=None,\n",
      "              subsample=1.0, tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=0) fit started\n",
      "DEBUG:flaml.automl:flaml.model - XGBClassifier(base_score=None, booster='gbtree',\n",
      "              colsample_bylevel=0.8148474110627004, colsample_bynode=None,\n",
      "              colsample_bytree=0.9777234800442423, gamma=None, gpu_id=None,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.03859136192132085,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=3.815612027960909, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=0.0009765625,\n",
      "              reg_lambda=5.525802807180917, scale_pos_weight=None,\n",
      "              subsample=1.0, tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=0) fit started\n",
      "[flaml.automl: 12-02 12:59:04] {146} DEBUG - flaml.model - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.8148474110627004, colsample_bynode=1,\n",
      "              colsample_bytree=0.9777234800442423, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.03859136192132085,\n",
      "              max_delta_step=0, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=3.815612027960909, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,\n",
      "              reg_lambda=5.525802807180917, scale_pos_weight=1, subsample=1.0,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.8148474110627004, colsample_bynode=1,\n",
      "              colsample_bytree=0.9777234800442423, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.03859136192132085,\n",
      "              max_delta_step=0, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=3.815612027960909, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,\n",
      "              reg_lambda=5.525802807180917, scale_pos_weight=1, subsample=1.0,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0) fit finished\n",
      "[flaml.automl: 12-02 12:59:04] {2023} INFO -  at 6.8s,\testimator xgboost's best error=0.2586,\tbest estimator lgbm's best error=0.2436\n",
      "INFO:flaml.automl: at 6.8s,\testimator xgboost's best error=0.2586,\tbest estimator lgbm's best error=0.2436\n",
      "[flaml.automl: 12-02 12:59:04] {1826} INFO - iteration 12, current learner xgboost\n",
      "INFO:flaml.automl:iteration 12, current learner xgboost\n",
      "[flaml.tune.tune: 12-02 12:59:04] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25912534572860507, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25912534572860507, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}\n",
      "[flaml.automl: 12-02 12:59:04] {143} DEBUG - flaml.model - XGBClassifier(base_score=None, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=None, colsample_bytree=1.0, gamma=None,\n",
      "              gpu_id=None, grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.25912534572860507,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=0.26208115308159446, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None,\n",
      "              reg_alpha=0.0013933617380144255, reg_lambda=0.18096917948292954,\n",
      "              scale_pos_weight=None, subsample=0.9266743941610592,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=0) fit started\n",
      "DEBUG:flaml.automl:flaml.model - XGBClassifier(base_score=None, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=None, colsample_bytree=1.0, gamma=None,\n",
      "              gpu_id=None, grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.25912534572860507,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=0.26208115308159446, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None,\n",
      "              reg_alpha=0.0013933617380144255, reg_lambda=0.18096917948292954,\n",
      "              scale_pos_weight=None, subsample=0.9266743941610592,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=0) fit started\n",
      "[flaml.automl: 12-02 12:59:05] {146} DEBUG - flaml.model - XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=1, colsample_bytree=1.0, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.25912534572860507,\n",
      "              max_delta_step=0, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=0.26208115308159446, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.0013933617380144255, reg_lambda=0.18096917948292954,\n",
      "              scale_pos_weight=1, subsample=0.9266743941610592,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=1, colsample_bytree=1.0, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.25912534572860507,\n",
      "              max_delta_step=0, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=0.26208115308159446, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.0013933617380144255, reg_lambda=0.18096917948292954,\n",
      "              scale_pos_weight=1, subsample=0.9266743941610592,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0) fit finished\n",
      "[flaml.automl: 12-02 12:59:05] {2023} INFO -  at 7.1s,\testimator xgboost's best error=0.2444,\tbest estimator lgbm's best error=0.2436\n",
      "INFO:flaml.automl: at 7.1s,\testimator xgboost's best error=0.2444,\tbest estimator lgbm's best error=0.2436\n",
      "[flaml.automl: 12-02 12:59:05] {1826} INFO - iteration 13, current learner xgboost\n",
      "INFO:flaml.automl:iteration 13, current learner xgboost\n",
      "[flaml.tune.tune: 12-02 12:59:05] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1.8630223791106992, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.27901659190538414}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1.8630223791106992, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.27901659190538414}\n",
      "[flaml.automl: 12-02 12:59:05] {143} DEBUG - flaml.model - XGBClassifier(base_score=None, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=None, colsample_bytree=0.946138073111236,\n",
      "              gamma=None, gpu_id=None, grow_policy='lossguide',\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=1.0, max_delta_step=None, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=1.8630223791106992, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None,\n",
      "              reg_alpha=0.0018311776973217071, reg_lambda=0.27901659190538414,\n",
      "              scale_pos_weight=None, subsample=0.8513627344387318,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=0) fit started\n",
      "DEBUG:flaml.automl:flaml.model - XGBClassifier(base_score=None, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=None, colsample_bytree=0.946138073111236,\n",
      "              gamma=None, gpu_id=None, grow_policy='lossguide',\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=1.0, max_delta_step=None, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=1.8630223791106992, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None,\n",
      "              reg_alpha=0.0018311776973217071, reg_lambda=0.27901659190538414,\n",
      "              scale_pos_weight=None, subsample=0.8513627344387318,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=0) fit started\n",
      "[flaml.automl: 12-02 12:59:05] {146} DEBUG - flaml.model - XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=1, colsample_bytree=0.946138073111236, gamma=0,\n",
      "              gpu_id=-1, grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=1.0, max_delta_step=0,\n",
      "              max_depth=0, max_leaves=4, min_child_weight=1.8630223791106992,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.0018311776973217071, reg_lambda=0.27901659190538414,\n",
      "              scale_pos_weight=1, subsample=0.8513627344387318,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=1, colsample_bytree=0.946138073111236, gamma=0,\n",
      "              gpu_id=-1, grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=1.0, max_delta_step=0,\n",
      "              max_depth=0, max_leaves=4, min_child_weight=1.8630223791106992,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.0018311776973217071, reg_lambda=0.27901659190538414,\n",
      "              scale_pos_weight=1, subsample=0.8513627344387318,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0) fit finished\n",
      "[flaml.automl: 12-02 12:59:05] {2023} INFO -  at 7.3s,\testimator xgboost's best error=0.2210,\tbest estimator xgboost's best error=0.2210\n",
      "INFO:flaml.automl: at 7.3s,\testimator xgboost's best error=0.2210,\tbest estimator xgboost's best error=0.2210\n",
      "[flaml.automl: 12-02 12:59:05] {1826} INFO - iteration 14, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 14, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:05] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.9692029582222275, 'max_leaves': 10, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 0.9692029582222275, 'max_leaves': 10, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:05] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9692029582222275, max_leaf_nodes=10,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9692029582222275, max_leaf_nodes=10,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:05] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9692029582222275, max_leaf_nodes=10,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9692029582222275, max_leaf_nodes=10,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:05] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9692029582222275, max_leaf_nodes=10,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9692029582222275, max_leaf_nodes=10,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:05] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9692029582222275, max_leaf_nodes=10,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9692029582222275, max_leaf_nodes=10,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:05] {2023} INFO -  at 7.6s,\testimator extra_tree's best error=0.2311,\tbest estimator xgboost's best error=0.2210\n",
      "INFO:flaml.automl: at 7.6s,\testimator extra_tree's best error=0.2311,\tbest estimator xgboost's best error=0.2210\n",
      "[flaml.automl: 12-02 12:59:05] {1826} INFO - iteration 15, current learner rf\n",
      "INFO:flaml.automl:iteration 15, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:05] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 1.0, 'max_leaves': 4, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 1.0, 'max_leaves': 4, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:05] {143} DEBUG - flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=4, n_estimators=1,\n",
      "                       n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=4, n_estimators=1,\n",
      "                       n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:05] {146} DEBUG - flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=4, n_estimators=1,\n",
      "                       n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=4, n_estimators=1,\n",
      "                       n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:05] {143} DEBUG - flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=4, n_estimators=4,\n",
      "                       n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=4, n_estimators=4,\n",
      "                       n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:05] {146} DEBUG - flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=4, n_estimators=4,\n",
      "                       n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=4, n_estimators=4,\n",
      "                       n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:05] {2023} INFO -  at 7.8s,\testimator rf's best error=0.2631,\tbest estimator xgboost's best error=0.2210\n",
      "INFO:flaml.automl: at 7.8s,\testimator rf's best error=0.2631,\tbest estimator xgboost's best error=0.2210\n",
      "[flaml.automl: 12-02 12:59:05] {1826} INFO - iteration 16, current learner rf\n",
      "INFO:flaml.automl:iteration 16, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:05] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.9692029582222275, 'max_leaves': 10, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 0.9692029582222275, 'max_leaves': 10, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:05] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9692029582222275,\n",
      "                       max_leaf_nodes=10, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9692029582222275,\n",
      "                       max_leaf_nodes=10, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:05] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9692029582222275,\n",
      "                       max_leaf_nodes=10, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9692029582222275,\n",
      "                       max_leaf_nodes=10, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:05] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9692029582222275,\n",
      "                       max_leaf_nodes=10, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9692029582222275,\n",
      "                       max_leaf_nodes=10, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:06] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9692029582222275,\n",
      "                       max_leaf_nodes=10, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9692029582222275,\n",
      "                       max_leaf_nodes=10, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:06] {2023} INFO -  at 8.0s,\testimator rf's best error=0.2232,\tbest estimator xgboost's best error=0.2210\n",
      "INFO:flaml.automl: at 8.0s,\testimator rf's best error=0.2232,\tbest estimator xgboost's best error=0.2210\n",
      "[flaml.automl: 12-02 12:59:06] {1826} INFO - iteration 17, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 17, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:06] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.9999999999999999, 'max_leaves': 4, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 0.9999999999999999, 'max_leaves': 4, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:06] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9999999999999999, max_leaf_nodes=4,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9999999999999999, max_leaf_nodes=4,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:06] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9999999999999999, max_leaf_nodes=4,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9999999999999999, max_leaf_nodes=4,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:06] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9999999999999999, max_leaf_nodes=4,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9999999999999999, max_leaf_nodes=4,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:06] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9999999999999999, max_leaf_nodes=4,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9999999999999999, max_leaf_nodes=4,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:06] {2023} INFO -  at 8.2s,\testimator extra_tree's best error=0.2311,\tbest estimator xgboost's best error=0.2210\n",
      "INFO:flaml.automl: at 8.2s,\testimator extra_tree's best error=0.2311,\tbest estimator xgboost's best error=0.2210\n",
      "[flaml.automl: 12-02 12:59:06] {1826} INFO - iteration 18, current learner rf\n",
      "INFO:flaml.automl:iteration 18, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:06] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.9999999999999999, 'max_leaves': 4, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 0.9999999999999999, 'max_leaves': 4, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:06] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9999999999999999,\n",
      "                       max_leaf_nodes=4, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9999999999999999,\n",
      "                       max_leaf_nodes=4, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:06] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9999999999999999,\n",
      "                       max_leaf_nodes=4, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9999999999999999,\n",
      "                       max_leaf_nodes=4, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:06] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9999999999999999,\n",
      "                       max_leaf_nodes=4, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9999999999999999,\n",
      "                       max_leaf_nodes=4, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:06] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9999999999999999,\n",
      "                       max_leaf_nodes=4, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9999999999999999,\n",
      "                       max_leaf_nodes=4, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:06] {2023} INFO -  at 8.3s,\testimator rf's best error=0.2232,\tbest estimator xgboost's best error=0.2210\n",
      "INFO:flaml.automl: at 8.3s,\testimator rf's best error=0.2232,\tbest estimator xgboost's best error=0.2210\n",
      "[flaml.automl: 12-02 12:59:06] {1826} INFO - iteration 19, current learner xgboost\n",
      "INFO:flaml.automl:iteration 19, current learner xgboost\n",
      "[flaml.tune.tune: 12-02 12:59:06] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 7, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292968}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_leaves': 7, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292968}\n",
      "[flaml.automl: 12-02 12:59:06] {143} DEBUG - flaml.model - XGBClassifier(base_score=None, booster='gbtree',\n",
      "              colsample_bylevel=0.9168331919232143, colsample_bynode=None,\n",
      "              colsample_bytree=1.0, gamma=None, gpu_id=None,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.25775724472262795,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=7,\n",
      "              min_child_weight=0.26208115308159446, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None,\n",
      "              reg_alpha=0.0013933617380144255, reg_lambda=0.18096917948292968,\n",
      "              scale_pos_weight=None, subsample=0.9266743941610592,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=0) fit started\n",
      "DEBUG:flaml.automl:flaml.model - XGBClassifier(base_score=None, booster='gbtree',\n",
      "              colsample_bylevel=0.9168331919232143, colsample_bynode=None,\n",
      "              colsample_bytree=1.0, gamma=None, gpu_id=None,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.25775724472262795,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=7,\n",
      "              min_child_weight=0.26208115308159446, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None,\n",
      "              reg_alpha=0.0013933617380144255, reg_lambda=0.18096917948292968,\n",
      "              scale_pos_weight=None, subsample=0.9266743941610592,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=0) fit started\n",
      "[flaml.automl: 12-02 12:59:06] {146} DEBUG - flaml.model - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.9168331919232143, colsample_bynode=1,\n",
      "              colsample_bytree=1.0, gamma=0, gpu_id=-1, grow_policy='lossguide',\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.25775724472262795, max_delta_step=0, max_depth=0,\n",
      "              max_leaves=7, min_child_weight=0.26208115308159446, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.0013933617380144255, reg_lambda=0.18096917948292968,\n",
      "              scale_pos_weight=1, subsample=0.9266743941610592,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.9168331919232143, colsample_bynode=1,\n",
      "              colsample_bytree=1.0, gamma=0, gpu_id=-1, grow_policy='lossguide',\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.25775724472262795, max_delta_step=0, max_depth=0,\n",
      "              max_leaves=7, min_child_weight=0.26208115308159446, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.0013933617380144255, reg_lambda=0.18096917948292968,\n",
      "              scale_pos_weight=1, subsample=0.9266743941610592,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0) fit finished\n",
      "[flaml.automl: 12-02 12:59:06] {2023} INFO -  at 8.6s,\testimator xgboost's best error=0.2210,\tbest estimator xgboost's best error=0.2210\n",
      "INFO:flaml.automl: at 8.6s,\testimator xgboost's best error=0.2210,\tbest estimator xgboost's best error=0.2210\n",
      "[flaml.automl: 12-02 12:59:06] {1826} INFO - iteration 20, current learner xgboost\n",
      "INFO:flaml.automl:iteration 20, current learner xgboost\n",
      "[flaml.tune.tune: 12-02 12:59:06] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.5873610441060633, 'learning_rate': 0.5305016568114994, 'subsample': 0.8132820472645403, 'colsample_bylevel': 0.8184166881476597, 'colsample_bytree': 0.8110207792444197, 'reg_alpha': 0.002464557255174736, 'reg_lambda': 0.6369900700728743}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.5873610441060633, 'learning_rate': 0.5305016568114994, 'subsample': 0.8132820472645403, 'colsample_bylevel': 0.8184166881476597, 'colsample_bytree': 0.8110207792444197, 'reg_alpha': 0.002464557255174736, 'reg_lambda': 0.6369900700728743}\n",
      "[flaml.automl: 12-02 12:59:06] {143} DEBUG - flaml.model - XGBClassifier(base_score=None, booster='gbtree',\n",
      "              colsample_bylevel=0.8184166881476597, colsample_bynode=None,\n",
      "              colsample_bytree=0.8110207792444197, gamma=None, gpu_id=None,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.5305016568114994,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=0.5873610441060633, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None,\n",
      "              reg_alpha=0.002464557255174736, reg_lambda=0.6369900700728743,\n",
      "              scale_pos_weight=None, subsample=0.8132820472645403,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=0) fit started\n",
      "DEBUG:flaml.automl:flaml.model - XGBClassifier(base_score=None, booster='gbtree',\n",
      "              colsample_bylevel=0.8184166881476597, colsample_bynode=None,\n",
      "              colsample_bytree=0.8110207792444197, gamma=None, gpu_id=None,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.5305016568114994,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=0.5873610441060633, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None,\n",
      "              reg_alpha=0.002464557255174736, reg_lambda=0.6369900700728743,\n",
      "              scale_pos_weight=None, subsample=0.8132820472645403,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=0) fit started\n",
      "[flaml.automl: 12-02 12:59:06] {146} DEBUG - flaml.model - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.8184166881476597, colsample_bynode=1,\n",
      "              colsample_bytree=0.8110207792444197, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.5305016568114994,\n",
      "              max_delta_step=0, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=0.5873610441060633, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.002464557255174736, reg_lambda=0.6369900700728743,\n",
      "              scale_pos_weight=1, subsample=0.8132820472645403,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.8184166881476597, colsample_bynode=1,\n",
      "              colsample_bytree=0.8110207792444197, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.5305016568114994,\n",
      "              max_delta_step=0, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=0.5873610441060633, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.002464557255174736, reg_lambda=0.6369900700728743,\n",
      "              scale_pos_weight=1, subsample=0.8132820472645403,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0) fit finished\n",
      "[flaml.automl: 12-02 12:59:06] {2023} INFO -  at 8.8s,\testimator xgboost's best error=0.2210,\tbest estimator xgboost's best error=0.2210\n",
      "INFO:flaml.automl: at 8.8s,\testimator xgboost's best error=0.2210,\tbest estimator xgboost's best error=0.2210\n",
      "[flaml.automl: 12-02 12:59:06] {1826} INFO - iteration 21, current learner xgboost\n",
      "INFO:flaml.automl:iteration 21, current learner xgboost\n",
      "[flaml.tune.tune: 12-02 12:59:06] {403} INFO - trial 1 config: {'n_estimators': 9, 'max_leaves': 4, 'min_child_weight': 5.909231502320296, 'learning_rate': 1.0, 'subsample': 0.8894434216129232, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013605736901132325, 'reg_lambda': 0.1222158118565165}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 9, 'max_leaves': 4, 'min_child_weight': 5.909231502320296, 'learning_rate': 1.0, 'subsample': 0.8894434216129232, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013605736901132325, 'reg_lambda': 0.1222158118565165}\n",
      "[flaml.automl: 12-02 12:59:06] {143} DEBUG - flaml.model - XGBClassifier(base_score=None, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=None, colsample_bytree=1.0, gamma=None,\n",
      "              gpu_id=None, grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=1.0,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=5.909231502320296, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=9, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None,\n",
      "              reg_alpha=0.0013605736901132325, reg_lambda=0.1222158118565165,\n",
      "              scale_pos_weight=None, subsample=0.8894434216129232,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=0) fit started\n",
      "DEBUG:flaml.automl:flaml.model - XGBClassifier(base_score=None, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=None, colsample_bytree=1.0, gamma=None,\n",
      "              gpu_id=None, grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=1.0,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=5.909231502320296, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=9, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None,\n",
      "              reg_alpha=0.0013605736901132325, reg_lambda=0.1222158118565165,\n",
      "              scale_pos_weight=None, subsample=0.8894434216129232,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=0) fit started\n",
      "[flaml.automl: 12-02 12:59:07] {146} DEBUG - flaml.model - XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=1, colsample_bytree=1.0, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=1.0, max_delta_step=0,\n",
      "              max_depth=0, max_leaves=4, min_child_weight=5.909231502320296,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=9, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.0013605736901132325, reg_lambda=0.1222158118565165,\n",
      "              scale_pos_weight=1, subsample=0.8894434216129232,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=1, colsample_bytree=1.0, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=1.0, max_delta_step=0,\n",
      "              max_depth=0, max_leaves=4, min_child_weight=5.909231502320296,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=9, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.0013605736901132325, reg_lambda=0.1222158118565165,\n",
      "              scale_pos_weight=1, subsample=0.8894434216129232,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0) fit finished\n",
      "[flaml.automl: 12-02 12:59:07] {2023} INFO -  at 9.1s,\testimator xgboost's best error=0.2210,\tbest estimator xgboost's best error=0.2210\n",
      "INFO:flaml.automl: at 9.1s,\testimator xgboost's best error=0.2210,\tbest estimator xgboost's best error=0.2210\n",
      "[flaml.automl: 12-02 12:59:07] {1826} INFO - iteration 22, current learner rf\n",
      "INFO:flaml.automl:iteration 22, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:07] {403} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.639099828735494, 'max_leaves': 9, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 7, 'max_features': 0.639099828735494, 'max_leaves': 9, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:07] {143} DEBUG - flaml.model - RandomForestClassifier(max_features=0.639099828735494, max_leaf_nodes=9,\n",
      "                       n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.639099828735494, max_leaf_nodes=9,\n",
      "                       n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:07] {146} DEBUG - flaml.model - RandomForestClassifier(max_features=0.639099828735494, max_leaf_nodes=9,\n",
      "                       n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.639099828735494, max_leaf_nodes=9,\n",
      "                       n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:07] {143} DEBUG - flaml.model - RandomForestClassifier(max_features=0.639099828735494, max_leaf_nodes=9,\n",
      "                       n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.639099828735494, max_leaf_nodes=9,\n",
      "                       n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:07] {146} DEBUG - flaml.model - RandomForestClassifier(max_features=0.639099828735494, max_leaf_nodes=9,\n",
      "                       n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.639099828735494, max_leaf_nodes=9,\n",
      "                       n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:07] {2023} INFO -  at 9.3s,\testimator rf's best error=0.2232,\tbest estimator xgboost's best error=0.2210\n",
      "INFO:flaml.automl: at 9.3s,\testimator rf's best error=0.2232,\tbest estimator xgboost's best error=0.2210\n",
      "[flaml.automl: 12-02 12:59:07] {1826} INFO - iteration 23, current learner rf\n",
      "INFO:flaml.automl:iteration 23, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:07] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 1.0, 'max_leaves': 12, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 1.0, 'max_leaves': 12, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:07] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=12,\n",
      "                       n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=12,\n",
      "                       n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:07] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=12,\n",
      "                       n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=12,\n",
      "                       n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:07] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=12,\n",
      "                       n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=12,\n",
      "                       n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:07] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=12,\n",
      "                       n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=12,\n",
      "                       n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:07] {2023} INFO -  at 9.6s,\testimator rf's best error=0.2232,\tbest estimator xgboost's best error=0.2210\n",
      "INFO:flaml.automl: at 9.6s,\testimator rf's best error=0.2232,\tbest estimator xgboost's best error=0.2210\n",
      "[flaml.automl: 12-02 12:59:07] {1826} INFO - iteration 24, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 24, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:07] {403} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.639099828735494, 'max_leaves': 9, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 7, 'max_features': 0.639099828735494, 'max_leaves': 9, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:07] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.639099828735494,\n",
      "                     max_leaf_nodes=9, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.639099828735494,\n",
      "                     max_leaf_nodes=9, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:07] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.639099828735494,\n",
      "                     max_leaf_nodes=9, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.639099828735494,\n",
      "                     max_leaf_nodes=9, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:07] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.639099828735494,\n",
      "                     max_leaf_nodes=9, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.639099828735494,\n",
      "                     max_leaf_nodes=9, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:07] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.639099828735494,\n",
      "                     max_leaf_nodes=9, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.639099828735494,\n",
      "                     max_leaf_nodes=9, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:07] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.639099828735494,\n",
      "                     max_leaf_nodes=9, n_estimators=7, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.639099828735494,\n",
      "                     max_leaf_nodes=9, n_estimators=7, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:07] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.639099828735494,\n",
      "                     max_leaf_nodes=9, n_estimators=7, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.639099828735494,\n",
      "                     max_leaf_nodes=9, n_estimators=7, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:07] {2023} INFO -  at 9.8s,\testimator extra_tree's best error=0.2311,\tbest estimator xgboost's best error=0.2210\n",
      "INFO:flaml.automl: at 9.8s,\testimator extra_tree's best error=0.2311,\tbest estimator xgboost's best error=0.2210\n",
      "[flaml.automl: 12-02 12:59:07] {1826} INFO - iteration 25, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 25, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:07] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 1.0, 'max_leaves': 12, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 1.0, 'max_leaves': 12, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:07] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=1.0, max_leaf_nodes=12, n_estimators=1,\n",
      "                     n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=1.0, max_leaf_nodes=12, n_estimators=1,\n",
      "                     n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:08] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=1.0, max_leaf_nodes=12, n_estimators=1,\n",
      "                     n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=1.0, max_leaf_nodes=12, n_estimators=1,\n",
      "                     n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:08] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=1.0, max_leaf_nodes=12, n_estimators=4,\n",
      "                     n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=1.0, max_leaf_nodes=12, n_estimators=4,\n",
      "                     n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:08] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=1.0, max_leaf_nodes=12, n_estimators=4,\n",
      "                     n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=1.0, max_leaf_nodes=12, n_estimators=4,\n",
      "                     n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:08] {2023} INFO -  at 10.1s,\testimator extra_tree's best error=0.2185,\tbest estimator extra_tree's best error=0.2185\n",
      "INFO:flaml.automl: at 10.1s,\testimator extra_tree's best error=0.2185,\tbest estimator extra_tree's best error=0.2185\n",
      "[flaml.automl: 12-02 12:59:08] {1826} INFO - iteration 26, current learner rf\n",
      "INFO:flaml.automl:iteration 26, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:08] {403} INFO - trial 1 config: {'n_estimators': 8, 'max_features': 0.9662106723461057, 'max_leaves': 6, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 8, 'max_features': 0.9662106723461057, 'max_leaves': 6, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:08] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9662106723461057,\n",
      "                       max_leaf_nodes=6, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9662106723461057,\n",
      "                       max_leaf_nodes=6, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:08] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9662106723461057,\n",
      "                       max_leaf_nodes=6, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9662106723461057,\n",
      "                       max_leaf_nodes=6, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:08] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9662106723461057,\n",
      "                       max_leaf_nodes=6, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9662106723461057,\n",
      "                       max_leaf_nodes=6, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:08] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9662106723461057,\n",
      "                       max_leaf_nodes=6, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9662106723461057,\n",
      "                       max_leaf_nodes=6, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:08] {2023} INFO -  at 10.3s,\testimator rf's best error=0.2232,\tbest estimator extra_tree's best error=0.2185\n",
      "INFO:flaml.automl: at 10.3s,\testimator rf's best error=0.2232,\tbest estimator extra_tree's best error=0.2185\n",
      "[flaml.automl: 12-02 12:59:08] {1826} INFO - iteration 27, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 27, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:08] {403} INFO - trial 1 config: {'n_estimators': 8, 'max_features': 0.9969126323328501, 'max_leaves': 8, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 8, 'max_features': 0.9969126323328501, 'max_leaves': 8, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:08] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9969126323328501, max_leaf_nodes=8,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9969126323328501, max_leaf_nodes=8,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:08] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9969126323328501, max_leaf_nodes=8,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9969126323328501, max_leaf_nodes=8,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:08] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9969126323328501, max_leaf_nodes=8,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9969126323328501, max_leaf_nodes=8,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:08] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9969126323328501, max_leaf_nodes=8,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9969126323328501, max_leaf_nodes=8,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:08] {2023} INFO -  at 10.5s,\testimator extra_tree's best error=0.2185,\tbest estimator extra_tree's best error=0.2185\n",
      "INFO:flaml.automl: at 10.5s,\testimator extra_tree's best error=0.2185,\tbest estimator extra_tree's best error=0.2185\n",
      "[flaml.automl: 12-02 12:59:08] {1826} INFO - iteration 28, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 28, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:08] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 1.0, 'max_leaves': 19, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 1.0, 'max_leaves': 19, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:08] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=19,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=19,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:08] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=19,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=19,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:08] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=19,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=19,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:08] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=19,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=19,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:08] {2023} INFO -  at 10.8s,\testimator extra_tree's best error=0.1985,\tbest estimator extra_tree's best error=0.1985\n",
      "INFO:flaml.automl: at 10.8s,\testimator extra_tree's best error=0.1985,\tbest estimator extra_tree's best error=0.1985\n",
      "[flaml.automl: 12-02 12:59:08] {1826} INFO - iteration 29, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 29, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:08] {403} INFO - trial 1 config: {'n_estimators': 11, 'max_features': 0.8488204428065548, 'max_leaves': 31, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 11, 'max_features': 0.8488204428065548, 'max_leaves': 31, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:08] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.8488204428065548, max_leaf_nodes=31,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.8488204428065548, max_leaf_nodes=31,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:09] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.8488204428065548, max_leaf_nodes=31,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.8488204428065548, max_leaf_nodes=31,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:09] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.8488204428065548, max_leaf_nodes=31,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.8488204428065548, max_leaf_nodes=31,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:09] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.8488204428065548, max_leaf_nodes=31,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.8488204428065548, max_leaf_nodes=31,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:09] {2023} INFO -  at 11.2s,\testimator extra_tree's best error=0.1789,\tbest estimator extra_tree's best error=0.1789\n",
      "INFO:flaml.automl: at 11.2s,\testimator extra_tree's best error=0.1789,\tbest estimator extra_tree's best error=0.1789\n",
      "[flaml.automl: 12-02 12:59:09] {1826} INFO - iteration 30, current learner rf\n",
      "INFO:flaml.automl:iteration 30, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:09] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.9722045109953315, 'max_leaves': 16, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 0.9722045109953315, 'max_leaves': 16, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:09] {143} DEBUG - flaml.model - RandomForestClassifier(max_features=0.9722045109953315, max_leaf_nodes=16,\n",
      "                       n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.9722045109953315, max_leaf_nodes=16,\n",
      "                       n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:09] {146} DEBUG - flaml.model - RandomForestClassifier(max_features=0.9722045109953315, max_leaf_nodes=16,\n",
      "                       n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.9722045109953315, max_leaf_nodes=16,\n",
      "                       n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:09] {143} DEBUG - flaml.model - RandomForestClassifier(max_features=0.9722045109953315, max_leaf_nodes=16,\n",
      "                       n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.9722045109953315, max_leaf_nodes=16,\n",
      "                       n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:09] {146} DEBUG - flaml.model - RandomForestClassifier(max_features=0.9722045109953315, max_leaf_nodes=16,\n",
      "                       n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.9722045109953315, max_leaf_nodes=16,\n",
      "                       n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:09] {2023} INFO -  at 11.5s,\testimator rf's best error=0.2084,\tbest estimator extra_tree's best error=0.1789\n",
      "INFO:flaml.automl: at 11.5s,\testimator rf's best error=0.2084,\tbest estimator extra_tree's best error=0.1789\n",
      "[flaml.automl: 12-02 12:59:09] {1826} INFO - iteration 31, current learner rf\n",
      "INFO:flaml.automl:iteration 31, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:09] {403} INFO - trial 1 config: {'n_estimators': 11, 'max_features': 0.825227063521587, 'max_leaves': 26, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 11, 'max_features': 0.825227063521587, 'max_leaves': 26, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:09] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.825227063521587,\n",
      "                       max_leaf_nodes=26, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.825227063521587,\n",
      "                       max_leaf_nodes=26, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:09] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.825227063521587,\n",
      "                       max_leaf_nodes=26, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.825227063521587,\n",
      "                       max_leaf_nodes=26, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:09] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.825227063521587,\n",
      "                       max_leaf_nodes=26, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.825227063521587,\n",
      "                       max_leaf_nodes=26, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:09] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.825227063521587,\n",
      "                       max_leaf_nodes=26, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.825227063521587,\n",
      "                       max_leaf_nodes=26, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:09] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.825227063521587,\n",
      "                       max_leaf_nodes=26, n_estimators=11, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.825227063521587,\n",
      "                       max_leaf_nodes=26, n_estimators=11, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:10] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.825227063521587,\n",
      "                       max_leaf_nodes=26, n_estimators=11, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.825227063521587,\n",
      "                       max_leaf_nodes=26, n_estimators=11, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:10] {2023} INFO -  at 12.0s,\testimator rf's best error=0.1935,\tbest estimator extra_tree's best error=0.1789\n",
      "INFO:flaml.automl: at 12.0s,\testimator rf's best error=0.1935,\tbest estimator extra_tree's best error=0.1789\n",
      "[flaml.automl: 12-02 12:59:10] {1826} INFO - iteration 32, current learner rf\n",
      "INFO:flaml.automl:iteration 32, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:10] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.9722045109953309, 'max_leaves': 16, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 0.9722045109953309, 'max_leaves': 16, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:10] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9722045109953309,\n",
      "                       max_leaf_nodes=16, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9722045109953309,\n",
      "                       max_leaf_nodes=16, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:10] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9722045109953309,\n",
      "                       max_leaf_nodes=16, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9722045109953309,\n",
      "                       max_leaf_nodes=16, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:10] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9722045109953309,\n",
      "                       max_leaf_nodes=16, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9722045109953309,\n",
      "                       max_leaf_nodes=16, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:10] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9722045109953309,\n",
      "                       max_leaf_nodes=16, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9722045109953309,\n",
      "                       max_leaf_nodes=16, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:10] {2023} INFO -  at 12.2s,\testimator rf's best error=0.1935,\tbest estimator extra_tree's best error=0.1789\n",
      "INFO:flaml.automl: at 12.2s,\testimator rf's best error=0.1935,\tbest estimator extra_tree's best error=0.1789\n",
      "[flaml.automl: 12-02 12:59:10] {1826} INFO - iteration 33, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 33, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:10] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.9999999999999999, 'max_leaves': 19, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 0.9999999999999999, 'max_leaves': 19, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:10] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9999999999999999, max_leaf_nodes=19,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9999999999999999, max_leaf_nodes=19,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:10] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9999999999999999, max_leaf_nodes=19,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9999999999999999, max_leaf_nodes=19,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:10] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9999999999999999, max_leaf_nodes=19,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9999999999999999, max_leaf_nodes=19,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:10] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9999999999999999, max_leaf_nodes=19,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9999999999999999, max_leaf_nodes=19,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:10] {2023} INFO -  at 12.6s,\testimator extra_tree's best error=0.1789,\tbest estimator extra_tree's best error=0.1789\n",
      "INFO:flaml.automl: at 12.6s,\testimator extra_tree's best error=0.1789,\tbest estimator extra_tree's best error=0.1789\n",
      "[flaml.automl: 12-02 12:59:10] {1826} INFO - iteration 34, current learner rf\n",
      "INFO:flaml.automl:iteration 34, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:10] {403} INFO - trial 1 config: {'n_estimators': 13, 'max_features': 0.9031538849074855, 'max_leaves': 7, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 13, 'max_features': 0.9031538849074855, 'max_leaves': 7, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:10] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9031538849074855,\n",
      "                       max_leaf_nodes=7, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9031538849074855,\n",
      "                       max_leaf_nodes=7, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:10] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9031538849074855,\n",
      "                       max_leaf_nodes=7, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9031538849074855,\n",
      "                       max_leaf_nodes=7, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:10] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9031538849074855,\n",
      "                       max_leaf_nodes=7, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9031538849074855,\n",
      "                       max_leaf_nodes=7, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:10] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9031538849074855,\n",
      "                       max_leaf_nodes=7, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9031538849074855,\n",
      "                       max_leaf_nodes=7, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:10] {2023} INFO -  at 12.7s,\testimator rf's best error=0.1935,\tbest estimator extra_tree's best error=0.1789\n",
      "INFO:flaml.automl: at 12.7s,\testimator rf's best error=0.1935,\tbest estimator extra_tree's best error=0.1789\n",
      "[flaml.automl: 12-02 12:59:10] {1826} INFO - iteration 35, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 35, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:10] {403} INFO - trial 1 config: {'n_estimators': 13, 'max_features': 0.9289752050037781, 'max_leaves': 8, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 13, 'max_features': 0.9289752050037781, 'max_leaves': 8, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:10] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9289752050037781, max_leaf_nodes=8,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9289752050037781, max_leaf_nodes=8,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:10] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9289752050037781, max_leaf_nodes=8,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9289752050037781, max_leaf_nodes=8,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:10] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9289752050037781, max_leaf_nodes=8,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9289752050037781, max_leaf_nodes=8,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:11] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9289752050037781, max_leaf_nodes=8,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9289752050037781, max_leaf_nodes=8,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:11] {2023} INFO -  at 12.9s,\testimator extra_tree's best error=0.1789,\tbest estimator extra_tree's best error=0.1789\n",
      "INFO:flaml.automl: at 12.9s,\testimator extra_tree's best error=0.1789,\tbest estimator extra_tree's best error=0.1789\n",
      "[flaml.automl: 12-02 12:59:11] {1826} INFO - iteration 36, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 36, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:11] {403} INFO - trial 1 config: {'n_estimators': 9, 'max_features': 0.7755816734886752, 'max_leaves': 117, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 9, 'max_features': 0.7755816734886752, 'max_leaves': 117, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:11] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7755816734886752,\n",
      "                     max_leaf_nodes=117, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7755816734886752,\n",
      "                     max_leaf_nodes=117, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:11] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7755816734886752,\n",
      "                     max_leaf_nodes=117, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7755816734886752,\n",
      "                     max_leaf_nodes=117, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:11] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7755816734886752,\n",
      "                     max_leaf_nodes=117, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7755816734886752,\n",
      "                     max_leaf_nodes=117, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:11] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7755816734886752,\n",
      "                     max_leaf_nodes=117, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7755816734886752,\n",
      "                     max_leaf_nodes=117, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:11] {2023} INFO -  at 13.6s,\testimator extra_tree's best error=0.1692,\tbest estimator extra_tree's best error=0.1692\n",
      "INFO:flaml.automl: at 13.6s,\testimator extra_tree's best error=0.1692,\tbest estimator extra_tree's best error=0.1692\n",
      "[flaml.automl: 12-02 12:59:11] {1826} INFO - iteration 37, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 37, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:11] {403} INFO - trial 1 config: {'n_estimators': 5, 'max_features': 0.646392449325737, 'max_leaves': 91, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 5, 'max_features': 0.646392449325737, 'max_leaves': 91, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:11] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.646392449325737, max_leaf_nodes=91,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.646392449325737, max_leaf_nodes=91,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:11] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.646392449325737, max_leaf_nodes=91,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.646392449325737, max_leaf_nodes=91,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:11] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.646392449325737, max_leaf_nodes=91,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.646392449325737, max_leaf_nodes=91,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:12] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.646392449325737, max_leaf_nodes=91,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.646392449325737, max_leaf_nodes=91,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:12] {2023} INFO -  at 14.0s,\testimator extra_tree's best error=0.1692,\tbest estimator extra_tree's best error=0.1692\n",
      "INFO:flaml.automl: at 14.0s,\testimator extra_tree's best error=0.1692,\tbest estimator extra_tree's best error=0.1692\n",
      "[flaml.automl: 12-02 12:59:12] {1826} INFO - iteration 38, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 38, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:12] {403} INFO - trial 1 config: {'n_estimators': 15, 'max_features': 0.930590901671201, 'max_leaves': 150, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 15, 'max_features': 0.930590901671201, 'max_leaves': 150, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:12] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.930590901671201,\n",
      "                     max_leaf_nodes=150, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.930590901671201,\n",
      "                     max_leaf_nodes=150, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:12] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.930590901671201,\n",
      "                     max_leaf_nodes=150, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.930590901671201,\n",
      "                     max_leaf_nodes=150, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:12] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.930590901671201,\n",
      "                     max_leaf_nodes=150, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.930590901671201,\n",
      "                     max_leaf_nodes=150, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:12] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.930590901671201,\n",
      "                     max_leaf_nodes=150, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.930590901671201,\n",
      "                     max_leaf_nodes=150, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:12] {2023} INFO -  at 14.9s,\testimator extra_tree's best error=0.1692,\tbest estimator extra_tree's best error=0.1692\n",
      "INFO:flaml.automl: at 14.9s,\testimator extra_tree's best error=0.1692,\tbest estimator extra_tree's best error=0.1692\n",
      "[flaml.automl: 12-02 12:59:13] {1826} INFO - iteration 39, current learner xgboost\n",
      "INFO:flaml.automl:iteration 39, current learner xgboost\n",
      "[flaml.tune.tune: 12-02 12:59:13] {403} INFO - trial 1 config: {'n_estimators': 7, 'max_leaves': 4, 'min_child_weight': 3.7946175399062563, 'learning_rate': 1.0, 'subsample': 0.94339802915019, 'colsample_bylevel': 0.8811171114303163, 'colsample_bytree': 0.7960408456608403, 'reg_alpha': 0.0029724360931790185, 'reg_lambda': 1.246651737581895}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 7, 'max_leaves': 4, 'min_child_weight': 3.7946175399062563, 'learning_rate': 1.0, 'subsample': 0.94339802915019, 'colsample_bylevel': 0.8811171114303163, 'colsample_bytree': 0.7960408456608403, 'reg_alpha': 0.0029724360931790185, 'reg_lambda': 1.246651737581895}\n",
      "[flaml.automl: 12-02 12:59:13] {143} DEBUG - flaml.model - XGBClassifier(base_score=None, booster='gbtree',\n",
      "              colsample_bylevel=0.8811171114303163, colsample_bynode=None,\n",
      "              colsample_bytree=0.7960408456608403, gamma=None, gpu_id=None,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=1.0,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=3.7946175399062563, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=7, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None,\n",
      "              reg_alpha=0.0029724360931790185, reg_lambda=1.246651737581895,\n",
      "              scale_pos_weight=None, subsample=0.94339802915019,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=0) fit started\n",
      "DEBUG:flaml.automl:flaml.model - XGBClassifier(base_score=None, booster='gbtree',\n",
      "              colsample_bylevel=0.8811171114303163, colsample_bynode=None,\n",
      "              colsample_bytree=0.7960408456608403, gamma=None, gpu_id=None,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=1.0,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=3.7946175399062563, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=7, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None,\n",
      "              reg_alpha=0.0029724360931790185, reg_lambda=1.246651737581895,\n",
      "              scale_pos_weight=None, subsample=0.94339802915019,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=0) fit started\n",
      "[flaml.automl: 12-02 12:59:13] {146} DEBUG - flaml.model - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.8811171114303163, colsample_bynode=1,\n",
      "              colsample_bytree=0.7960408456608403, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=1.0, max_delta_step=0,\n",
      "              max_depth=0, max_leaves=4, min_child_weight=3.7946175399062563,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=7, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.0029724360931790185, reg_lambda=1.246651737581895,\n",
      "              scale_pos_weight=1, subsample=0.94339802915019,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.8811171114303163, colsample_bynode=1,\n",
      "              colsample_bytree=0.7960408456608403, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=1.0, max_delta_step=0,\n",
      "              max_depth=0, max_leaves=4, min_child_weight=3.7946175399062563,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=7, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.0029724360931790185, reg_lambda=1.246651737581895,\n",
      "              scale_pos_weight=1, subsample=0.94339802915019,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0) fit finished\n",
      "[flaml.automl: 12-02 12:59:13] {2023} INFO -  at 15.2s,\testimator xgboost's best error=0.2158,\tbest estimator extra_tree's best error=0.1692\n",
      "INFO:flaml.automl: at 15.2s,\testimator xgboost's best error=0.2158,\tbest estimator extra_tree's best error=0.1692\n",
      "[flaml.automl: 12-02 12:59:13] {1826} INFO - iteration 40, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 40, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:13] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.8219857503018808, 'max_leaves': 189, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 0.8219857503018808, 'max_leaves': 189, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:13] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.8219857503018808,\n",
      "                     max_leaf_nodes=189, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.8219857503018808,\n",
      "                     max_leaf_nodes=189, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:13] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.8219857503018808,\n",
      "                     max_leaf_nodes=189, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.8219857503018808,\n",
      "                     max_leaf_nodes=189, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:13] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.8219857503018808,\n",
      "                     max_leaf_nodes=189, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.8219857503018808,\n",
      "                     max_leaf_nodes=189, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:14] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.8219857503018808,\n",
      "                     max_leaf_nodes=189, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.8219857503018808,\n",
      "                     max_leaf_nodes=189, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:14] {2023} INFO -  at 16.2s,\testimator extra_tree's best error=0.1692,\tbest estimator extra_tree's best error=0.1692\n",
      "INFO:flaml.automl: at 16.2s,\testimator extra_tree's best error=0.1692,\tbest estimator extra_tree's best error=0.1692\n",
      "[flaml.automl: 12-02 12:59:14] {1826} INFO - iteration 41, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 41, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:14] {403} INFO - trial 1 config: {'n_estimators': 25, 'max_features': 0.7317972751116162, 'max_leaves': 72, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 25, 'max_features': 0.7317972751116162, 'max_leaves': 72, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:14] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.7317972751116162, max_leaf_nodes=72,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.7317972751116162, max_leaf_nodes=72,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:14] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.7317972751116162, max_leaf_nodes=72,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.7317972751116162, max_leaf_nodes=72,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:14] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.7317972751116162, max_leaf_nodes=72,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.7317972751116162, max_leaf_nodes=72,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:14] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.7317972751116162, max_leaf_nodes=72,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.7317972751116162, max_leaf_nodes=72,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:14] {2023} INFO -  at 16.7s,\testimator extra_tree's best error=0.1692,\tbest estimator extra_tree's best error=0.1692\n",
      "INFO:flaml.automl: at 16.7s,\testimator extra_tree's best error=0.1692,\tbest estimator extra_tree's best error=0.1692\n",
      "[flaml.automl: 12-02 12:59:14] {1826} INFO - iteration 42, current learner rf\n",
      "INFO:flaml.automl:iteration 42, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:14] {403} INFO - trial 1 config: {'n_estimators': 9, 'max_features': 0.7540240016109981, 'max_leaves': 98, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 9, 'max_features': 0.7540240016109981, 'max_leaves': 98, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:14] {143} DEBUG - flaml.model - RandomForestClassifier(max_features=0.7540240016109981, max_leaf_nodes=98,\n",
      "                       n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.7540240016109981, max_leaf_nodes=98,\n",
      "                       n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:15] {146} DEBUG - flaml.model - RandomForestClassifier(max_features=0.7540240016109981, max_leaf_nodes=98,\n",
      "                       n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.7540240016109981, max_leaf_nodes=98,\n",
      "                       n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:15] {143} DEBUG - flaml.model - RandomForestClassifier(max_features=0.7540240016109981, max_leaf_nodes=98,\n",
      "                       n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.7540240016109981, max_leaf_nodes=98,\n",
      "                       n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:15] {146} DEBUG - flaml.model - RandomForestClassifier(max_features=0.7540240016109981, max_leaf_nodes=98,\n",
      "                       n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.7540240016109981, max_leaf_nodes=98,\n",
      "                       n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:15] {143} DEBUG - flaml.model - RandomForestClassifier(max_features=0.7540240016109981, max_leaf_nodes=98,\n",
      "                       n_estimators=9, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.7540240016109981, max_leaf_nodes=98,\n",
      "                       n_estimators=9, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:15] {146} DEBUG - flaml.model - RandomForestClassifier(max_features=0.7540240016109981, max_leaf_nodes=98,\n",
      "                       n_estimators=9, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.7540240016109981, max_leaf_nodes=98,\n",
      "                       n_estimators=9, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:15] {2023} INFO -  at 17.6s,\testimator rf's best error=0.1598,\tbest estimator rf's best error=0.1598\n",
      "INFO:flaml.automl: at 17.6s,\testimator rf's best error=0.1598,\tbest estimator rf's best error=0.1598\n",
      "[flaml.automl: 12-02 12:59:15] {1826} INFO - iteration 43, current learner rf\n",
      "INFO:flaml.automl:iteration 43, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:15] {403} INFO - trial 1 config: {'n_estimators': 5, 'max_features': 0.6284256551078026, 'max_leaves': 76, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 5, 'max_features': 0.6284256551078026, 'max_leaves': 76, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:15] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6284256551078026,\n",
      "                       max_leaf_nodes=76, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6284256551078026,\n",
      "                       max_leaf_nodes=76, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:15] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6284256551078026,\n",
      "                       max_leaf_nodes=76, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6284256551078026,\n",
      "                       max_leaf_nodes=76, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:15] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6284256551078026,\n",
      "                       max_leaf_nodes=76, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6284256551078026,\n",
      "                       max_leaf_nodes=76, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:16] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6284256551078026,\n",
      "                       max_leaf_nodes=76, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6284256551078026,\n",
      "                       max_leaf_nodes=76, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:16] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6284256551078026,\n",
      "                       max_leaf_nodes=76, n_estimators=5, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6284256551078026,\n",
      "                       max_leaf_nodes=76, n_estimators=5, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:16] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6284256551078026,\n",
      "                       max_leaf_nodes=76, n_estimators=5, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6284256551078026,\n",
      "                       max_leaf_nodes=76, n_estimators=5, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:16] {2023} INFO -  at 18.2s,\testimator rf's best error=0.1598,\tbest estimator rf's best error=0.1598\n",
      "INFO:flaml.automl: at 18.2s,\testimator rf's best error=0.1598,\tbest estimator rf's best error=0.1598\n",
      "[flaml.automl: 12-02 12:59:16] {1826} INFO - iteration 44, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 44, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:16] {403} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.9015830853646544, 'max_leaves': 319, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 7, 'max_features': 0.9015830853646544, 'max_leaves': 319, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:16] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.9015830853646544,\n",
      "                     max_leaf_nodes=319, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.9015830853646544,\n",
      "                     max_leaf_nodes=319, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:16] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.9015830853646544,\n",
      "                     max_leaf_nodes=319, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.9015830853646544,\n",
      "                     max_leaf_nodes=319, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:16] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.9015830853646544,\n",
      "                     max_leaf_nodes=319, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.9015830853646544,\n",
      "                     max_leaf_nodes=319, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:17] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.9015830853646544,\n",
      "                     max_leaf_nodes=319, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.9015830853646544,\n",
      "                     max_leaf_nodes=319, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:17] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.9015830853646544,\n",
      "                     max_leaf_nodes=319, n_estimators=7, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.9015830853646544,\n",
      "                     max_leaf_nodes=319, n_estimators=7, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:18] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.9015830853646544,\n",
      "                     max_leaf_nodes=319, n_estimators=7, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.9015830853646544,\n",
      "                     max_leaf_nodes=319, n_estimators=7, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:18] {2023} INFO -  at 20.1s,\testimator extra_tree's best error=0.1477,\tbest estimator extra_tree's best error=0.1477\n",
      "INFO:flaml.automl: at 20.1s,\testimator extra_tree's best error=0.1477,\tbest estimator extra_tree's best error=0.1477\n",
      "[flaml.automl: 12-02 12:59:18] {1826} INFO - iteration 45, current learner xgboost\n",
      "INFO:flaml.automl:iteration 45, current learner xgboost\n",
      "[flaml.tune.tune: 12-02 12:59:18] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 5, 'min_child_weight': 1.8630223791106992, 'learning_rate': 0.38946718731417634, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217078, 'reg_lambda': 0.27901659190538414}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_leaves': 5, 'min_child_weight': 1.8630223791106992, 'learning_rate': 0.38946718731417634, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217078, 'reg_lambda': 0.27901659190538414}\n",
      "[flaml.automl: 12-02 12:59:18] {143} DEBUG - flaml.model - XGBClassifier(base_score=None, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=None, colsample_bytree=0.946138073111236,\n",
      "              gamma=None, gpu_id=None, grow_policy='lossguide',\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.38946718731417634, max_delta_step=None,\n",
      "              max_depth=0, max_leaves=5, min_child_weight=1.8630223791106992,\n",
      "              missing=nan, monotone_constraints=None, n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None,\n",
      "              reg_alpha=0.0018311776973217078, reg_lambda=0.27901659190538414,\n",
      "              scale_pos_weight=None, subsample=0.8513627344387318,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=0) fit started\n",
      "DEBUG:flaml.automl:flaml.model - XGBClassifier(base_score=None, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=None, colsample_bytree=0.946138073111236,\n",
      "              gamma=None, gpu_id=None, grow_policy='lossguide',\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.38946718731417634, max_delta_step=None,\n",
      "              max_depth=0, max_leaves=5, min_child_weight=1.8630223791106992,\n",
      "              missing=nan, monotone_constraints=None, n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None,\n",
      "              reg_alpha=0.0018311776973217078, reg_lambda=0.27901659190538414,\n",
      "              scale_pos_weight=None, subsample=0.8513627344387318,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=0) fit started\n",
      "[flaml.automl: 12-02 12:59:18] {146} DEBUG - flaml.model - XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=1, colsample_bytree=0.946138073111236, gamma=0,\n",
      "              gpu_id=-1, grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.38946718731417634,\n",
      "              max_delta_step=0, max_depth=0, max_leaves=5,\n",
      "              min_child_weight=1.8630223791106992, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.0018311776973217078, reg_lambda=0.27901659190538414,\n",
      "              scale_pos_weight=1, subsample=0.8513627344387318,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=1, colsample_bytree=0.946138073111236, gamma=0,\n",
      "              gpu_id=-1, grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.38946718731417634,\n",
      "              max_delta_step=0, max_depth=0, max_leaves=5,\n",
      "              min_child_weight=1.8630223791106992, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=4, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.0018311776973217078, reg_lambda=0.27901659190538414,\n",
      "              scale_pos_weight=1, subsample=0.8513627344387318,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0) fit finished\n",
      "[flaml.automl: 12-02 12:59:18] {2023} INFO -  at 20.3s,\testimator xgboost's best error=0.2158,\tbest estimator extra_tree's best error=0.1477\n",
      "INFO:flaml.automl: at 20.3s,\testimator xgboost's best error=0.2158,\tbest estimator extra_tree's best error=0.1477\n",
      "[flaml.automl: 12-02 12:59:18] {1826} INFO - iteration 46, current learner rf\n",
      "INFO:flaml.automl:iteration 46, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:18] {403} INFO - trial 1 config: {'n_estimators': 15, 'max_features': 0.9047246724959543, 'max_leaves': 126, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 15, 'max_features': 0.9047246724959543, 'max_leaves': 126, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:18] {143} DEBUG - flaml.model - RandomForestClassifier(max_features=0.9047246724959543, max_leaf_nodes=126,\n",
      "                       n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.9047246724959543, max_leaf_nodes=126,\n",
      "                       n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:18] {146} DEBUG - flaml.model - RandomForestClassifier(max_features=0.9047246724959543, max_leaf_nodes=126,\n",
      "                       n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.9047246724959543, max_leaf_nodes=126,\n",
      "                       n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:18] {143} DEBUG - flaml.model - RandomForestClassifier(max_features=0.9047246724959543, max_leaf_nodes=126,\n",
      "                       n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.9047246724959543, max_leaf_nodes=126,\n",
      "                       n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:19] {146} DEBUG - flaml.model - RandomForestClassifier(max_features=0.9047246724959543, max_leaf_nodes=126,\n",
      "                       n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.9047246724959543, max_leaf_nodes=126,\n",
      "                       n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:19] {2023} INFO -  at 21.0s,\testimator rf's best error=0.1500,\tbest estimator extra_tree's best error=0.1477\n",
      "INFO:flaml.automl: at 21.0s,\testimator rf's best error=0.1500,\tbest estimator extra_tree's best error=0.1477\n",
      "[flaml.automl: 12-02 12:59:19] {1826} INFO - iteration 47, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 47, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:19] {403} INFO - trial 1 config: {'n_estimators': 9, 'max_features': 0.7755816734886747, 'max_leaves': 117, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 9, 'max_features': 0.7755816734886747, 'max_leaves': 117, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:19] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.7755816734886747, max_leaf_nodes=117,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.7755816734886747, max_leaf_nodes=117,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:19] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.7755816734886747, max_leaf_nodes=117,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.7755816734886747, max_leaf_nodes=117,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:19] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.7755816734886747, max_leaf_nodes=117,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.7755816734886747, max_leaf_nodes=117,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:19] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.7755816734886747, max_leaf_nodes=117,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.7755816734886747, max_leaf_nodes=117,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:19] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.7755816734886747, max_leaf_nodes=117,\n",
      "                     n_estimators=9, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.7755816734886747, max_leaf_nodes=117,\n",
      "                     n_estimators=9, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:20] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.7755816734886747, max_leaf_nodes=117,\n",
      "                     n_estimators=9, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.7755816734886747, max_leaf_nodes=117,\n",
      "                     n_estimators=9, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:20] {2023} INFO -  at 22.1s,\testimator extra_tree's best error=0.1477,\tbest estimator extra_tree's best error=0.1477\n",
      "INFO:flaml.automl: at 22.1s,\testimator extra_tree's best error=0.1477,\tbest estimator extra_tree's best error=0.1477\n",
      "[flaml.automl: 12-02 12:59:20] {1826} INFO - iteration 48, current learner rf\n",
      "INFO:flaml.automl:iteration 48, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:20] {403} INFO - trial 1 config: {'n_estimators': 6, 'max_features': 0.9588555456617158, 'max_leaves': 203, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 6, 'max_features': 0.9588555456617158, 'max_leaves': 203, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:20] {143} DEBUG - flaml.model - RandomForestClassifier(max_features=0.9588555456617158, max_leaf_nodes=203,\n",
      "                       n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.9588555456617158, max_leaf_nodes=203,\n",
      "                       n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:20] {146} DEBUG - flaml.model - RandomForestClassifier(max_features=0.9588555456617158, max_leaf_nodes=203,\n",
      "                       n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.9588555456617158, max_leaf_nodes=203,\n",
      "                       n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:20] {143} DEBUG - flaml.model - RandomForestClassifier(max_features=0.9588555456617158, max_leaf_nodes=203,\n",
      "                       n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.9588555456617158, max_leaf_nodes=203,\n",
      "                       n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:21] {146} DEBUG - flaml.model - RandomForestClassifier(max_features=0.9588555456617158, max_leaf_nodes=203,\n",
      "                       n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.9588555456617158, max_leaf_nodes=203,\n",
      "                       n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:21] {2023} INFO -  at 23.1s,\testimator rf's best error=0.1476,\tbest estimator rf's best error=0.1476\n",
      "INFO:flaml.automl: at 23.1s,\testimator rf's best error=0.1476,\tbest estimator rf's best error=0.1476\n",
      "[flaml.automl: 12-02 12:59:21] {1826} INFO - iteration 49, current learner rf\n",
      "INFO:flaml.automl:iteration 49, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:21] {403} INFO - trial 1 config: {'n_estimators': 16, 'max_features': 0.9047246724959541, 'max_leaves': 126, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 16, 'max_features': 0.9047246724959541, 'max_leaves': 126, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:21] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9047246724959541,\n",
      "                       max_leaf_nodes=126, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9047246724959541,\n",
      "                       max_leaf_nodes=126, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:21] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9047246724959541,\n",
      "                       max_leaf_nodes=126, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9047246724959541,\n",
      "                       max_leaf_nodes=126, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:21] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9047246724959541,\n",
      "                       max_leaf_nodes=126, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9047246724959541,\n",
      "                       max_leaf_nodes=126, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:21] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9047246724959541,\n",
      "                       max_leaf_nodes=126, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.9047246724959541,\n",
      "                       max_leaf_nodes=126, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:21] {2023} INFO -  at 23.9s,\testimator rf's best error=0.1476,\tbest estimator rf's best error=0.1476\n",
      "INFO:flaml.automl: at 23.9s,\testimator rf's best error=0.1476,\tbest estimator rf's best error=0.1476\n",
      "[flaml.automl: 12-02 12:59:21] {1826} INFO - iteration 50, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 50, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:21] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.6603699418332465, 'max_leaves': 395, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 0.6603699418332465, 'max_leaves': 395, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:21] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.6603699418332465,\n",
      "                     max_leaf_nodes=395, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.6603699418332465,\n",
      "                     max_leaf_nodes=395, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:22] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.6603699418332465,\n",
      "                     max_leaf_nodes=395, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.6603699418332465,\n",
      "                     max_leaf_nodes=395, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:22] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.6603699418332465,\n",
      "                     max_leaf_nodes=395, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.6603699418332465,\n",
      "                     max_leaf_nodes=395, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:22] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.6603699418332465,\n",
      "                     max_leaf_nodes=395, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.6603699418332465,\n",
      "                     max_leaf_nodes=395, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:22] {2023} INFO -  at 24.7s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 24.7s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:22] {1826} INFO - iteration 51, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 51, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:22] {403} INFO - trial 1 config: {'n_estimators': 8, 'max_features': 0.901583085364654, 'max_leaves': 319, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 8, 'max_features': 0.901583085364654, 'max_leaves': 319, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:22] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.901583085364654, max_leaf_nodes=319,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.901583085364654, max_leaf_nodes=319,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:23] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.901583085364654, max_leaf_nodes=319,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.901583085364654, max_leaf_nodes=319,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:23] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.901583085364654, max_leaf_nodes=319,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.901583085364654, max_leaf_nodes=319,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:24] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.901583085364654, max_leaf_nodes=319,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.901583085364654, max_leaf_nodes=319,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:24] {2023} INFO -  at 25.9s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 25.9s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:24] {1826} INFO - iteration 52, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 52, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:24] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 1.0, 'max_leaves': 550, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 1.0, 'max_leaves': 550, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:24] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=550,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=550,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:24] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=550,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=550,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:24] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=550,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=550,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:25] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=550,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=550,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:25] {2023} INFO -  at 27.4s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 27.4s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:25] {1826} INFO - iteration 53, current learner rf\n",
      "INFO:flaml.automl:iteration 53, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:25] {403} INFO - trial 1 config: {'n_estimators': 5, 'max_features': 1.0, 'max_leaves': 554, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 5, 'max_features': 1.0, 'max_leaves': 554, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:25] {143} DEBUG - flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=554, n_estimators=1,\n",
      "                       n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=554, n_estimators=1,\n",
      "                       n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:25] {146} DEBUG - flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=554, n_estimators=1,\n",
      "                       n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=554, n_estimators=1,\n",
      "                       n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:25] {143} DEBUG - flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=554, n_estimators=4,\n",
      "                       n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=554, n_estimators=4,\n",
      "                       n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:26] {146} DEBUG - flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=554, n_estimators=4,\n",
      "                       n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=554, n_estimators=4,\n",
      "                       n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:26] {2023} INFO -  at 28.5s,\testimator rf's best error=0.1476,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 28.5s,\testimator rf's best error=0.1476,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:26] {1826} INFO - iteration 54, current learner rf\n",
      "INFO:flaml.automl:iteration 54, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:26] {403} INFO - trial 1 config: {'n_estimators': 8, 'max_features': 0.8248499786765907, 'max_leaves': 74, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 8, 'max_features': 0.8248499786765907, 'max_leaves': 74, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:26] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.8248499786765907,\n",
      "                       max_leaf_nodes=74, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.8248499786765907,\n",
      "                       max_leaf_nodes=74, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:26] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.8248499786765907,\n",
      "                       max_leaf_nodes=74, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.8248499786765907,\n",
      "                       max_leaf_nodes=74, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:26] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.8248499786765907,\n",
      "                       max_leaf_nodes=74, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.8248499786765907,\n",
      "                       max_leaf_nodes=74, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:27] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.8248499786765907,\n",
      "                       max_leaf_nodes=74, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.8248499786765907,\n",
      "                       max_leaf_nodes=74, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:27] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.8248499786765907,\n",
      "                       max_leaf_nodes=74, n_estimators=8, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.8248499786765907,\n",
      "                       max_leaf_nodes=74, n_estimators=8, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:27] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.8248499786765907,\n",
      "                       max_leaf_nodes=74, n_estimators=8, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.8248499786765907,\n",
      "                       max_leaf_nodes=74, n_estimators=8, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:27] {2023} INFO -  at 29.3s,\testimator rf's best error=0.1476,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 29.3s,\testimator rf's best error=0.1476,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:27] {1826} INFO - iteration 55, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 55, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:27] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.42754544930335475, 'max_leaves': 283, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 0.42754544930335475, 'max_leaves': 283, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:27] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.42754544930335475, max_leaf_nodes=283,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.42754544930335475, max_leaf_nodes=283,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:27] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.42754544930335475, max_leaf_nodes=283,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.42754544930335475, max_leaf_nodes=283,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:27] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.42754544930335475, max_leaf_nodes=283,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.42754544930335475, max_leaf_nodes=283,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:27] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.42754544930335475, max_leaf_nodes=283,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.42754544930335475, max_leaf_nodes=283,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:28] {2023} INFO -  at 29.9s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 29.9s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:28] {1826} INFO - iteration 56, current learner xgboost\n",
      "INFO:flaml.automl:iteration 56, current learner xgboost\n",
      "[flaml.tune.tune: 12-02 12:59:28] {403} INFO - trial 1 config: {'n_estimators': 7, 'max_leaves': 9, 'min_child_weight': 5.469602241327581, 'learning_rate': 1.0, 'subsample': 0.9772874081612134, 'colsample_bylevel': 0.9088550158793876, 'colsample_bytree': 0.7428526330379099, 'reg_alpha': 0.07645644140847146, 'reg_lambda': 6.292715740379093}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 7, 'max_leaves': 9, 'min_child_weight': 5.469602241327581, 'learning_rate': 1.0, 'subsample': 0.9772874081612134, 'colsample_bylevel': 0.9088550158793876, 'colsample_bytree': 0.7428526330379099, 'reg_alpha': 0.07645644140847146, 'reg_lambda': 6.292715740379093}\n",
      "[flaml.automl: 12-02 12:59:28] {143} DEBUG - flaml.model - XGBClassifier(base_score=None, booster='gbtree',\n",
      "              colsample_bylevel=0.9088550158793876, colsample_bynode=None,\n",
      "              colsample_bytree=0.7428526330379099, gamma=None, gpu_id=None,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=1.0,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=9,\n",
      "              min_child_weight=5.469602241327581, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=7, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None,\n",
      "              reg_alpha=0.07645644140847146, reg_lambda=6.292715740379093,\n",
      "              scale_pos_weight=None, subsample=0.9772874081612134,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=0) fit started\n",
      "DEBUG:flaml.automl:flaml.model - XGBClassifier(base_score=None, booster='gbtree',\n",
      "              colsample_bylevel=0.9088550158793876, colsample_bynode=None,\n",
      "              colsample_bytree=0.7428526330379099, gamma=None, gpu_id=None,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=1.0,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=9,\n",
      "              min_child_weight=5.469602241327581, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=7, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None,\n",
      "              reg_alpha=0.07645644140847146, reg_lambda=6.292715740379093,\n",
      "              scale_pos_weight=None, subsample=0.9772874081612134,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=0) fit started\n",
      "[flaml.automl: 12-02 12:59:28] {146} DEBUG - flaml.model - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.9088550158793876, colsample_bynode=1,\n",
      "              colsample_bytree=0.7428526330379099, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=1.0, max_delta_step=0,\n",
      "              max_depth=0, max_leaves=9, min_child_weight=5.469602241327581,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=7, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.07645644140847146, reg_lambda=6.292715740379093,\n",
      "              scale_pos_weight=1, subsample=0.9772874081612134,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.9088550158793876, colsample_bynode=1,\n",
      "              colsample_bytree=0.7428526330379099, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=1.0, max_delta_step=0,\n",
      "              max_depth=0, max_leaves=9, min_child_weight=5.469602241327581,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=7, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.07645644140847146, reg_lambda=6.292715740379093,\n",
      "              scale_pos_weight=1, subsample=0.9772874081612134,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0) fit finished\n",
      "[flaml.automl: 12-02 12:59:28] {2023} INFO -  at 30.2s,\testimator xgboost's best error=0.2158,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 30.2s,\testimator xgboost's best error=0.2158,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:28] {1826} INFO - iteration 57, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 57, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:28] {403} INFO - trial 1 config: {'n_estimators': 5, 'max_features': 0.696099781260012, 'max_leaves': 293, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 5, 'max_features': 0.696099781260012, 'max_leaves': 293, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:28] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.696099781260012,\n",
      "                     max_leaf_nodes=293, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.696099781260012,\n",
      "                     max_leaf_nodes=293, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:28] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.696099781260012,\n",
      "                     max_leaf_nodes=293, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.696099781260012,\n",
      "                     max_leaf_nodes=293, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:28] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.696099781260012,\n",
      "                     max_leaf_nodes=293, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.696099781260012,\n",
      "                     max_leaf_nodes=293, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:29] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.696099781260012,\n",
      "                     max_leaf_nodes=293, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.696099781260012,\n",
      "                     max_leaf_nodes=293, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:29] {2023} INFO -  at 31.2s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 31.2s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:29] {1826} INFO - iteration 58, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 58, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:29] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.6264740656684021, 'max_leaves': 533, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 0.6264740656684021, 'max_leaves': 533, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:29] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.6264740656684021, max_leaf_nodes=533,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.6264740656684021, max_leaf_nodes=533,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:29] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.6264740656684021, max_leaf_nodes=533,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.6264740656684021, max_leaf_nodes=533,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:29] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.6264740656684021, max_leaf_nodes=533,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.6264740656684021, max_leaf_nodes=533,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:30] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.6264740656684021, max_leaf_nodes=533,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.6264740656684021, max_leaf_nodes=533,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:30] {2023} INFO -  at 32.1s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 32.1s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:30] {1826} INFO - iteration 59, current learner rf\n",
      "INFO:flaml.automl:iteration 59, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:30] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.7023194991052981, 'max_leaves': 251, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 0.7023194991052981, 'max_leaves': 251, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:30] {143} DEBUG - flaml.model - RandomForestClassifier(max_features=0.7023194991052981, max_leaf_nodes=251,\n",
      "                       n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.7023194991052981, max_leaf_nodes=251,\n",
      "                       n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:30] {146} DEBUG - flaml.model - RandomForestClassifier(max_features=0.7023194991052981, max_leaf_nodes=251,\n",
      "                       n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.7023194991052981, max_leaf_nodes=251,\n",
      "                       n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:30] {143} DEBUG - flaml.model - RandomForestClassifier(max_features=0.7023194991052981, max_leaf_nodes=251,\n",
      "                       n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.7023194991052981, max_leaf_nodes=251,\n",
      "                       n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:31] {146} DEBUG - flaml.model - RandomForestClassifier(max_features=0.7023194991052981, max_leaf_nodes=251,\n",
      "                       n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=0.7023194991052981, max_leaf_nodes=251,\n",
      "                       n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:31] {2023} INFO -  at 33.0s,\testimator rf's best error=0.1476,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 33.0s,\testimator rf's best error=0.1476,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:31] {1826} INFO - iteration 60, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 60, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:31] {403} INFO - trial 1 config: {'n_estimators': 8, 'max_features': 0.5579355639479606, 'max_leaves': 306, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 8, 'max_features': 0.5579355639479606, 'max_leaves': 306, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:31] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.5579355639479606, max_leaf_nodes=306,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.5579355639479606, max_leaf_nodes=306,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:31] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.5579355639479606, max_leaf_nodes=306,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.5579355639479606, max_leaf_nodes=306,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:31] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.5579355639479606, max_leaf_nodes=306,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.5579355639479606, max_leaf_nodes=306,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:31] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.5579355639479606, max_leaf_nodes=306,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.5579355639479606, max_leaf_nodes=306,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:31] {2023} INFO -  at 33.7s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 33.7s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:31] {1826} INFO - iteration 61, current learner rf\n",
      "INFO:flaml.automl:iteration 61, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:31] {403} INFO - trial 1 config: {'n_estimators': 12, 'max_features': 1.0, 'max_leaves': 164, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 12, 'max_features': 1.0, 'max_leaves': 164, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:31] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=1.0,\n",
      "                       max_leaf_nodes=164, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=1.0,\n",
      "                       max_leaf_nodes=164, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:32] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=1.0,\n",
      "                       max_leaf_nodes=164, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=1.0,\n",
      "                       max_leaf_nodes=164, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:32] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=1.0,\n",
      "                       max_leaf_nodes=164, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=1.0,\n",
      "                       max_leaf_nodes=164, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:32] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=1.0,\n",
      "                       max_leaf_nodes=164, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=1.0,\n",
      "                       max_leaf_nodes=164, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:32] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=1.0,\n",
      "                       max_leaf_nodes=164, n_estimators=12, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=1.0,\n",
      "                       max_leaf_nodes=164, n_estimators=12, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:33] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=1.0,\n",
      "                       max_leaf_nodes=164, n_estimators=12, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=1.0,\n",
      "                       max_leaf_nodes=164, n_estimators=12, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:33] {2023} INFO -  at 35.3s,\testimator rf's best error=0.1476,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 35.3s,\testimator rf's best error=0.1476,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:33] {1826} INFO - iteration 62, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 62, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:33] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.7816107956823481, 'max_leaves': 510, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 0.7816107956823481, 'max_leaves': 510, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:33] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7816107956823481,\n",
      "                     max_leaf_nodes=510, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7816107956823481,\n",
      "                     max_leaf_nodes=510, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:33] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7816107956823481,\n",
      "                     max_leaf_nodes=510, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7816107956823481,\n",
      "                     max_leaf_nodes=510, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:33] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7816107956823481,\n",
      "                     max_leaf_nodes=510, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7816107956823481,\n",
      "                     max_leaf_nodes=510, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:34] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7816107956823481,\n",
      "                     max_leaf_nodes=510, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7816107956823481,\n",
      "                     max_leaf_nodes=510, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:34] {2023} INFO -  at 36.4s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 36.4s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:34] {1826} INFO - iteration 63, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 63, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:34] {403} INFO - trial 1 config: {'n_estimators': 6, 'max_features': 0.450017471900366, 'max_leaves': 303, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 6, 'max_features': 0.450017471900366, 'max_leaves': 303, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:34] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.450017471900366,\n",
      "                     max_leaf_nodes=303, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.450017471900366,\n",
      "                     max_leaf_nodes=303, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:34] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.450017471900366,\n",
      "                     max_leaf_nodes=303, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.450017471900366,\n",
      "                     max_leaf_nodes=303, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:34] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.450017471900366,\n",
      "                     max_leaf_nodes=303, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.450017471900366,\n",
      "                     max_leaf_nodes=303, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:35] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.450017471900366,\n",
      "                     max_leaf_nodes=303, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.450017471900366,\n",
      "                     max_leaf_nodes=303, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:35] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.450017471900366,\n",
      "                     max_leaf_nodes=303, n_estimators=6, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.450017471900366,\n",
      "                     max_leaf_nodes=303, n_estimators=6, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:35] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.450017471900366,\n",
      "                     max_leaf_nodes=303, n_estimators=6, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.450017471900366,\n",
      "                     max_leaf_nodes=303, n_estimators=6, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:35] {2023} INFO -  at 37.5s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 37.5s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:35] {1826} INFO - iteration 64, current learner rf\n",
      "INFO:flaml.automl:iteration 64, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:35] {403} INFO - trial 1 config: {'n_estimators': 6, 'max_features': 1.0, 'max_leaves': 283, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 6, 'max_features': 1.0, 'max_leaves': 283, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:35] {143} DEBUG - flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=283, n_estimators=1,\n",
      "                       n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=283, n_estimators=1,\n",
      "                       n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:36] {146} DEBUG - flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=283, n_estimators=1,\n",
      "                       n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=283, n_estimators=1,\n",
      "                       n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:36] {143} DEBUG - flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=283, n_estimators=4,\n",
      "                       n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=283, n_estimators=4,\n",
      "                       n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:36] {146} DEBUG - flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=283, n_estimators=4,\n",
      "                       n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=283, n_estimators=4,\n",
      "                       n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:36] {143} DEBUG - flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=283, n_estimators=6,\n",
      "                       n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=283, n_estimators=6,\n",
      "                       n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:37] {146} DEBUG - flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=283, n_estimators=6,\n",
      "                       n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(max_features=1.0, max_leaf_nodes=283, n_estimators=6,\n",
      "                       n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:37] {2023} INFO -  at 39.4s,\testimator rf's best error=0.1476,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 39.4s,\testimator rf's best error=0.1476,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:37] {1826} INFO - iteration 65, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 65, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:37] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.9690478421544381, 'max_leaves': 515, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 0.9690478421544381, 'max_leaves': 515, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:37] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9690478421544381, max_leaf_nodes=515,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9690478421544381, max_leaf_nodes=515,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:38] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9690478421544381, max_leaf_nodes=515,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9690478421544381, max_leaf_nodes=515,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:38] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9690478421544381, max_leaf_nodes=515,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9690478421544381, max_leaf_nodes=515,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:38] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9690478421544381, max_leaf_nodes=515,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9690478421544381, max_leaf_nodes=515,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:38] {2023} INFO -  at 40.8s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 40.8s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:38] {1826} INFO - iteration 66, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 66, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:38] {403} INFO - trial 1 config: {'n_estimators': 6, 'max_features': 0.7774020881365313, 'max_leaves': 146, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 6, 'max_features': 0.7774020881365313, 'max_leaves': 146, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:38] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7774020881365313,\n",
      "                     max_leaf_nodes=146, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7774020881365313,\n",
      "                     max_leaf_nodes=146, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:39] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7774020881365313,\n",
      "                     max_leaf_nodes=146, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7774020881365313,\n",
      "                     max_leaf_nodes=146, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:39] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7774020881365313,\n",
      "                     max_leaf_nodes=146, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7774020881365313,\n",
      "                     max_leaf_nodes=146, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:39] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7774020881365313,\n",
      "                     max_leaf_nodes=146, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7774020881365313,\n",
      "                     max_leaf_nodes=146, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:39] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7774020881365313,\n",
      "                     max_leaf_nodes=146, n_estimators=6, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7774020881365313,\n",
      "                     max_leaf_nodes=146, n_estimators=6, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:40] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7774020881365313,\n",
      "                     max_leaf_nodes=146, n_estimators=6, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.7774020881365313,\n",
      "                     max_leaf_nodes=146, n_estimators=6, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:40] {2023} INFO -  at 42.0s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 42.0s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:40] {1826} INFO - iteration 67, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 67, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:40] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.5609561213324874, 'max_leaves': 1070, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 0.5609561213324874, 'max_leaves': 1070, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:40] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.5609561213324874, max_leaf_nodes=1070,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.5609561213324874, max_leaf_nodes=1070,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:40] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.5609561213324874, max_leaf_nodes=1070,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.5609561213324874, max_leaf_nodes=1070,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:40] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.5609561213324874, max_leaf_nodes=1070,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.5609561213324874, max_leaf_nodes=1070,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:41] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.5609561213324874, max_leaf_nodes=1070,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.5609561213324874, max_leaf_nodes=1070,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:41] {2023} INFO -  at 43.0s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 43.0s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:41] {1826} INFO - iteration 68, current learner rf\n",
      "INFO:flaml.automl:iteration 68, current learner rf\n",
      "[flaml.tune.tune: 12-02 12:59:41] {403} INFO - trial 1 config: {'n_estimators': 6, 'max_features': 0.6207949500985488, 'max_leaves': 146, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 6, 'max_features': 0.6207949500985488, 'max_leaves': 146, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:41] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6207949500985488,\n",
      "                       max_leaf_nodes=146, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6207949500985488,\n",
      "                       max_leaf_nodes=146, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:41] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6207949500985488,\n",
      "                       max_leaf_nodes=146, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6207949500985488,\n",
      "                       max_leaf_nodes=146, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:41] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6207949500985488,\n",
      "                       max_leaf_nodes=146, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6207949500985488,\n",
      "                       max_leaf_nodes=146, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:41] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6207949500985488,\n",
      "                       max_leaf_nodes=146, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6207949500985488,\n",
      "                       max_leaf_nodes=146, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:41] {143} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6207949500985488,\n",
      "                       max_leaf_nodes=146, n_estimators=6, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6207949500985488,\n",
      "                       max_leaf_nodes=146, n_estimators=6, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:41] {146} DEBUG - flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6207949500985488,\n",
      "                       max_leaf_nodes=146, n_estimators=6, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - RandomForestClassifier(criterion='entropy', max_features=0.6207949500985488,\n",
      "                       max_leaf_nodes=146, n_estimators=6, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:41] {2023} INFO -  at 43.9s,\testimator rf's best error=0.1476,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 43.9s,\testimator rf's best error=0.1476,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:41] {1826} INFO - iteration 69, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 69, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:41] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.875751262936266, 'max_leaves': 332, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 0.875751262936266, 'max_leaves': 332, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:41] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.875751262936266,\n",
      "                     max_leaf_nodes=332, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.875751262936266,\n",
      "                     max_leaf_nodes=332, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:42] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.875751262936266,\n",
      "                     max_leaf_nodes=332, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.875751262936266,\n",
      "                     max_leaf_nodes=332, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:42] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.875751262936266,\n",
      "                     max_leaf_nodes=332, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.875751262936266,\n",
      "                     max_leaf_nodes=332, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:43] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.875751262936266,\n",
      "                     max_leaf_nodes=332, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.875751262936266,\n",
      "                     max_leaf_nodes=332, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:43] {2023} INFO -  at 45.1s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 45.1s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:43] {1826} INFO - iteration 70, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 70, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:43] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.4979592705521248, 'max_leaves': 470, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 0.4979592705521248, 'max_leaves': 470, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:43] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.4979592705521248, max_leaf_nodes=470,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.4979592705521248, max_leaf_nodes=470,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:43] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.4979592705521248, max_leaf_nodes=470,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.4979592705521248, max_leaf_nodes=470,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:43] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.4979592705521248, max_leaf_nodes=470,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.4979592705521248, max_leaf_nodes=470,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:43] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.4979592705521248, max_leaf_nodes=470,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.4979592705521248, max_leaf_nodes=470,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:43] {2023} INFO -  at 45.9s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 45.9s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:43] {1826} INFO - iteration 71, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 71, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:43] {403} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.9240180397104876, 'max_leaves': 234, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 7, 'max_features': 0.9240180397104876, 'max_leaves': 234, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:43] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9240180397104876, max_leaf_nodes=234,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9240180397104876, max_leaf_nodes=234,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:44] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9240180397104876, max_leaf_nodes=234,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9240180397104876, max_leaf_nodes=234,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:44] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9240180397104876, max_leaf_nodes=234,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9240180397104876, max_leaf_nodes=234,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:45] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9240180397104876, max_leaf_nodes=234,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9240180397104876, max_leaf_nodes=234,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:45] {2023} INFO -  at 47.2s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 47.2s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:45] {1826} INFO - iteration 72, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 72, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:45] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.47194799380051056, 'max_leaves': 667, 'criterion': 'entropy'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 0.47194799380051056, 'max_leaves': 667, 'criterion': 'entropy'}\n",
      "[flaml.automl: 12-02 12:59:45] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.47194799380051056,\n",
      "                     max_leaf_nodes=667, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.47194799380051056,\n",
      "                     max_leaf_nodes=667, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:45] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.47194799380051056,\n",
      "                     max_leaf_nodes=667, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.47194799380051056,\n",
      "                     max_leaf_nodes=667, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:45] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.47194799380051056,\n",
      "                     max_leaf_nodes=667, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.47194799380051056,\n",
      "                     max_leaf_nodes=667, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:46] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.47194799380051056,\n",
      "                     max_leaf_nodes=667, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.47194799380051056,\n",
      "                     max_leaf_nodes=667, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:46] {2023} INFO -  at 48.0s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 48.0s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:46] {1826} INFO - iteration 73, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 73, current learner extra_tree\n",
      "[flaml.tune.tune: 12-02 12:59:46] {403} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.9798339101280237, 'max_leaves': 234, 'criterion': 'gini'}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'n_estimators': 4, 'max_features': 0.9798339101280237, 'max_leaves': 234, 'criterion': 'gini'}\n",
      "[flaml.automl: 12-02 12:59:46] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9798339101280237, max_leaf_nodes=234,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9798339101280237, max_leaf_nodes=234,\n",
      "                     n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:46] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9798339101280237, max_leaf_nodes=234,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9798339101280237, max_leaf_nodes=234,\n",
      "                     n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:46] {143} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9798339101280237, max_leaf_nodes=234,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9798339101280237, max_leaf_nodes=234,\n",
      "                     n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:47] {146} DEBUG - flaml.model - ExtraTreesClassifier(max_features=0.9798339101280237, max_leaf_nodes=234,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(max_features=0.9798339101280237, max_leaf_nodes=234,\n",
      "                     n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:47] {2023} INFO -  at 49.3s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 49.3s,\testimator extra_tree's best error=0.1427,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:47] {1826} INFO - iteration 74, current learner lrl1\n",
      "INFO:flaml.automl:iteration 74, current learner lrl1\n",
      "INFO:flaml.searcher.blendsearch:No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://github.com/microsoft/FLAML/wiki/About-%60low_cost_partial_config%60\n",
      "[flaml.tune.tune: 12-02 12:59:47] {403} INFO - trial 1 config: {'C': 1.0}\n",
      "INFO:flaml.tune.tune:trial 1 config: {'C': 1.0}\n",
      "[flaml.automl: 12-02 12:59:47] {143} DEBUG - flaml.model - LogisticRegression(n_jobs=-1, penalty='l1', solver='saga') fit started\n",
      "DEBUG:flaml.automl:flaml.model - LogisticRegression(n_jobs=-1, penalty='l1', solver='saga') fit started\n",
      "/Users/eirik.stavelin/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 12-02 12:59:55] {146} DEBUG - flaml.model - LogisticRegression(n_jobs=-1, penalty='l1', solver='saga') fit finished\n",
      "DEBUG:flaml.automl:flaml.model - LogisticRegression(n_jobs=-1, penalty='l1', solver='saga') fit finished\n",
      "[flaml.automl: 12-02 12:59:55] {2023} INFO -  at 57.8s,\testimator lrl1's best error=0.1671,\tbest estimator extra_tree's best error=0.1427\n",
      "INFO:flaml.automl: at 57.8s,\testimator lrl1's best error=0.1671,\tbest estimator extra_tree's best error=0.1427\n",
      "[flaml.automl: 12-02 12:59:55] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.6603699418332465,\n",
      "                     max_leaf_nodes=395, n_estimators=1, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.6603699418332465,\n",
      "                     max_leaf_nodes=395, n_estimators=1, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:56] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.6603699418332465,\n",
      "                     max_leaf_nodes=395, n_estimators=1, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.6603699418332465,\n",
      "                     max_leaf_nodes=395, n_estimators=1, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:56] {143} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.6603699418332465,\n",
      "                     max_leaf_nodes=395, n_estimators=4, n_jobs=-1) fit started\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.6603699418332465,\n",
      "                     max_leaf_nodes=395, n_estimators=4, n_jobs=-1) fit started\n",
      "[flaml.automl: 12-02 12:59:57] {146} DEBUG - flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.6603699418332465,\n",
      "                     max_leaf_nodes=395, n_estimators=4, n_jobs=-1) fit finished\n",
      "DEBUG:flaml.automl:flaml.model - ExtraTreesClassifier(criterion='entropy', max_features=0.6603699418332465,\n",
      "                     max_leaf_nodes=395, n_estimators=4, n_jobs=-1) fit finished\n",
      "[flaml.automl: 12-02 12:59:57] {2240} INFO - retrain extra_tree for 1.3s\n",
      "INFO:flaml.automl:retrain extra_tree for 1.3s\n",
      "[flaml.automl: 12-02 12:59:57] {2247} INFO - retrained model: ExtraTreesClassifier(criterion='entropy', max_features=0.6603699418332465,\n",
      "                     max_leaf_nodes=395, n_estimators=4, n_jobs=-1)\n",
      "INFO:flaml.automl:retrained model: ExtraTreesClassifier(criterion='entropy', max_features=0.6603699418332465,\n",
      "                     max_leaf_nodes=395, n_estimators=4, n_jobs=-1)\n",
      "[flaml.automl: 12-02 12:59:57] {1608} INFO - fit succeeded\n",
      "INFO:flaml.automl:fit succeeded\n",
      "[flaml.automl: 12-02 12:59:57] {1609} INFO - Time taken to find the best model: 24.745869636535645\n",
      "INFO:flaml.automl:Time taken to find the best model: 24.745869636535645\n"
     ]
    }
   ],
   "source": [
    "# Initialize an AutoML instance\n",
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "\n",
    "automl_settings = {\n",
    "    \"time_budget\": 50,#43200, #10801,  # in seconds (This will train for 10 minutes) 3600=1h\n",
    "    \"metric\": 'macro_f1',\n",
    "    \"task\": 'classification',\n",
    "    \"log_file_name\": \"nlp.log\",\n",
    "    'n_jobs': -1#,\n",
    "#    'eval_method': 'cv',\n",
    "#    'n_splits': 5\n",
    "}\n",
    "\n",
    "# perhaps flaml also can nest models, as ensambles...\n",
    "# ensemble – boolean or dict | default=False. Whether to perform ensemble after search. \n",
    "# Can be a dict with keys ‘passthrough’ and ‘final_estimator’ to specify the passthrough \n",
    "# and final_estimator in the stacker.\n",
    "\n",
    "\n",
    "# Fit the models\n",
    "automl.fit(X_train=X_train, y_train=y_train, verbose=4, **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.745869636535645"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<flaml.model.ExtraTreesEstimator at 0x10e600100>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(criterion='entropy', max_features=0.6603699418332465,\n",
       "                     max_leaf_nodes=395, n_estimators=4, n_jobs=-1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[585,  89],\n",
       "       [104, 595]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'85_94'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       674\n",
      "           1       0.87      0.85      0.86       699\n",
      "\n",
      "    accuracy                           0.86      1373\n",
      "   macro avg       0.86      0.86      0.86      1373\n",
      "weighted avg       0.86      0.86      0.86      1373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Time to find best model (in seconds)\n",
    "automl.time_to_find_best_model\n",
    "\n",
    "# Inspect the best model\n",
    "automl.model\n",
    "\n",
    "# look at estimator\n",
    "automl.model.estimator\n",
    "\n",
    "\n",
    "flaml_pred = automl.predict(X_val)\n",
    "# Inspect the confusion matrix\n",
    "#automl.model.score(X_val, y_val)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_val, flaml_pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = str(round(accuracy_score(y_val, flaml_pred)*100, 2)).replace(\".\", \"_\")\n",
    "acc\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_val, flaml_pred, target_names=['0','1']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.ensemble._forest.ExtraTreesClassifier"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(automl.model.estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pickle and save the automl object'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'load pickled automl object'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.05077413, 1.        , 1.        , ..., 0.79444444, 0.75      ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "time_used = automl_settings.get('time_budget', 'unknown_time')\n",
    "model_name = automl.model.estimator.__class__.__name__\n",
    "\n",
    "file_name = f'../../data/models/automl_{model_name}_{time_used}_s_acs_{acc}.pkl'\n",
    "'''pickle and save the automl object'''\n",
    "import pickle\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(automl, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "'''load pickled automl object'''\n",
    "with open(file_name, 'rb') as f:\n",
    "    automl = pickle.load(f)\n",
    "\n",
    "automl.predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature1 = generate_language_features(pd.DataFrame([\"Eirik\"], columns=[\"Name\"]))\n",
    "\n",
    "# her trenger jeg features slik mine egne funksjoner har definert det:\n",
    "# 1 gen features\n",
    "# 2 ohe på kategorisk varabler\n",
    "# drop navn\n",
    "\n",
    "#automl.predict_proba(feature1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "class Debug(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def transform(self, X):\n",
    "        print(\"Debug transform\")\n",
    "        print(X)\n",
    "        print(pd.DataFrame(X).head())\n",
    "        print(X.shape)\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9370aa7a89e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# apply the pipeline to the input dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \"\"\"\n\u001b[1;32m    425\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mlast_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    349\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-9370aa7a89e0>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input_df, **transform_params)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtransform_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/ntk/aux_functions.py\u001b[0m in \u001b[0;36mgenerate_language_features\u001b[0;34m(df, col, verbose)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     df['final_letter_is_vowel'] = df[col].str.endswith(\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3453\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3454\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3455\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Name'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class DataframeFunctionTransformer():\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        return self.func(input_df)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "def drop_cols(input_df, cols=['Name', 'Gender']):\n",
    "    # for col in cols:\n",
    "    #     if col in input_df:\n",
    "    #         input_df.drop()\n",
    "    input_df.drop(labels = cols, axis=1, errors='ignore', inplace=True)\n",
    "    # input_df[\"text\"] = input_df[\"text\"].map(lambda t: t.upper())\n",
    "    return input_df\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"one_hot\", OneHotEncoder(handle_unknown=\"ignore\"), [\"last_1_letter\", \"last_2_letter\", \"last_3_letter\"]),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "# this pipeline has a single step\n",
    "pipeline = Pipeline(\n",
    "    verbose=True,\n",
    "    steps=[\n",
    "    (\"generate_features\", DataframeFunctionTransformer(generate_language_features)),\n",
    "   (\"drop_cols\", DataframeFunctionTransformer(drop_cols)),\n",
    "   # ('dbg', Debug()),\n",
    "    (\"ohe_cat_variables\", preprocessor)\n",
    "    # ,\n",
    "    # (\"model\", lgb.LGBMClassifier(colsample_bytree=0.5205191706285026, learning_rate=1.0,\n",
    "    #            max_bin=511, min_child_samples=2, n_estimators=42, num_leaves=10,\n",
    "    #            reg_alpha=0.0922808777931273, reg_lambda=0.0009765625,\n",
    "    #            verbose=-1))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# # sample dataframe\n",
    "# df = pd.DataFrame({\n",
    "#    # \"id\":[1,2,3,4],\n",
    "#     \"Name\":[\"Eirik\",\"Bar\",\"BAz\",\"quux\"]\n",
    "# })\n",
    "\n",
    "# apply the pipeline to the input dataframe\n",
    "_ = pipeline.fit_transform(X_train.copy())\n",
    "print(\"What?\")\n",
    "_.shape\n",
    "\n",
    "\n",
    "\n",
    "print(\"Transform someting:\")\n",
    "pipeline[-1].get_feature_names_out()\n",
    "print(pipeline.transform(pd.DataFrame({'Name': ['Eirik', 'Ingeridene']})))\n",
    "\n",
    "pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pickle and save the automl object'"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'load pickled automl object'"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one_hot__last_1_letter_A</th>\n",
       "      <th>one_hot__last_1_letter_B</th>\n",
       "      <th>one_hot__last_1_letter_C</th>\n",
       "      <th>one_hot__last_1_letter_D</th>\n",
       "      <th>one_hot__last_1_letter_E</th>\n",
       "      <th>one_hot__last_1_letter_F</th>\n",
       "      <th>one_hot__last_1_letter_G</th>\n",
       "      <th>one_hot__last_1_letter_H</th>\n",
       "      <th>one_hot__last_1_letter_I</th>\n",
       "      <th>one_hot__last_1_letter_J</th>\n",
       "      <th>one_hot__last_1_letter_K</th>\n",
       "      <th>one_hot__last_1_letter_L</th>\n",
       "      <th>one_hot__last_1_letter_M</th>\n",
       "      <th>one_hot__last_1_letter_N</th>\n",
       "      <th>one_hot__last_1_letter_O</th>\n",
       "      <th>...</th>\n",
       "      <th>one_hot__last_3_letter_ØRG</th>\n",
       "      <th>one_hot__last_3_letter_ØRK</th>\n",
       "      <th>one_hot__last_3_letter_ØRN</th>\n",
       "      <th>one_hot__last_3_letter_ØRT</th>\n",
       "      <th>one_hot__last_3_letter_ØVE</th>\n",
       "      <th>one_hot__last_3_letter_ØYA</th>\n",
       "      <th>one_hot__last_3_letter_ÚLI</th>\n",
       "      <th>one_hot__last_3_letter_ÚNA</th>\n",
       "      <th>one_hot__last_3_letter_ÚNI</th>\n",
       "      <th>one_hot__last_3_letter_ÚSI</th>\n",
       "      <th>one_hot__last_3_letter_ÚST</th>\n",
       "      <th>one_hot__last_3_letter_ÝR</th>\n",
       "      <th>one_hot__last_3_letter_ÞÓR</th>\n",
       "      <th>remainder__final_letter_is_vowel</th>\n",
       "      <th>remainder__syllable_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1652 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   one_hot__last_1_letter_A  one_hot__last_1_letter_B  \\\n",
       "0                       0.0                       0.0   \n",
       "\n",
       "   one_hot__last_1_letter_C  one_hot__last_1_letter_D  \\\n",
       "0                       0.0                       0.0   \n",
       "\n",
       "   one_hot__last_1_letter_E  one_hot__last_1_letter_F  \\\n",
       "0                       0.0                       0.0   \n",
       "\n",
       "   one_hot__last_1_letter_G  one_hot__last_1_letter_H  \\\n",
       "0                       0.0                       0.0   \n",
       "\n",
       "   one_hot__last_1_letter_I  one_hot__last_1_letter_J  \\\n",
       "0                       0.0                       0.0   \n",
       "\n",
       "   one_hot__last_1_letter_K  one_hot__last_1_letter_L  \\\n",
       "0                       1.0                       0.0   \n",
       "\n",
       "   one_hot__last_1_letter_M  one_hot__last_1_letter_N  \\\n",
       "0                       0.0                       0.0   \n",
       "\n",
       "   one_hot__last_1_letter_O  ...  one_hot__last_3_letter_ØRG  \\\n",
       "0                       0.0  ...                         0.0   \n",
       "\n",
       "   one_hot__last_3_letter_ØRK  one_hot__last_3_letter_ØRN  \\\n",
       "0                         0.0                         0.0   \n",
       "\n",
       "   one_hot__last_3_letter_ØRT  one_hot__last_3_letter_ØVE  \\\n",
       "0                         0.0                         0.0   \n",
       "\n",
       "   one_hot__last_3_letter_ØYA  one_hot__last_3_letter_ÚLI  \\\n",
       "0                         0.0                         0.0   \n",
       "\n",
       "   one_hot__last_3_letter_ÚNA  one_hot__last_3_letter_ÚNI  \\\n",
       "0                         0.0                         0.0   \n",
       "\n",
       "   one_hot__last_3_letter_ÚSI  one_hot__last_3_letter_ÚST  \\\n",
       "0                         0.0                         0.0   \n",
       "\n",
       "   one_hot__last_3_letter_ÝR  one_hot__last_3_letter_ÞÓR  \\\n",
       "0                        0.0                         0.0   \n",
       "\n",
       "   remainder__final_letter_is_vowel  remainder__syllable_count  \n",
       "0                               0.0                        1.0  \n",
       "\n",
       "[1 rows x 1652 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = f'data/_pickled2_pipe.pkl'\n",
    "'''pickle and save the automl object'''\n",
    "import pickle\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(pipeline, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "'''load pickled automl object'''\n",
    "with open(file_name, 'rb') as f:\n",
    "    pipeline = pickle.load(f)\n",
    "\n",
    "\n",
    "# test\n",
    "pd.DataFrame.sparse.from_spmatrix(\n",
    "    pipeline.transform(pd.DataFrame({\"Name\": [\"Eirik\"]})), \n",
    "    columns=pipeline[2].get_feature_names_out()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Gender]\n",
       "Index: []"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(5505, 1)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(5505, 1652)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['one_hot__last_1_letter_A', 'one_hot__last_1_letter_B',\n",
       "       'one_hot__last_1_letter_C', ..., 'one_hot__last_3_letter_ÞÓR',\n",
       "       'remainder__final_letter_is_vowel', 'remainder__syllable_count'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = load_gendered_names()\n",
    "y = df['Gender']\n",
    "X = df.drop(columns=['Gender'])\n",
    "\n",
    "df[X.duplicated()] # I get duplicates when the names and gender gets dropped. That is prob a problem.\n",
    "\n",
    "# tmp enrich data using pipeline\n",
    "X.shape\n",
    "X_train_transformed = pipeline.transform(X)\n",
    "X_train_transformed.shape\n",
    "\n",
    "# Test\n",
    "#test = pd.DataFrame.sparse.from_spmatrix(\n",
    "#    X_train_transformed, \n",
    "#    columns=pipeline[2].get_feature_names_out()\n",
    "#    )\n",
    "#test['Gender'] = df['Gender']\n",
    "#test['Name'] = df['Name']\n",
    "#test\n",
    "pipeline[2].get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_transformed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c50b27484dc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# split data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=99)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_transformed' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# split data\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=99)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_transformed, y, random_state=99)\n",
    "X_train.shape\n",
    "type(X_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c0076cafcd7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train_df = pd.DataFrame.sparse.from_spmatrix(\n\u001b[1;32m      2\u001b[0m    \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m    \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m    ).reindex()\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#X_train_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mget_feature_names_out\u001b[0;34m(self, input_features)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0minput_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_feature_names_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "X_train_df = pd.DataFrame.sparse.from_spmatrix(\n",
    "   X_train, \n",
    "   columns=pipeline[2].get_feature_names_out()\n",
    "   ).reindex()\n",
    "#X_train_df\n",
    "type(X_train_df)\n",
    "X_train_df.shape\n",
    "type(y_train)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-330f05a622da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Fit the models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mautoml_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# what model should I choose?\n",
    "\n",
    "# Initialize an AutoML instance\n",
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "\n",
    "automl_settings = {\n",
    "    \"time_budget\": 2000,  # in seconds (This will train for 10 minutes) 3600=1h\n",
    "    \"metric\": 'macro_f1',\n",
    "    \"task\": 'classification',\n",
    "    \"log_file_name\": \"nlp.log\",\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Fit the models\n",
    "automl.fit(X_train=X_train_df, y_train=y_train, verbose=1, **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still hard. let's see if https://github.com/scikit-learn-contrib/sklearn-pandas \n",
    "# can make this easier..\n",
    "\n",
    "#df = pd.DataFrame({\n",
    "#    \"id\":[1,2,3,4],\n",
    "#    \"Name\":[\"Eirik\",\"Bar\",\"BAz\",\"quux\"]\n",
    "#})\n",
    "#from sklearn_pandas import DataFrameMapper, gen_features\n",
    "#\n",
    "#\n",
    "#class GetColumnsStartingWith:\n",
    "#>    def __init__(self, start_str):\n",
    " #       self.pattern = start_str\n",
    "#\n",
    "#    def __call__(self, X:pd.DataFrame=None):\n",
    "#        return [c for c in X.columns if c.startswith(self.pattern)]\n",
    "#\n",
    "#mapper = DataFrameMapper([\n",
    "#     #gen_features(columns=[\"Name\"], classes=[generate_language_features], )\n",
    "#     ('Name', DataframeFunctionTransformer(generate_language_features), {''}) #,\n",
    "#     #(GetColumnsStartingWith(\"last_\"),  OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "# ])\n",
    "\n",
    "\n",
    "# df\n",
    "# mapper.fit_transform(df)\n",
    "\n",
    "\n",
    "# not easier, because the DataFrameMapper seems to always expect us to work col-by-col\n",
    "# so the feature generation does not fit into this, and I end up with yet-another thing thats\n",
    "# need to be pickled with the model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0e2ea01bd33f26cc744c5ad7e2be103241be5e8a6903fb841a3bd29e21386e2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('3.9.0': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
